{"./":{"url":"./","title":"Introduction","keywords":"","body":"概括 JUC "},"Doc/util/AbstractMap.java.html":{"url":"Doc/util/AbstractMap.java.html","title":"AbstractMap.Java","keywords":"","body":"AbstractMap /* * Copyright (c) 1997, 2013, Oracle and/or its affiliates. All rights reserved. * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ package java.util; import java.util.Map.Entry; /** * This class provides a skeletal implementation of the Map * interface, to minimize the effort required to implement this interface. * 该类对Map接口提供了骨架实现，以尽量减少实现Map接口所需要的工作量。 * * To implement an unmodifiable map, the programmer needs only to extend this * class and provide an implementation for the entrySet method, which * returns a set-view of the map's mappings. Typically, the returned set * will, in turn, be implemented atop AbstractSet. This set should * not support the add or remove methods, and its iterator * should not support the remove method. * 实现不可修改的map，程序员仅需要扩展本类并且提供对entrySet方法的实现，entrySet方法返回map的映射set集合视图。 * 通常，返回的set集合将依次在AbstractSet之上实现。 * 该set集合将不支持add、remove方法，并且它的迭代器不支持remove方法。 * * To implement a modifiable map, the programmer must additionally override * this class's put method (which otherwise throws an * UnsupportedOperationException), and the iterator returned by * entrySet().iterator() must additionally implement its * remove method. * 实现可修改的map，程序员必须额外覆盖（override 重写）本类的put方法（否则将抛出UnsupportedOperationException）， * 并且通过entrySet()/iterator()返回的迭代器必须额外实现它的remove方法。 * * The programmer should generally provide a void (no argument) and map * constructor, as per the recommendation in the Map interface * specification. * 根据Map接口的建议，程序员通常提供了一个void（无参数）和一个map的构造函数。 * (Map接口的建议：所有通用目的的map实现类都应该支持两种“标准”构造方法，一种是无参，一种是map（会拷贝成等效map）) * * The documentation for each non-abstract method in this class describes its * implementation in detail. Each of these methods may be overridden if the * map being implemented admits a more efficient implementation. * 对于在本类中的每个非抽象方法，该文档描述了他们的实现细节。 * 每个方法都可能被覆盖，如果正在实现的map允许更有效的实现。 * * This class is a member of the * * Java Collections Framework. * 本类属于Java Collection Framework * * @param the type of keys maintained by this map * @param the type of mapped values * * @author Josh Bloch * @author Neal Gafter * @see Map * @see Collection * @since 1.2 */ public abstract class AbstractMap implements Map { /** * Sole constructor. (For invocation by subclass constructors, typically * implicit.) * 唯一构造器。（对于子类构造函数的调用，通常是隐式的） */ protected AbstractMap() { } // Query Operations // 查询操作 /** * {@inheritDoc} * 继承文档 * 注意，{@inheritDoc}表明 * * @implSpec * 实现规范 * This implementation returns entrySet().size(). * 该实现返回entrySet().size() * */ public int size() { return entrySet().size(); } /** * {@inheritDoc} * * @implSpec * This implementation returns size() == 0. */ public boolean isEmpty() { return size() == 0; } /** * {@inheritDoc} * * @implSpec * This implementation iterates over entrySet() searching * for an entry with the specified value. If such an entry is found, * true is returned. If the iteration terminates without * finding such an entry, false is returned. Note that this * implementation requires linear time in the size of the map. * 此实现通过遍历entrySet()来搜索具有指定value的entry。 * 如果搜到对应的entry，返回true。 * 如果迭代结束没有找到对应的entry，返回false。 * 注意，该实现所需要的时间与map的大小成线性相关。 * * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public boolean containsValue(Object value) { Iterator> i = entrySet().iterator(); // （这个迭代器对象缩写成i看呆了） if (value==null) { // 区分null与非null的情况，分别进行遍历 while (i.hasNext()) { Entry e = i.next(); if (e.getValue()==null) return true; } } else { while (i.hasNext()) { Entry e = i.next(); if (value.equals(e.getValue())) return true; } } return false; } /** * {@inheritDoc} * * @implSpec * This implementation iterates over entrySet() searching * for an entry with the specified key. If such an entry is found, * true is returned. If the iteration terminates without * finding such an entry, false is returned. Note that this * implementation requires linear time in the size of the map; many * implementations will override this method. * 此实现通过遍历entrySet()来搜索具有指定key的entry。 * 如果搜到对应的entry，返回true。 * 如果迭代结束没有找到对应的entry，返回false。 * 注意，该实现所需要的时间与map的大小成线性相关。 * 许多实现会重写（override）该方法。（因为有很多对提高key查询效率做的优化） * * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public boolean containsKey(Object key) { Iterator> i = entrySet().iterator(); if (key==null) { while (i.hasNext()) { Entry e = i.next(); if (e.getKey()==null) return true; } } else { while (i.hasNext()) { Entry e = i.next(); if (key.equals(e.getKey())) return true; } } return false; } /** * {@inheritDoc} * * @implSpec * This implementation iterates over entrySet() searching * for an entry with the specified key. If such an entry is found, * the entry's value is returned. If the iteration terminates without * finding such an entry, null is returned. Note that this * implementation requires linear time in the size of the map; many * implementations will override this method. * 此实现通过遍历entrySet()来搜索具有指定key的entry。 * 如果搜到对应的entry，返回该entry的value值。 * 如果迭代结束没有找到对应的entry，返回null。 * 注意，该实现所需要的时间与map的大小成线性相关。 * 许多实现会重写（override）该方法。（对key的访问优化） * * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public V get(Object key) { Iterator> i = entrySet().iterator(); if (key==null) { while (i.hasNext()) { Entry e = i.next(); if (e.getKey()==null) return e.getValue(); } } else { while (i.hasNext()) { Entry e = i.next(); if (key.equals(e.getKey())) return e.getValue(); } } return null; } // Modification Operations // 修改操作 /** * {@inheritDoc} * * @implSpec * This implementation always throws an * UnsupportedOperationException. * 该实现总是抛出UnsupportedOperationException。（啥原因，因为不能通过entry来put么？？？） * * @throws UnsupportedOperationException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @throws IllegalArgumentException {@inheritDoc} */ public V put(K key, V value) { throw new UnsupportedOperationException(); } /** * {@inheritDoc} * * @implSpec * This implementation iterates over entrySet() searching for an * entry with the specified key. If such an entry is found, its value is * obtained with its getValue operation, the entry is removed * from the collection (and the backing map) with the iterator's * remove operation, and the saved value is returned. If the * iteration terminates without finding such an entry, null is * returned. Note that this implementation requires linear time in the * size of the map; many implementations will override this method. * 此实现通过遍历entrySet()来搜索具有指定key的entry。 * 如果搜到对应的entry，则通过getValue操作获取该key对应的value值，并通过迭代器的remove操作将该entry从集合中（也会反映到map上）移除，并返回刚保存的value值。 * 如果遍历结束没有找到对应的entry，返回null。 * 注意，该实现所需要的时间与map的大小成线性相关。 * 许多实现会重写（override）该方法。（对key的访问优化） * * Note that this implementation throws an * UnsupportedOperationException if the entrySet * iterator does not support the remove method and this map * contains a mapping for the specified key. * 注意，如果entrySet迭代器不支持remove方法，并且该map包含给定key的映射，则抛出UnsupportedOperationException。 * * @throws UnsupportedOperationException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public V remove(Object key) { Iterator> i = entrySet().iterator(); Entry correctEntry = null; if (key==null) { while (correctEntry==null && i.hasNext()) { // 找到对应的entry结束 Entry e = i.next(); if (e.getKey()==null) correctEntry = e; // 保存对应的entry } } else { while (correctEntry==null && i.hasNext()) { Entry e = i.next(); if (key.equals(e.getKey())) correctEntry = e; } } // 不在遍历时直接保存oldValue的值，而是通过保存entry再获取value值，是因为oldValue为null时不好判断map中是否存在给定key？？？那为啥不用findFlag+oldValue这种东西？？？ V oldValue = null; if (correctEntry !=null) { oldValue = correctEntry.getValue(); // 通过entry获取给定key对应的value i.remove(); // 通过迭代器删除该entry } return oldValue; } // Bulk Operations // 批量操作 /** * {@inheritDoc} * * @implSpec * This implementation iterates over the specified map's * entrySet() collection, and calls this map's put * operation once for each entry returned by the iteration. * 本实现通过迭代给定map（mapA）的entrySet()集合，并对通过迭代返回的每一个entry调用该map（mapB）的put操作。 * * Note that this implementation throws an * UnsupportedOperationException if this map does not support * the put operation and the specified map is nonempty. * 注意，如果该map不支持put操作并且给定map不为空，则抛出UnsupportedOperationException。 * * * @throws UnsupportedOperationException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @throws IllegalArgumentException {@inheritDoc} */ public void putAll(Map m) { for (Map.Entry e : m.entrySet()) put(e.getKey(), e.getValue()); // 遍历给定map，将每个entry都加入到当前map中 } /** * {@inheritDoc} * * @implSpec * This implementation calls entrySet().clear(). * 本实现调用entrySet().clear() * * Note that this implementation throws an * UnsupportedOperationException if the entrySet * does not support the clear operation. * 注意，如果entrySet不支持clear操作，则抛出UnsupportedOperationException。 * * @throws UnsupportedOperationException {@inheritDoc} */ public void clear() { entrySet().clear(); } // Views // 视图 /** * Each of these fields are initialized to contain an instance of the * appropriate view the first time this view is requested. The views are * stateless, so there's no reason to create more than one of each. * 在第一次请求该视图的时候，每一个字段都被初始化为包含相应（appropriate）视图的实例。 * 视图是无状态的，所以没有必要创建多个视图。 * * Since there is no synchronization performed while accessing these fields, * it is expected that java.util.Map view classes using these fields have * no non-final fields (or any fields at all except for outer-this). Adhering * to this rule would make the races on these fields benign. * 由于在访问这些字段的时候没有（限制）同步执行，因此使用这些字段的java.util.Map视图应该没有使用非final字段（或除了outer-this之外的任何字段）。 * 遵守这一规则将使得在这些字段上的竞争变得良性。 * （必须使用final来修饰引用下面这些视图的field？？？） * * It is also imperative that implementations read the field only once, * as in: * 实现只读取该字段一次也是有必要的。（仅有一次读取赋值） * * {@code * public Set keySet() { * Set ks = keySet; // single racy read * if (ks == null) { * ks = new KeySet(); * keySet = ks; * } * return ks; * } *} */ transient Set keySet; // transient修饰，不会被序列化 transient Collection values; /** * {@inheritDoc} * * @implSpec * This implementation returns a set that subclasses {@link AbstractSet}. * The subclass's iterator method returns a \"wrapper object\" over this * map's entrySet() iterator. The size method * delegates to this map's size method and the * contains method delegates to this map's * containsKey method. * 返回AbstractSet的子类实现。 * 该子类的迭代器方法，在该map的entrySet()迭代器上返回一个“包装器对象”。（借用了该map的entrySet()迭代器） * size方法委托给该map的size方法，contains方法委托给该map的containsKey方法。（都是借用） * * The set is created the first time this method is called, * and returned in response to all subsequent calls. No synchronization * is performed, so there is a slight chance that multiple calls to this * method will not all return the same set. * 该set在首次调用该方法时创建（并返回），并且在后续的调用中直接返回。 * 没有同步执行（的限制），因此（slight chance有微弱的机会）多次调用该方法可能不会总返回相同set。 * */ public Set keySet() { Set ks = keySet; if (ks == null) { // 如果ks非空则直接返回值（可能是第一次，也有可能是并发的问题） ks = new AbstractSet() { public Iterator iterator() { // AbstractSet继承的AbstractConllection（它又实现的Collection），实现类必须实现iterator方法。 return new Iterator() { private Iterator> i = entrySet().iterator(); // 调用该map的entrySet()迭代器方法进行了包装。 public boolean hasNext() { return i.hasNext(); } public K next() { return i.next().getKey(); // 因为该方法是keySet，所以要从entrySet中取出key来返回 } public void remove() { i.remove(); } }; } public int size() { return AbstractMap.this.size(); // 调用该map的size方法（表明key的个数与该map的个数是相等的） } public boolean isEmpty() { return AbstractMap.this.isEmpty(); } public void clear() { AbstractMap.this.clear(); // keySet的clear会将整个map进行clear } public boolean contains(Object k) { return AbstractMap.this.containsKey(k); // key的contains是通过调用map的containsKey来实现的 } }; keySet = ks; } return ks; } /** * {@inheritDoc} * * @implSpec * This implementation returns a collection that subclasses {@link * AbstractCollection}. The subclass's iterator method returns a * \"wrapper object\" over this map's entrySet() iterator. * The size method delegates to this map's size * method and the contains method delegates to this map's * containsValue method. * 返回AbstractCollection的子类实现。 * 该子类的迭代器方法，在该map的entrySet()迭代器上返回一个“包装器对象”。（借用了该map的entrySet()迭代器） * size方法委托给该map的size方法，contains方法委托给该map的containsKey方法。（都是借用） * * The collection is created the first time this method is called, and * returned in response to all subsequent calls. No synchronization is * performed, so there is a slight chance that multiple calls to this * method will not all return the same collection. * 该collection在首次调用该方法时创建（并返回），并且在后续的调用中直接返回。 * 没有同步执行（的限制），因此（slight chance有微弱的机会）多次调用该方法可能不会总返回相同set。 * */ public Collection values() { Collection vals = values; if (vals == null) { // 如果vals非空则直接返回值（可能是第一次，也有可能是并发的问题） vals = new AbstractCollection() { public Iterator iterator() { // AbstractConllection（它又实现的Collection），实现类必须实现iterator方法。 return new Iterator() { private Iterator> i = entrySet().iterator(); // 调用该map的entrySet()迭代器方法进行了包装。 public boolean hasNext() { return i.hasNext(); } public V next() { return i.next().getValue(); // 因为该方法是values，所以要从entrySet中取出value来返回 } public void remove() { i.remove(); } }; } public int size() { return AbstractMap.this.size(); // 用map的size返回，与keySet()一样 } public boolean isEmpty() { return AbstractMap.this.isEmpty(); } public void clear() { AbstractMap.this.clear(); // 调用values的clear也会将整个map给clear } public boolean contains(Object v) { return AbstractMap.this.containsValue(v); // contains是通过map的containsValue(v)方法实现的 } }; values = vals; } return vals; } public abstract Set> entrySet(); // 需要实现类自己定义 // Comparison and hashing // 比较与hash /** * Compares the specified object with this map for equality. Returns * true if the given object is also a map and the two maps * represent the same mappings. More formally, two maps m1 and * m2 represent the same mappings if * m1.entrySet().equals(m2.entrySet()). This ensures that the * equals method works properly across different implementations * of the Map interface. * 比较给定的object与该map是否相等。 * 如果给定的object也是个map，并且与该map代表相同的映射，则返回true。 * 更正式的说法，两个map：m1与m2代表相同的映射，当且仅当m1.entrySet().equals(m2.entrySet())。 * 这确保了equals方法可以在Map接口的不同实现中正常工作。 * * @implSpec * This implementation first checks if the specified object is this map; * if so it returns true. Then, it checks if the specified * object is a map whose size is identical to the size of this map; if * not, it returns false. If so, it iterates over this map's * entrySet collection, and checks that the specified map * contains each mapping that this map contains. If the specified map * fails to contain such a mapping, false is returned. If the * iteration completes, true is returned. * 该实现首先检查给定的object是否为该（本）map；如果是，则返回true。 * 然后，检查给定的map是否是大小与该map一致的map，如果不是，返回false。 * 如果相同，迭代遍历该map的entrySet集合，检查给定的map是否包含该map含有的所有映射。 * 如果给定的map未包含这样的映射，返回false。 * 如果迭代完成，返回true。 * * @param o object to be compared for equality with this map * @return true if the specified object is equal to this map */ public boolean equals(Object o) { if (o == this) // 首先判断是否为同一个对象 return true; if (!(o instanceof Map)) // 2、判断给定对象是否为map类型 return false; Map m = (Map) o; if (m.size() != size()) // 3、将给定对象强转成map，判断给定对象的size是否与本map的size相同 return false; try { Iterator> i = entrySet().iterator(); // 4、迭代遍历本map的entry，进行两个对象间的key、value比较 while (i.hasNext()) { Entry e = i.next(); K key = e.getKey(); V value = e.getValue(); if (value == null) { if (!(m.get(key)==null && m.containsKey(key))) // 5、如果本entry的value为null，判断给定的对象该key对应的value是否为null（containsKey是为了在get为null时，确认key是否存在） return false; } else { if (!value.equals(m.get(key))) // 6、如果本entry的value不为null，通过给定对象的get(key)来比较value是否相等。（能get到非null的说明key是存在的） return false; } } } catch (ClassCastException unused) { return false; } catch (NullPointerException unused) { return false; } return true; } /** * Returns the hash code value for this map. The hash code of a map is * defined to be the sum of the hash codes of each entry in the map's * entrySet() view. This ensures that m1.equals(m2) * implies that m1.hashCode()==m2.hashCode() for any two maps * m1 and m2, as required by the general contract of * {@link Object#hashCode}. * 返回该map的hash值。 * map的hash值，是由map中entrySet()视图里每一个entry的hash值相加得到的。 * 确保了对任意两个map：m1与m2，当m1.equals(m2)成立时m1.hashCode()==m2.hashCode()也成立，符合Object#hashCode的普遍要求。 * * @implSpec * This implementation iterates over entrySet(), calling * {@link Map.Entry#hashCode hashCode()} on each element (entry) in the * set, and adding up the results. * 此实现迭代entrySet()，对在set中每一个entry元素调用Map.Entry#hashCode的hashCode()，相加得到结果。 * * @return the hash code value for this map * @see Map.Entry#hashCode() * @see Object#equals(Object) * @see Set#equals(Object) */ public int hashCode() { int h = 0; Iterator> i = entrySet().iterator(); while (i.hasNext()) h += i.next().hashCode(); // 迭代相加每个entry的hash值，结果就作为该map的hash值 return h; } /** * Returns a string representation of this map. The string representation * consists of a list of key-value mappings in the order returned by the * map's entrySet view's iterator, enclosed in braces * (\"{}\"). Adjacent mappings are separated by the characters * \", \" (comma and space). Each key-value mapping is rendered as * the key followed by an equals sign (\"=\") followed by the * associated value. Keys and values are converted to strings as by * {@link String#valueOf(Object)}. * 返回一个表示该map的string。 * string的表现形式为包含key-value映射的列表，按照map的entrySet视图顺序排列，括在{}中。 * 相邻（adjacent 相邻）的映射通过“, ”分隔（逗号与空格）。 * 每个key-value映射的渲染都是key后面跟着等号“=”，再跟着对应的value值。 * key和value通过String#valueOf(Object)转化成string类型。 * * @return a string representation of this map */ public String toString() { Iterator> i = entrySet().iterator(); if (! i.hasNext()) return \"{}\"; StringBuilder sb = new StringBuilder(); // 用StringBuilder来构建字符串，没有同步保证（并发还是用StringBuffer吧）（This class provides an API compatible with StringBuffer, but with no guarantee of synchronization. ） sb.append('{'); for (;;) { Entry e = i.next(); K key = e.getKey(); V value = e.getValue(); sb.append(key == this ? \"(this Map)\" : key); // 判断了一下是否是this，是的话就不嵌套该map.toString()了（因为调用this.toString()可能造成无限递归？？？） sb.append('='); sb.append(value == this ? \"(this Map)\" : value); // sb.append(Object obj)，会调用String.valueOf(obj)转化为String if (! i.hasNext()) return sb.append('}').toString(); sb.append(',').append(' '); } } /** * Returns a shallow copy of this AbstractMap instance: the keys * and values themselves are not cloned. * 返回该AbstractMap实例的浅拷贝：keys与values本身不会拷贝（不会创建keys、values的副本，只是多了个AbstractMap的副本） * （堆里有两个AbstractMap实例对象，拷贝后的result没有keys、values了） * * @return a shallow copy of this map */ protected Object clone() throws CloneNotSupportedException { AbstractMap result = (AbstractMap)super.clone(); result.keySet = null; result.values = null; return result; } /** * Utility method for SimpleEntry and SimpleImmutableEntry. * Test for equality, checking for nulls. * SimpleEntry与SimpleImmutableEntry的实用（Utility）方法。 * 测试相等性，检查null值。 * * NB: Do not replace with Object.equals until JDK-8015417 is resolved. * 注意（NB）：不要用Object.equals来替换该方法，直到JDK-8015417被解决。 * （不知道是否可用JDK1.7的Objects.equals()来做） */ private static boolean eq(Object o1, Object o2) { return o1 == null ? o2 == null : o1.equals(o2); } // Implementation Note: SimpleEntry and SimpleImmutableEntry // are distinct unrelated classes, even though they share // some code. Since you can't add or subtract final-ness // of a field in a subclass, they can't share representations, // and the amount of duplicated code is too small to warrant // exposing a common abstract class. // 实现说明：SimpleEntry（简单Entry）与SimpleImmutableEntry（简单不可变Entry）是不同的不相关的类，即使他们有相同的代码。 // 由于你不能在子类中添加或者减去字段的最终性（final-ness），所以他们不能共享表示， // 并且重复的代码太少，无法保证（warrant）能够从里面抽象出来一个公共类（公共抽象类）。 /** * An Entry maintaining a key and a value. The value may be * changed using the setValue method. This class * facilitates the process of building custom map * implementations. For example, it may be convenient to return * arrays of SimpleEntry instances in method * Map.entrySet().toArray. * 维护一个key与value的Entry。 * 可以使用setValue来修改内部的value值。 * 该类有助于（facilitate）自定义map的构建过程。 * 例如：在方法Map.entrySet().toArray返回SimpleEntry数组可能更方便（convenient）。 * * @since 1.6 */ public static class SimpleEntry implements Entry, java.io.Serializable // 这个Entry接口，是Map接口里的interface Entry { private static final long serialVersionUID = -8499721149061103585L; // 只有两个字段 private final K key; // key作为final，只能赋值一次 private V value; // value可以任意修改 /** * Creates an entry representing a mapping from the specified * key to the specified value. * 创建一个entry，表示从给定key到给定value的映射。 * * @param key the key represented by this entry * @param value the value represented by this entry */ public SimpleEntry(K key, V value) { this.key = key; this.value = value; } /** * Creates an entry representing the same mapping as the * specified entry. * 创建一个entry，表示与给定entry相同的映射。 * * @param entry the entry to copy */ public SimpleEntry(Entry entry) { this.key = entry.getKey(); // 拆解开分别赋值 this.value = entry.getValue(); } /** * Returns the key corresponding to this entry. * 返回该entry关联的key * * @return the key corresponding to this entry */ public K getKey() { return key; } /** * Returns the value corresponding to this entry. * 返回该entry关联的value * * @return the value corresponding to this entry */ public V getValue() { return value; } /** * Replaces the value corresponding to this entry with the specified * value. * 用给定value替换该entry关联的value值。 * * @param value new value to be stored in this entry * 存入entry的新值 * @return the old value corresponding to the entry * 返回旧值 */ public V setValue(V value) { V oldValue = this.value; this.value = value; return oldValue; } /** * Compares the specified object with this entry for equality. * Returns {@code true} if the given object is also a map entry and * the two entries represent the same mapping. More formally, two * entries {@code e1} and {@code e2} represent the same mapping * if * (e1.getKey()==null ? * e2.getKey()==null : * e1.getKey().equals(e2.getKey())) * &amp;&amp; * (e1.getValue()==null ? * e2.getValue()==null : * e1.getValue().equals(e2.getValue())) * This ensures that the {@code equals} method works properly across * different implementations of the {@code Map.Entry} interface. * 比较给定的object与该entry是否相等。 * 如果给定object也是个map，并且这俩map代表相同映射，则返回true。 * 更正式的说法，两个entry：e1与e2,代表相同的映射，当且仅当： * (e1.getKey()==null ? * e2.getKey()==null : * e1.getKey().equals(e2.getKey())) * && * (e1.getValue()==null ? * e2.getValue()==null : * e1.getValue().equals(e2.getValue())) * 这确保了equals方法在不同的Map.Entry接口实现中能够正常工作。 * * @param o object to be compared for equality with this map entry * @return {@code true} if the specified object is equal to this map * entry * @see #hashCode */ public boolean equals(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; return eq(key, e.getKey()) && eq(value, e.getValue()); // 直接通过AbstractMap#eq()方法来简化实现 } /** * Returns the hash code value for this map entry. The hash code * of a map entry {@code e} is defined to be: * (e.getKey()==null ? 0 : e.getKey().hashCode()) ^ * (e.getValue()==null ? 0 : e.getValue().hashCode()) * This ensures that {@code e1.equals(e2)} implies that * {@code e1.hashCode()==e2.hashCode()} for any two Entries * {@code e1} and {@code e2}, as required by the general * contract of {@link Object#hashCode}. * 返回该map entry的hash code值。 * map entry--e的hash code定义如下： * (e.getKey()==null ? 0 : e.getKey().hashCode()) ^ * (e.getValue()==null ? 0 : e.getValue().hashCode()) * （用key的hashCode与value的hashCode做异或操作，作为Entry的hashCode） * 保证了对于任意两个Entry：e1与e2，e1.equals(e2)成立意味着e1.hashCode()==e2.hashCode()， * 这也符合Object.hashCode基本约定要求。（即equals相等hashCode必须相等） * * @return the hash code value for this map entry * @see #equals */ public int hashCode() { return (key == null ? 0 : key.hashCode()) ^ (value == null ? 0 : value.hashCode()); } /** * Returns a String representation of this map entry. This * implementation returns the string representation of this * entry's key followed by the equals character (\"=\") * followed by the string representation of this entry's value. * 返回代表该map entry的String字符串。 * 该实现返回的该entry的key的String表示，后面跟着等号“=”，再跟着entry的value的String表示 * * @return a String representation of this map entry */ public String toString() { return key + \"=\" + value; } } /** * An Entry maintaining an immutable key and value. This class * does not support method setValue. This class may be * convenient in methods that return thread-safe snapshots of * key-value mappings. * 维护一个不可变的key与value的Entry。 * 该类不支持setValue方法。 * 在返回线程安全的key-value映射的快照方法中使用该类可能更方便。 * * @since 1.6 */ public static class SimpleImmutableEntry implements Entry, java.io.Serializable { private static final long serialVersionUID = 7138329143949025153L; private final K key; private final V value; // 与SimpleEntry不同的是，value也是final的 /** * Creates an entry representing a mapping from the specified * key to the specified value. * * @param key the key represented by this entry * @param value the value represented by this entry */ public SimpleImmutableEntry(K key, V value) { this.key = key; this.value = value; } /** * Creates an entry representing the same mapping as the * specified entry. * * @param entry the entry to copy */ public SimpleImmutableEntry(Entry entry) { this.key = entry.getKey(); this.value = entry.getValue(); } /** * Returns the key corresponding to this entry. * * @return the key corresponding to this entry */ public K getKey() { return key; } /** * Returns the value corresponding to this entry. * * @return the value corresponding to this entry */ public V getValue() { return value; } /** * Replaces the value corresponding to this entry with the specified * value (optional operation). This implementation simply throws * UnsupportedOperationException, as this class implements * an immutable map entry. * 该实现替换value会抛出UnsupportedOperationException，作为该类实现的不可变（immutable）map entry。 * * @param value new value to be stored in this entry * @return (Does not return) * @throws UnsupportedOperationException always */ public V setValue(V value) { throw new UnsupportedOperationException(); } /** * Compares the specified object with this entry for equality. * Returns {@code true} if the given object is also a map entry and * the two entries represent the same mapping. More formally, two * entries {@code e1} and {@code e2} represent the same mapping * if * (e1.getKey()==null ? * e2.getKey()==null : * e1.getKey().equals(e2.getKey())) * &amp;&amp; * (e1.getValue()==null ? * e2.getValue()==null : * e1.getValue().equals(e2.getValue())) * This ensures that the {@code equals} method works properly across * different implementations of the {@code Map.Entry} interface. * * @param o object to be compared for equality with this map entry * @return {@code true} if the specified object is equal to this map * entry * @see #hashCode */ public boolean equals(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; return eq(key, e.getKey()) && eq(value, e.getValue()); } /** * Returns the hash code value for this map entry. The hash code * of a map entry {@code e} is defined to be: * (e.getKey()==null ? 0 : e.getKey().hashCode()) ^ * (e.getValue()==null ? 0 : e.getValue().hashCode()) * This ensures that {@code e1.equals(e2)} implies that * {@code e1.hashCode()==e2.hashCode()} for any two Entries * {@code e1} and {@code e2}, as required by the general * contract of {@link Object#hashCode}. * * @return the hash code value for this map entry * @see #equals */ public int hashCode() { return (key == null ? 0 : key.hashCode()) ^ (value == null ? 0 : value.hashCode()); } /** * Returns a String representation of this map entry. This * implementation returns the string representation of this * entry's key followed by the equals character (\"=\") * followed by the string representation of this entry's value. * * @return a String representation of this map entry */ public String toString() { return key + \"=\" + value; } } } "},"Doc/util/Map.java.html":{"url":"Doc/util/Map.java.html","title":"Map.Java","keywords":"","body":"Map /* * Copyright (c) 1997, 2013, Oracle and/or its affiliates. All rights reserved. * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * （使用受条款约束（terms 条款）） * * * * * * * * * * * * * * * * * * * * */ package java.util; import java.util.function.BiConsumer; import java.util.function.BiFunction; import java.util.function.Function; import java.io.Serializable; /** * An object that maps keys to values. A map cannot contain duplicate keys; * each key can map to at most one value. * 将键映射到值的对象。 * map不能包含重复的键；每个key至多对应一个value。 * * This interface takes the place of the Dictionary class, which * was a totally abstract class rather than an interface. * 该接口取代了Dictionary类，Dictionary类是一个抽象类而不是接口。 * * The Map interface provides three collection views, which * allow a map's contents to be viewed as a set of keys, collection of values, * or set of key-value mappings. The order of a map is defined as * the order in which the iterators on the map's collection views return their * elements. Some map implementations, like the TreeMap class, make * specific guarantees as to their order; others, like the HashMap * class, do not. * map接口提供了三种collection视图，允许将map的内容作为一组key，一组value，或者为一组key-value映射。 * map的顺序定义为在map的集合视图上的迭代器返回的元素的顺序。 * 一些map的实现，例如TreeMap类，对顺序有特定的保证；其他的，比如HashMap类就没有。 * * Note: great care must be exercised if mutable objects are used as map * keys. The behavior of a map is not specified if the value of an object is * changed in a manner that affects equals comparisons while the * object is a key in the map. A special case of this prohibition is that it * is not permissible for a map to contain itself as a key. While it is * permissible for a map to contain itself as a value, extreme caution is * advised: the equals and hashCode methods are no longer * well defined on such a map. * 注意：如果用可变的对象作为map的key，必须非常小心。 * 如果对象作为map中的key，它的值以影响equal比较的方式改变时，则不会指定map的行为。（map不会限制key是否是可变对象、可变对象是否发生变化） * 此禁忌（prohibition）的特殊场景为不允许使用该map对象作为该map的key。（只会限制不能把自身作为自身包含元素的key） * 虽然允许将map自身作为自己的value值，但建议格外（extreme 极端）小心（caution 慎重）：（可以把自身作为自身包含元素的value） * 在此map上不再定义equals和hashCode方法。（map没有特殊的equals与hashCode方法，要比较value相同时，需要考虑这一点）（从代码看是定义了的，这个是啥意思？？？） * * All general-purpose map implementation classes should provide two * \"standard\" constructors: a void (no arguments) constructor which creates an * empty map, and a constructor with a single argument of type Map, * which creates a new map with the same key-value mappings as its argument. * In effect, the latter constructor allows the user to copy any map, * producing an equivalent map of the desired class. There is no way to * enforce this recommendation (as interfaces cannot contain constructors) but * all of the general-purpose map implementations in the JDK comply. * 所有通用目的的map实现类都应该支持两种“标准”构造方法： * void（无参数）构造方法，创建空map * 带有map类型的单一参数构造方法，创建带有相同key-value映射作为其参数的新map。 * 实际上，后一个构造方法允许用户拷贝任意map，生成与想要的map等效的map。（将目标map复制成一个新的map） * 没有强制要求执行此建议（作为接口类不能包含构造方法），但是所有在JDK中的通用map的实现都符合该建议。 * * The \"destructive\" methods contained in this interface, that is, the * methods that modify the map on which they operate, are specified to throw * UnsupportedOperationException if this map does not support the * operation. If this is the case, these methods may, but are not required * to, throw an UnsupportedOperationException if the invocation would * have no effect on the map. For example, invoking the {@link #putAll(Map)} * method on an unmodifiable map may, but is not required to, throw the * exception if the map whose mappings are to be \"superimposed\" is empty. * 接口中包含“破坏性”方法，即修改map的操作方法，如果该map不支持该操作，则指定抛出UnsupportedOperationException。 * 如果是下面这种情况：如果调用可能不影响map，该方法可能（但不要求）抛出UnsupportedOperationException。 * 例如，在一个不可修改的map上调用putAll(map)方法，如果该map要“叠加”的映射为空，可能（但不要求）抛出异常 * （叠加就是通过putAll方法给map添加新的映射元素） * * Some map implementations have restrictions on the keys and values they * may contain. For example, some implementations prohibit null keys and * values, and some have restrictions on the types of their keys. Attempting * to insert an ineligible key or value throws an unchecked exception, * typically NullPointerException or ClassCastException. * Attempting to query the presence of an ineligible key or value may throw an * exception, or it may simply return false; some implementations will exhibit * the former behavior and some will exhibit the latter. More generally, * attempting an operation on an ineligible key or value whose completion * would not result in the insertion of an ineligible element into the map may * throw an exception or it may succeed, at the option of the implementation. * Such exceptions are marked as \"optional\" in the specification for this * interface. * 一些map实现类会对它可能包含的key、value进行限制。 * 例如，有些实现禁止null key和value，有些实现限制key的类型。 * 尝试插入不合格（ineligible）key或者value将抛出unchecked异常，通常为NullPointerException或者为ClassCastException。 * 尝试查询不合格的key或者value可能抛出异常，或者可能简单的返回false； * 一些实现可能表现出（exhibit）前一种（former）行为，另一些实现可能表现出后一种行为。 * 更一般的，尝试操作不合格的key或者value，其完成不会导致不合格元素插入到map中，可能会抛出异常，或者成功，这取决于具体实现。 * （就是存在这种情况：元素为不合格元素时，插入操作可能会返回成功，但是元素并未插入） * 在此接口规范中，该异常被标记为“可选”。 * * Many methods in Collections Framework interfaces are defined * in terms of the {@link Object#equals(Object) equals} method. For * example, the specification for the {@link #containsKey(Object) * containsKey(Object key)} method says: \"returns true if and * only if this map contains a mapping for a key k such that * (key==null ? k==null : key.equals(k)).\" This specification should * not be construed to imply that invoking Map.containsKey * with a non-null argument key will cause key.equals(k) to * be invoked for any key k. Implementations are free to * implement optimizations whereby the equals invocation is avoided, * for example, by first comparing the hash codes of the two keys. (The * {@link Object#hashCode()} specification guarantees that two objects with * unequal hash codes cannot be equal.) More generally, implementations of * the various Collections Framework interfaces are free to take advantage of * the specified behavior of underlying {@link Object} methods wherever the * implementor deems it appropriate. * 在Collections Framework（集合框架）的许多方法都是根据（in terms of）equals方法来定义的。 * 例如，containsKey(Object key)方法规范（specification）说：当且仅当该map包含k的映射，使得(key==null ? k==null : key.equals(k))，才返回true。 * 本规范不应被解释为暗示，如果使用非空key参数调用Map.containsKey方法，将导致为任意k调用key.equals(k)方法 * 实现类可以自由的实现优化（optimization），由此（whereby）避免调用equals方法， * 例如，首先比较两个key的hash code。 * （Object#hashCode()方法规范保证两个对象如果hash code不同则对象不相等。） * 更一般的，各种集合框架接口的实现可以自由的利用底层Object方法的指定行为，只要实现者认为合适在哪里用都可以。 * （这段是说明有些集合框架的方法，是基于Object提供的方法来实现的，可以自由选择Object的方法来实现功能） * * Some map operations which perform recursive traversal of the map may fail * with an exception for self-referential instances where the map directly or * indirectly contains itself. This includes the {@code clone()}, * {@code equals()}, {@code hashCode()} and {@code toString()} methods. * Implementations may optionally handle the self-referential scenario, however * most current implementations do not do so. * 一些需要执行map的递归遍历的map操作可能会失败：当map直接或间接包含自身的自引用会有异常。（不能对包含将自身作为元素的map进行递归遍历，可能会死循环） * 这些操作包括clone()、equals()、hashCode()和toString()方法。 * 实现可以选择性的处理自引用的场景（scenario 设想），然而当前大多数实现都没有这样做。 * * This interface is a member of the * * Java Collections Framework. * 该接口属于Java Collections Framework（java集合框架）。 * * @param the type of keys maintained by this map * @param the type of mapped values * * @author Josh Bloch * @see HashMap * @see TreeMap * @see Hashtable * @see SortedMap * @see Collection * @see Set * @since 1.2 */ public interface Map { // Query Operations // 查询操作（我还以为所有的方法外注释都是/***/，原来并不是） /** * Returns the number of key-value mappings in this map. If the * map contains more than Integer.MAX_VALUE elements, returns * Integer.MAX_VALUE. * 返回该map中key-value映射的数量。 * 如果map包含的元素数超过Integer.MAX_VALUE，返回Integer.MAX_VALUE * * @return the number of key-value mappings in this map */ int size(); /** * Returns true if this map contains no key-value mappings. * 如果该map包含的key-value映射为空，返回true。 * * @return true if this map contains no key-value mappings */ boolean isEmpty(); /** * Returns true if this map contains a mapping for the specified * key. More formally, returns true if and only if * this map contains a mapping for a key k such that * (key==null ? k==null : key.equals(k)). (There can be * at most one such mapping.) * 如果该map包含指定key的映射，返回true。 * 更正式的说法，当且仅当该map包含该k的映射，使得满足(key==null ? k==null : key.equals(k))，则返回true。 * （最多可以有一个这样的映射） * （key唯一，最多只有一个） * * @param key key whose presence in this map is to be tested * key参数，测试该key是否存在于该map * @return true if this map contains a mapping for the specified * key * @throws ClassCastException if the key is of an inappropriate type for * this map * 抛出ClassCastException，如果key的类型与该map不符。 * * (optional) * @throws NullPointerException if the specified key is null and this map * does not permit null keys * 抛出NullPointerException，如果指定key是null并且该map不允许非空key * * (optional) */ boolean containsKey(Object key); /** * Returns true if this map maps one or more keys to the * specified value. More formally, returns true if and only if * this map contains at least one mapping to a value v such that * (value==null ? v==null : value.equals(v)). This operation * will probably require time linear in the map size for most * implementations of the Map interface. * 返回true，如果该map有一个或多个key映射到指定的value。 * 更正式的说法，返回true，当且仅当该map包含至少一个到该value v的映射，使得满足(value==null ? v==null : value.equals(v))。 * 对于大多数该Map接口的实现来说，该操作花费的时间可能与map的大小成线性相关。 * * @param value value whose presence in this map is to be tested * @return true if this map maps one or more keys to the * specified value * @throws ClassCastException if the value is of an inappropriate type for * this map * (optional) * @throws NullPointerException if the specified value is null and this * map does not permit null values * 抛出NullPointerException，如果指定value是null并且该map不允许非空value * * (optional) */ boolean containsValue(Object value); /** * Returns the value to which the specified key is mapped, * or {@code null} if this map contains no mapping for the key. * 如果存在指定key的映射，返回对应的value， * 如果不存在指定key的映射，返回null。 * * More formally, if this map contains a mapping from a key * {@code k} to a value {@code v} such that {@code (key==null ? k==null : * key.equals(k))}, then this method returns {@code v}; otherwise * it returns {@code null}. (There can be at most one such mapping.) * 更正式的说法，如果该map包含从键k到值v的映射，使得满足key==null ? k==null : key.equals(k))，则该方法返回v；否则返回null。 * （最多可以有一个这样的映射） * * If this map permits null values, then a return value of * {@code null} does not necessarily indicate that the map * contains no mapping for the key; it's also possible that the map * explicitly maps the key to {@code null}. The {@link #containsKey * containsKey} operation may be used to distinguish these two cases. * 如果该map允许null值，那么返回值为null不再一定暗示该map不包含该key的映射； * 也有可能该map有明确的（explicitly）key到null的映射。 * containsKey操作可以用于区分这两种场景。 * * @param key the key whose associated value is to be returned * key参数，返回该key关联的value * @return the value to which the specified key is mapped, or * {@code null} if this map contains no mapping for the key * @throws ClassCastException if the key is of an inappropriate type for * this map * (optional) * @throws NullPointerException if the specified key is null and this map * does not permit null keys * (optional) */ V get(Object key); // Modification Operations // 修改操作 // 对于标注为可选操作的，都有可能由于不支持抛出UnsupportedOperationException /** * Associates the specified value with the specified key in this map * (optional operation). If the map previously contained a mapping for * the key, the old value is replaced by the specified value. (A map * m is said to contain a mapping for a key k if and only * if {@link #containsKey(Object) m.containsKey(k)} would return * true.) * 在该map中将指定的key与指定的value进行关联（可选操作）。 * 如果map中之前已经包含该key的映射，那么使用指定的值替换旧值。 * （map m包含键k映射，当且仅当m.containsKey(k)返回true） * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with key, or * null if there was no mapping for key. * (A null return can also indicate that the map * previously associated null with key, * if the implementation supports null values.) * 返回值为该key原关联的值，如果该key原来没关联值，返回null。 * （如果实现类支持value为null，那么返回的null也可以表示该key原来的关联值为null） * * @throws UnsupportedOperationException if the put operation * is not supported by this map * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * @throws NullPointerException if the specified key or value is null * and this map does not permit null keys or values * @throws IllegalArgumentException if some property of the specified key * or value prevents it from being stored in this map */ V put(K key, V value); /** * Removes the mapping for a key from this map if it is present * (optional operation). More formally, if this map contains a mapping * from key k to value v such that * (key==null ? k==null : key.equals(k)), that mapping * is removed. (The map can contain at most one such mapping.) * 如果key在该map中存在，从该map中移除该key映射（可选操作） * 更正式的说法，如果该map存在该key到value的映射，使得满足(key==null ? k==null : key.equals(k))，那么移除该映射。 * （该map至多存在一个这样的映射） * * Returns the value to which this map previously associated the key, * or null if the map contained no mapping for the key. * 返回原关联到该key上的value值，如果该map没有包含该key的映射，返回null。 * * If this map permits null values, then a return value of * null does not necessarily indicate that the map * contained no mapping for the key; it's also possible that the map * explicitly mapped the key to null. * 如果该map允许值value为null，那么返回的值是null不再一定表示该map没有包含该key的映射；也有可能map有明确的（explicitly）key到null的映射。 * * The map will not contain a mapping for the specified key once the * call returns. * 一旦调用返回，映射将不包含（没有再，因为以前也可能没有）指定key的映射。 * * @param key key whose mapping is to be removed from the map * @return the previous value associated with key, or * null if there was no mapping for key. * @throws UnsupportedOperationException if the remove operation * is not supported by this map * @throws ClassCastException if the key is of an inappropriate type for * this map * (optional) * @throws NullPointerException if the specified key is null and this * map does not permit null keys * (optional) */ V remove(Object key); // Bulk Operations // 批量操作 /** * Copies all of the mappings from the specified map to this map * (optional operation). The effect of this call is equivalent to that * of calling {@link #put(Object,Object) put(k, v)} on this map once * for each mapping from key k to value v in the * specified map. The behavior of this operation is undefined if the * specified map is modified while the operation is in progress. * 将指定map的所有映射都拷贝到该map（可选操作）。 * 该方法与对指定map的每个key到value映射做一次到该map的put(k, v)操作效果是相同的。 * 如果在执行该操作的过程中指定map被修改了，该执行何种行为是没有定义的。（如果指定map变了，该方法要做啥操作没有特别定义） * * @param m mappings to be stored in this map * @throws UnsupportedOperationException if the putAll operation * is not supported by this map * @throws ClassCastException if the class of a key or value in the * specified map prevents it from being stored in this map * @throws NullPointerException if the specified map is null, or if * this map does not permit null keys or values, and the * specified map contains null keys or values * @throws IllegalArgumentException if some property of a key or value in * the specified map prevents it from being stored in this map */ void putAll(Map m); /** * Removes all of the mappings from this map (optional operation). * The map will be empty after this call returns. * 从该map中移除所有的映射（可选操作）。 * 在执行该方法后，该map将为空。 * * @throws UnsupportedOperationException if the clear operation * is not supported by this map */ void clear(); // Views // 视图 /** * Returns a {@link Set} view of the keys contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own remove operation), the results of * the iteration are undefined. The set supports element removal, * which removes the corresponding mapping from the map, via the * Iterator.remove, Set.remove, * removeAll, retainAll, and clear * operations. It does not support the add or addAll * operations. * 返回该map包含的key的集合（set）视图。 * 该集合由map支持，所以对map的修改会反映在集合上，反之亦然。 * 如果在迭代器遍历集合的过程中该map被修改了（除了迭代器自己的remove操作修改map），迭代的结果是未明确定义的。 * 该集合支持元素移除，即从map中移除相应的映射，元素移除可以通过下面几个方法： * Iterator.remove、Set.remove、removeAll、retainAll、clear * 不支持add与addAll操作。 * * @return a set view of the keys contained in this map */ Set keySet(); /** * Returns a {@link Collection} view of the values contained in this map. * The collection is backed by the map, so changes to the map are * reflected in the collection, and vice-versa. If the map is * modified while an iteration over the collection is in progress * (except through the iterator's own remove operation), * the results of the iteration are undefined. The collection * supports element removal, which removes the corresponding * mapping from the map, via the Iterator.remove, * Collection.remove, removeAll, * retainAll and clear operations. It does not * support the add or addAll operations. * 返回该map包含的value集合视图。 * 该集合由map支持，所以对map的修改会反映在集合上，反之亦然。 * 如果在迭代器遍历集合的过程中该map被修改了（除了迭代器自己的remove操作修改map），迭代的结果是未明确定义的。 * 该集合支持元素移除，即从map中移除相应的（corresponding）映射，元素移除可以通过下面几个方法： * Iterator.remove、Set.remove、removeAll、retainAll、clear * 不支持add与addAll操作。 * * @return a collection view of the values contained in this map */ Collection values(); /** * Returns a {@link Set} view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own remove operation, or through the * setValue operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the Iterator.remove, * Set.remove, removeAll, retainAll and * clear operations. It does not support the * add or addAll operations. * 返回该map包含的映射Set视图。 * 该set集合由map支持，所以对map的修改会反映在集合上，反之亦然。 * 如果在迭代器遍历set的过程中该map被修改了 * （除了迭代器自己的remove操作，或者在迭代器返回的map entry上进行setValue操作修改map）， * 迭代的结果是未明确定义的。 * 该set支持元素移除，即从map中移除相应的（corresponding）映射，元素移除可以通过下面几个方法： * Iterator.remove、Set.remove、removeAll、retainAll和clear。 * 不支持add与addAll操作。 * * @return a set view of the mappings contained in this map */ Set> entrySet(); /** * A map entry (key-value pair). The Map.entrySet method returns * a collection-view of the map, whose elements are of this class. The * only way to obtain a reference to a map entry is from the * iterator of this collection-view. These Map.Entry objects are * valid only for the duration of the iteration; more formally, * the behavior of a map entry is undefined if the backing map has been * modified after the entry was returned by the iterator, except through * the setValue operation on the map entry. * map的entry（实体？？？）（key-value对）。 * Map.entrySet方法返回该map的集合视图，集合的元素类型为该类。 * 获取map entry的唯一方法是通过刚才集合视图的迭代器。 * Map.Entry对象仅在迭代期间有效； * 更正式的说法，如果在迭代器返回entry之后，来源的map被修改了，则map entry的行为是未定义的，除非通过setValue操作map entry。 * * @see Map#entrySet() * @since 1.2 */ interface Entry { /** * Returns the key corresponding to this entry. * 返回该entry对应的key * * @return the key corresponding to this entry * @throws IllegalStateException implementations may, but are not * required to, throw this exception if the entry has been * removed from the backing map. */ K getKey(); /** * Returns the value corresponding to this entry. If the mapping * has been removed from the backing map (by the iterator's * remove operation), the results of this call are undefined. * 返回该entry对应的value。 * 如果该映射关系从来源map移除（通过迭代器的remove操作），该调用结果是未定义。 * * @return the value corresponding to this entry * @throws IllegalStateException implementations may, but are not * required to, throw this exception if the entry has been * removed from the backing map. */ V getValue(); /** * Replaces the value corresponding to this entry with the specified * value (optional operation). (Writes through to the map.) The * behavior of this call is undefined if the mapping has already been * removed from the map (by the iterator's remove operation). * 使用给定的value替换该entry对应的value（可选操作）。（也会写入到map） * 如果该映射已经从map中移除了（通过迭代器的remove操作），该调用行为未定义。 * * @param value new value to be stored in this entry * @return old value corresponding to the entry * 返回值该entry对应的旧值 * @throws UnsupportedOperationException if the put operation * is not supported by the backing map * @throws ClassCastException if the class of the specified value * prevents it from being stored in the backing map * @throws NullPointerException if the backing map does not permit * null values, and the specified value is null * @throws IllegalArgumentException if some property of this value * prevents it from being stored in the backing map * @throws IllegalStateException implementations may, but are not * required to, throw this exception if the entry has been * removed from the backing map. */ V setValue(V value); /** * Compares the specified object with this entry for equality. * Returns true if the given object is also a map entry and * the two entries represent the same mapping. More formally, two * entries e1 and e2 represent the same mapping * if * (e1.getKey()==null ? * e2.getKey()==null : e1.getKey().equals(e2.getKey())) &amp;&amp; * (e1.getValue()==null ? * e2.getValue()==null : e1.getValue().equals(e2.getValue())) * * This ensures that the equals method works properly across * different implementations of the Map.Entry interface. * 比较给定的对象与该entry是否相等。 * 返回true，如果给定的对象也是一个map的entry，并且这两个entry代表相同的映射。 * 更正式的说法，两个entry：e1与e2代表相同映射的定义为： * (e1.getKey()==null ? * e2.getKey()==null : e1.getKey().equals(e2.getKey())) && * (e1.getValue()==null ? * e2.getValue()==null : e1.getValue().equals(e2.getValue())) * （比较分为两部分，要保证两个entry的key与value都相等） * 这确保了equals方法能够在不同的Map.Entry接口实现中正常工作。 * * @param o object to be compared for equality with this map entry * @return true if the specified object is equal to this map * entry */ boolean equals(Object o); /** * Returns the hash code value for this map entry. The hash code * of a map entry e is defined to be: * (e.getKey()==null ? 0 : e.getKey().hashCode()) ^ * (e.getValue()==null ? 0 : e.getValue().hashCode()) * * This ensures that e1.equals(e2) implies that * e1.hashCode()==e2.hashCode() for any two Entries * e1 and e2, as required by the general * contract of Object.hashCode. * 返回该map entry的hash code值。 * map entry--e的hash code定义如下： * (e.getKey()==null ? 0 : e.getKey().hashCode()) ^ * (e.getValue()==null ? 0 : e.getValue().hashCode()) * （用key的hashCode与value的hashCode做异或操作，作为Entry的hashCode） * 保证了对于任意两个Entry：e1与e2，e1.equals(e2)成立意味着e1.hashCode()==e2.hashCode()， * 这也符合Object.hashCode基本约定要求。（即equals相等hashCode必须相等） * * @return the hash code value for this map entry * @see Object#hashCode() * @see Object#equals(Object) * @see #equals(Object) */ int hashCode(); /** * Returns a comparator that compares {@link Map.Entry} in natural order on key. * 返回一个比较器，在key上按自然顺序比较Map.Entry * * The returned comparator is serializable and throws {@link * NullPointerException} when comparing an entry with a null key. * 返回的comparator是可序列化的，当entry与为null的key进行比较时，抛出NullPointerException * * @param the {@link Comparable} type of then map keys * @param the type of the map values * @return a comparator that compares {@link Map.Entry} in natural order on key. * @see Comparable * @since 1.8 */ public static , V> Comparator> comparingByKey() { // 对于泛型方法的定义：public/private等 static 方法域泛型 返回值 方法名(入参) // , V> 这一块是方法域泛型，用于限定传入参数的类型，当然，传入参数没泛型这块有没有都没问题 return (Comparator> & Serializable) (c1, c2) -> c1.getKey().compareTo(c2.getKey()); // 通过Comparable的compareTo方法比较 // 返回值是个Comparator的匿名类实例，涉及到函数式接口，(c1, c2) -> c1.getKey().compareTo(c2.getKey())是对接口类唯一的抽象方法的实现 } /** * Returns a comparator that compares {@link Map.Entry} in natural order on value. * 返回一个比较器，在value上按自然顺序比较Map.Entry * * The returned comparator is serializable and throws {@link * NullPointerException} when comparing an entry with null values. * 返回的comparator是可序列化的，当entry与为null的value进行比较时，抛出NullPointerException * * @param the type of the map keys * @param the {@link Comparable} type of the map values * @return a comparator that compares {@link Map.Entry} in natural order on value. * @see Comparable * @since 1.8 */ public static > Comparator> comparingByValue() { return (Comparator> & Serializable) (c1, c2) -> c1.getValue().compareTo(c2.getValue()); } /** * Returns a comparator that compares {@link Map.Entry} by key using the given * {@link Comparator}. * 返回一个比较器，在key上按给定的Comparator比较Map.Entry * * The returned comparator is serializable if the specified comparator * is also serializable. * 如果给定的comparator是可序列化的，返回的comparator也是可序列化的 * * @param the type of the map keys * @param the type of the map values * @param cmp the key {@link Comparator} * @return a comparator that compares {@link Map.Entry} by the key. * @since 1.8 */ public static Comparator> comparingByKey(Comparator cmp) { Objects.requireNonNull(cmp); // JDK1.7 新增的Objects，判断cmp如果为null则抛出异常。 return (Comparator> & Serializable) (c1, c2) -> cmp.compare(c1.getKey(), c2.getKey()); // 通过Comparator的compare比较 } /** * Returns a comparator that compares {@link Map.Entry} by value using the given * {@link Comparator}. * 返回一个比较器，在value上按给定的Comparator比较Map.Entry * * The returned comparator is serializable if the specified comparator * is also serializable. * 如果给定的comparator是可序列化的，返回的comparator也是可序列化的 * * @param the type of the map keys * @param the type of the map values * @param cmp the value {@link Comparator} * @return a comparator that compares {@link Map.Entry} by the value. * @since 1.8 */ public static Comparator> comparingByValue(Comparator cmp) { Objects.requireNonNull(cmp); return (Comparator> & Serializable) (c1, c2) -> cmp.compare(c1.getValue(), c2.getValue()); } } // Comparison and hashing // 比较和hash /** * Compares the specified object with this map for equality. Returns * true if the given object is also a map and the two maps * represent the same mappings. More formally, two maps m1 and * m2 represent the same mappings if * m1.entrySet().equals(m2.entrySet()). This ensures that the * equals method works properly across different implementations * of the Map interface. * 比较给定的对象与该map是否相等。 * 如果给定的对象是map并且这两个map表示相同的映射，返回true。 * 更正式的说法，两个map：m1与m2代表相同的映射，需要满足以下条件： * m1.entrySet().equals（m2.entrySet())。 * 这确保了equals方法能够在不同的Map接口实现类中正常工作。 * * @param o object to be compared for equality with this map * @return true if the specified object is equal to this map */ boolean equals(Object o); /** * Returns the hash code value for this map. The hash code of a map is * defined to be the sum of the hash codes of each entry in the map's * entrySet() view. This ensures that m1.equals(m2) * implies that m1.hashCode()==m2.hashCode() for any two maps * m1 and m2, as required by the general contract of * {@link Object#hashCode}. * 返回该map的hash code。 * map的hash code是通过该map下的entrySet()视图中每个entry的hash code求和得到的。 * 这确保了对于任意的m1.equals(m2)意味着m1.hashCode()==m2.hashCode()，正如hashCode的约定所要求的那样 * * @return the hash code value for this map * @see Map.Entry#hashCode() * @see Object#equals(Object) * @see #equals(Object) */ int hashCode(); // Defaultable methods // 可默认方法 /** * Returns the value to which the specified key is mapped, or * {@code defaultValue} if this map contains no mapping for the key. * 返回给定key映射的value值，如果map内没包含该key的映射，返回defaultValue * * @implSpec * 默认实现行为规范 * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * * @param key the key whose associated value is to be returned * @param defaultValue the default mapping of the key * @return the value to which the specified key is mapped, or * {@code defaultValue} if this map contains no mapping for the key * @throws ClassCastException if the key is of an inappropriate type for * this map * (optional) * @throws NullPointerException if the specified key is null and this map * does not permit null keys * (optional) * @since 1.8 */ default V getOrDefault(Object key, V defaultValue) { V v; return (((v = get(key)) != null) || containsKey(key)) // 先get，如果能拿到就返回，如果为null需要再判断containsKey ? v : defaultValue; } /** * Performs the given action for each entry in this map until all entries * have been processed or the action throws an exception. Unless * otherwise specified by the implementing class, actions are performed in * the order of entry set iteration (if an iteration order is specified.) * Exceptions thrown by the action are relayed to the caller. * 对在该map内的每一个entry执行给定的操作，直到所有的entry被处理或者操作抛出异常。 * 除非实现类另有规定（如果指定了迭代顺序），否则将按照entry集合迭代的顺序执行操作。 * 操作抛出的异常将转发给调用者。 * * @implSpec * The default implementation is equivalent to, for this {@code map}: * {@code * for (Map.Entry entry : map.entrySet()) * action.accept(entry.getKey(), entry.getValue()); * } * 该方法的默认实现与上面的map操作相等 * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * * @param action The action to be performed for each entry * @throws NullPointerException if the specified action is null * @throws ConcurrentModificationException if an entry is found to be * removed during iteration * @since 1.8 */ default void forEach(BiConsumer action) { Objects.requireNonNull(action); for (Map.Entry entry : entrySet()) { K k; V v; try { k = entry.getKey(); v = entry.getValue(); } catch(IllegalStateException ise) { // 通过entry来getKey()、getValue()，会因为依赖的map修改导致获取异常 // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); } action.accept(k, v); } } /** * Replaces each entry's value with the result of invoking the given * function on that entry until all entries have been processed or the * function throws an exception. Exceptions thrown by the function are * relayed to the caller. * 通过调用给定的方法替换每个entry的value值，直到所有entry被处理完或者方法抛出异常。 * 方法抛出的异常被转发给调用者。 * * @implSpec * The default implementation is equivalent to, for this {@code map}: * {@code * for (Map.Entry entry : map.entrySet()) * entry.setValue(function.apply(entry.getKey(), entry.getValue())); * } * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * * @param function the function to apply to each entry * @throws UnsupportedOperationException if the {@code set} operation * is not supported by this map's entry set iterator. * @throws ClassCastException if the class of a replacement value * prevents it from being stored in this map * @throws NullPointerException if the specified function is null, or the * specified replacement value is null, and this map does not permit null * values * @throws ClassCastException if a replacement value is of an inappropriate * type for this map * (optional) * @throws NullPointerException if function or a replacement value is null, * and this map does not permit null keys or values * (optional) * @throws IllegalArgumentException if some property of a replacement value * prevents it from being stored in this map * (optional) * @throws ConcurrentModificationException if an entry is found to be * removed during iteration * @since 1.8 */ default void replaceAll(BiFunction function) { Objects.requireNonNull(function); for (Map.Entry entry : entrySet()) { K k; V v; try { k = entry.getKey(); v = entry.getValue(); } catch(IllegalStateException ise) { // 好像所有都是异常的缩写 // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); // 抛出entry指向的对象被删除导致的并发修改异常 } // ise thrown from function is not a cme. v = function.apply(k, v); try { entry.setValue(v); } catch(IllegalStateException ise) { // this usually means the entry is no longer in the map. throw new ConcurrentModificationException(ise); } } } /** * If the specified key is not already associated with a value (or is mapped * to {@code null}) associates it with the given value and returns * {@code null}, else returns the current value. * 如果指定的key没有关联到value（或者映射为null），那么将该key与指定的value关联，并返回null。 * 否则返回该key当前关联的value值 * * @implSpec * The default implementation is equivalent to, for this {@code * map}: * * {@code * V v = map.get(key); * if (v == null) * v = map.put(key, value); * * return v; * } * 该方法与上面这段代码等价 * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with the specified key, or * {@code null} if there was no mapping for the key. * (A {@code null} return can also indicate that the map * previously associated {@code null} with the key, * if the implementation supports null values.) * （对于支持value为null的map，返回null有两种含义：不存在该key的映射，或者原映射value为null） * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * (optional) * @throws ClassCastException if the key or value is of an inappropriate * type for this map * (optional) * @throws NullPointerException if the specified key or value is null, * and this map does not permit null keys or values * (optional) * @throws IllegalArgumentException if some property of the specified key * or value prevents it from being stored in this map * (optional) * @since 1.8 */ default V putIfAbsent(K key, V value) { // putIfAbsent 设置如果不存在 V v = get(key); if (v == null) { v = put(key, value); } return v; } /** * Removes the entry for the specified key only if it is currently * mapped to the specified value. * 根据指定的key移除entry，当且仅当该key当前映射值为给定的value值。 * * @implSpec * The default implementation is equivalent to, for this {@code map}: * * {@code * if (map.containsKey(key) && Objects.equals(map.get(key), value)) { * map.remove(key); * return true; * } else * return false; * } * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * * @param key key with which the specified value is associated * @param value value expected to be associated with the specified key * @return {@code true} if the value was removed * @throws UnsupportedOperationException if the {@code remove} operation * is not supported by this map * (optional) * @throws ClassCastException if the key or value is of an inappropriate * type for this map * (optional) * @throws NullPointerException if the specified key or value is null, * and this map does not permit null keys or values * (optional) * @since 1.8 */ default boolean remove(Object key, Object value) { Object curValue = get(key); // 根据key找到当前value值（注意get方法对key为null的操作），如果get不到会返回null if (!Objects.equals(curValue, value) || // 使用Objects封装的equals方法比较两个对象是否相等（null安全）：(a == b) || (a != null && a.equals(b)) (curValue == null && !containsKey(key))) { return false; // 如果指定key当前值与给定值不相等，或者当前值为null并且不包含指定key，则返回false。（这里判断curValue == null是为了效率？？？） } remove(key); // 执行Map的抽象方法 return true; } /** * Replaces the entry for the specified key only if currently * mapped to the specified value. * 根据指定的key替换entry，当且仅当该key当前映射值为给定的value值。 * * @implSpec * The default implementation is equivalent to, for this {@code map}: * * {@code * if (map.containsKey(key) && Objects.equals(map.get(key), value)) { * map.put(key, newValue); * return true; * } else * return false; * } * * The default implementation does not throw NullPointerException * for maps that do not support null values if oldValue is null unless * newValue is also null. * 如果对于不支持value为null的map的oldValue为null，则该方法默认实现不会抛出NullPointerException，除非newValue也是null。 * （好奇oldValue是如何为null的，难道Map的实现允许动态调整是否支持value为null？？？） * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * * @param key key with which the specified value is associated * @param oldValue value expected to be associated with the specified key * @param newValue value to be associated with the specified key * @return {@code true} if the value was replaced * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * (optional) * @throws ClassCastException if the class of a specified key or value * prevents it from being stored in this map * @throws NullPointerException if a specified key or newValue is null, * and this map does not permit null keys or values * @throws NullPointerException if oldValue is null and this map does not * permit null values * (optional) * @throws IllegalArgumentException if some property of a specified key * or value prevents it from being stored in this map * @since 1.8 */ default boolean replace(K key, V oldValue, V newValue) { Object curValue = get(key); if (!Objects.equals(curValue, oldValue) || (curValue == null && !containsKey(key))) { return false; // 如果指定key当前值与给定值不相等，或者当前值为null并且不包含指定key，则返回false。（这里判断curValue == null是为了效率？？？） } put(key, newValue); // 执行Map的抽象方法 return true; } /** * Replaces the entry for the specified key only if it is * currently mapped to some value. * 根据指定的key替换entry，当且仅当该key当前映射值为某个值。 * （当且仅当map中存在该key的映射，不管key映射的值是多少） * * @implSpec * The default implementation is equivalent to, for this {@code map}: * * {@code * if (map.containsKey(key)) { * return map.put(key, value); * } else * return null; * } * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * * @param key key with which the specified value is associated * @param value value to be associated with the specified key * @return the previous value associated with the specified key, or * {@code null} if there was no mapping for the key. * (A {@code null} return can also indicate that the map * previously associated {@code null} with the key, * if the implementation supports null values.) * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * (optional) * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * (optional) * @throws NullPointerException if the specified key or value is null, * and this map does not permit null keys or values * @throws IllegalArgumentException if some property of the specified key * or value prevents it from being stored in this map * @since 1.8 */ default V replace(K key, V value) { V curValue; if (((curValue = get(key)) != null) || containsKey(key)) { // 这里先拿curValue来判断，是因为curValue是必拿的，因为返回值为curValue curValue = put(key, value); } return curValue; } /** * If the specified key is not already associated with a value (or is mapped * to {@code null}), attempts to compute its value using the given mapping * function and enters it into this map unless {@code null}. * 如果指定的key没有关联到value（或者映射为null），尝试使用给定的映射方法计算value值，若计算值不为null，则设置为该key映射的value值。 * * If the function returns {@code null} no mapping is recorded. If * the function itself throws an (unchecked) exception, the * exception is rethrown, and no mapping is recorded. The most * common usage is to construct a new object serving as an initial * mapped value or memoized result, as in: * 如果方法返回null，那么不做任何映射记录（不会把新值映射给key）。 * 如果方法自身抛出（未检查）异常，则在此方法中重新抛出该异常，并且不做任何映射记录。 * 大多数用法是构建一个新对象作为初始化映射值或者记忆结果，像下面这样： * * {@code * map.computeIfAbsent(key, k -> new Value(f(k))); * } * * Or to implement a multi-value map, {@code Map>}, * supporting multiple values per key: * 或者实现一个多value的map，Map>支持单个key映射多value * * {@code * map.computeIfAbsent(key, k -> new HashSet()).add(v); * } * * * @implSpec * The default implementation is equivalent to the following steps for this * {@code map}, then returning the current value or {@code null} if now * absent: * * {@code * if (map.get(key) == null) { * V newValue = mappingFunction.apply(key); * if (newValue != null) * map.put(key, newValue); * } * } * 默认实现如上，返回结果为**当前value**（当前value可能是非null的旧值value，也可能是计算后非null的value），如果当前映射不存在返回null（function计算为null）。 * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. In particular, all implementations of * subinterface {@link java.util.concurrent.ConcurrentMap} must document * whether the function is applied once atomically only if the value is not * present. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * 特别是（in particular），子接口java.util.concurrent.ConcurrentMap的所有实现，必须记录该方法是否仅在value不存在时支持以原子性操作执行一次。 * * @param key key with which the specified value is to be associated * @param mappingFunction the function to compute a value * @return the current (existing or computed) value associated with * the specified key, or null if the computed value is null * 返回当前value值（当前value值有两种情况：1、key对应的原value不为null，2、function计算出的不为null的新value） * 如果计算结果为null，返回null。 * @throws NullPointerException if the specified key is null and * this map does not support null keys, or the mappingFunction * is null * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * (optional) * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * (optional) * @since 1.8 */ default V computeIfAbsent(K key, Function mappingFunction) { Objects.requireNonNull(mappingFunction); // 判断给定的function是否为null V v; if ((v = get(key)) == null) { V newValue; if ((newValue = mappingFunction.apply(key)) != null) { put(key, newValue); // 只有在计算结果非null的时候才设置新值value return newValue; } } return v; } /** * If the value for the specified key is present and non-null, attempts to * compute a new mapping given the key and its current mapped value. * 如果给定的key关联的value存在，并且非null，尝试计算新的value值，作为给定的key映射value。 * * If the function returns {@code null}, the mapping is removed. If the * function itself throws an (unchecked) exception, the exception is * rethrown, and the current mapping is left unchanged. * 如果方法返回null，指定key的映射会被移除。 * 如果方法自身抛出（未检查）异常，异常会被该方法重新抛出，并且指定key的映射保持不变。 * * (源码中这个*就是凸出来的) * @implSpec * The default implementation is equivalent to performing the following * steps for this {@code map}, then returning the current value or * {@code null} if now absent: * * {@code * if (map.get(key) != null) { * V oldValue = map.get(key); * V newValue = remappingFunction.apply(key, oldValue); * if (newValue != null) * map.put(key, newValue); * else * map.remove(key); * } * } * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. In particular, all implementations of * subinterface {@link java.util.concurrent.ConcurrentMap} must document * whether the function is applied once atomically only if the value is not * present. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * 特别是（in particular），子接口java.util.concurrent.ConcurrentMap的所有实现，必须记录该方法是否仅在value不存在时支持以原子性操作执行一次。 * * @param key key with which the specified value is to be associated * @param remappingFunction the function to compute a value * @return the new value associated with the specified key, or null if none * 返回新的value，如果计算结果为null，返回null * @throws NullPointerException if the specified key is null and * this map does not support null keys, or the * remappingFunction is null * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * (optional) * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * (optional) * @since 1.8 */ default V computeIfPresent(K key, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); V oldValue; if ((oldValue = get(key)) != null) { V newValue = remappingFunction.apply(key, oldValue); // 用旧值计算新值 if (newValue != null) { put(key, newValue); // 如果新值不为null，则设置该key对应的新值，并返回新值 return newValue; } else { remove(key); // 如果新值为null，则删除该key的映射，并返回null return null; } } else { return null; // 如果旧值为null，返回null } } /** * Attempts to compute a mapping for the specified key and its current * mapped value (or {@code null} if there is no current mapping). For * example, to either create or append a {@code String} msg to a value * mapping: * 尝试计算给定key与其当前映射的value的映射（如果当前没有映射，则为null）。 * （通俗的说法，就是用key与它的当前value值进行计算，得到新值value） * 例如，创建或附加一个String类型的msg到一个value映射： * * {@code * map.compute(key, (k, v) -> (v == null) ? msg : v.concat(msg))} * (Method {@link #merge merge()} is often simpler to use for such purposes.) * （merge方法通常就用于将此类操作简化） * * If the function returns {@code null}, the mapping is removed (or * remains absent if initially absent). If the function itself throws an * (unchecked) exception, the exception is rethrown, and the current mapping * is left unchanged. * 如果方法返回null，该映射删除（或者如果最初不存在，则保留不存在）。（原来没有映射关系，就不做删除操作） * 如果计算方法自身抛出（未检查）异常，该方法重新抛出异常，并且指定key的映射保持不变。 * * @implSpec * The default implementation is equivalent to performing the following * steps for this {@code map}, then returning the current value or * {@code null} if absent: * * {@code * V oldValue = map.get(key); * V newValue = remappingFunction.apply(key, oldValue); * if (oldValue != null ) { * if (newValue != null) * map.put(key, newValue); * else * map.remove(key); * } else { * if (newValue != null) * map.put(key, newValue); * else * return null; * } * } * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. In particular, all implementations of * subinterface {@link java.util.concurrent.ConcurrentMap} must document * whether the function is applied once atomically only if the value is not * present. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * 特别是（in particular），子接口java.util.concurrent.ConcurrentMap的所有实现，必须记录该方法是否仅在value不存在时支持以原子性操作执行一次。 * * @param key key with which the specified value is to be associated * @param remappingFunction the function to compute a value * @return the new value associated with the specified key, or null if none * @throws NullPointerException if the specified key is null and * this map does not support null keys, or the * remappingFunction is null * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * (optional) * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * (optional) * @since 1.8 */ default V compute(K key, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); V oldValue = get(key); // 获取给定key的旧值value V newValue = remappingFunction.apply(key, oldValue); // 用key与旧值value计算新值value if (newValue == null) { // delete mapping if (oldValue != null || containsKey(key)) { // 如果新值为null，并且key映射存在（有非null旧值，或者旧值为null时key存在（key-null）） // something to remove remove(key); // 移除key的映射关系，返回null return null; } else { // 如果新值为null，并且key映射不存在，啥也不做，返回null // nothing to do. Leave things as they were. return null; } } else { // add or replace old mapping put(key, newValue); // 如果新值不为null，设置该key映射到新值value return newValue; } } /** * If the specified key is not already associated with a value or is * associated with null, associates it with the given non-null value. * Otherwise, replaces the associated value with the results of the given * remapping function, or removes if the result is {@code null}. This * method may be of use when combining multiple mapped values for a key. * For example, to either create or append a {@code String msg} to a * value mapping: * 如果给定的key没有关联value，或者关联的value为null，则将该key关联到给定的非null value。 * 否则，用给定的remapping方法计算结果替换原关联值，如果计算结果为null，则删除该key的映射。（用旧值与给定值计算新值） * 当key组合映射到多个value上时，该方法可能有用。 * 例如，创建或附件一个String类型的msg到value的映射： * * {@code * map.merge(key, msg, String::concat) * } * * If the function returns {@code null} the mapping is removed. If the * function itself throws an (unchecked) exception, the exception is * rethrown, and the current mapping is left unchanged. * 如果方法返回null，该映射删除。 * 如果计算方法自身抛出（未检查）异常，该方法重新抛出异常，并且指定key的映射保持不变。 * * @implSpec * The default implementation is equivalent to performing the following * steps for this {@code map}, then returning the current value or * {@code null} if absent: * * {@code * V oldValue = map.get(key); * V newValue = (oldValue == null) ? value : * remappingFunction.apply(oldValue, value); * if (newValue == null) * map.remove(key); * else * map.put(key, newValue); * } * * The default implementation makes no guarantees about synchronization * or atomicity properties of this method. Any implementation providing * atomicity guarantees must override this method and document its * concurrency properties. In particular, all implementations of * subinterface {@link java.util.concurrent.ConcurrentMap} must document * whether the function is applied once atomically only if the value is not * present. * 该方法默认实现不保证同步或者原子性属性。 * 任何提供原子性保证的实现必须重写（覆盖）此方法并记录下它的并发属性。 * 特别是（in particular），子接口java.util.concurrent.ConcurrentMap的所有实现，必须记录该方法是否仅在value不存在时支持以原子性操作执行一次。 * * @param key key with which the resulting value is to be associated * @param value the non-null value to be merged with the existing value * associated with the key or, if no existing value or a null value * is associated with the key, to be associated with the key * @param remappingFunction the function to recompute a value if present * @return the new value associated with the specified key, or null if no * value is associated with the key * 返回关联到给定key的新值value，如果没有关联到该key的value，返回null * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * (optional) * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * (optional) * @throws NullPointerException if the specified key is null and this map * does not support null keys or the value or remappingFunction is * null * @since 1.8 */ default V merge(K key, V value, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); // 给定值不能为null V oldValue = get(key); V newValue = (oldValue == null) ? value : remappingFunction.apply(oldValue, value); // 用旧值与给定值计算新值 if(newValue == null) { // 如果新值为null，删除映射关系 remove(key); } else { put(key, newValue); // 否则设置key映射到新值 } return newValue; // 返回新值 } } "},"Doc/util/concurrent/AbstractExecutorService.java.html":{"url":"Doc/util/concurrent/AbstractExecutorService.java.html","title":"AbstractExecutorService.Java","keywords":"","body":"AbstractExecutorService /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; import java.util.*; /** * Provides default implementations of {@link ExecutorService} * execution methods. This class implements the {@code submit}, * {@code invokeAny} and {@code invokeAll} methods using a * {@link RunnableFuture} returned by {@code newTaskFor}, which defaults * to the {@link FutureTask} class provided in this package. For example, * the implementation of {@code submit(Runnable)} creates an * associated {@code RunnableFuture} that is executed and * returned. Subclasses may override the {@code newTaskFor} methods * to return {@code RunnableFuture} implementations other than * {@code FutureTask}. * 提供ExecutorService执行方法的默认实现。 * 该类通过使用RunnableFuture返回的newTaskFor（newTaskFor默认提供的返回对象为该包下的FutureTask类实例）实现了submit、invokeAny和invokeAll方法， * 例如，实现的submit(Runnable)方法，就创建一个关联的RunnableFuture对象，用于执行任务与返回。 * 子类可以覆盖newTaskFor方法，以返回RunnableFuture的实现，而不是FutureTask的实现。 * * Extension example. Here is a sketch of a class * that customizes {@link ThreadPoolExecutor} to use * a {@code CustomTask} class instead of the default {@code FutureTask}: * 扩展样例。 * 这有一个草图（sketch），一个自定义的ThreadPoolExecutor使用CustomTask类替代默认的FutureTask类： * * {@code * public class CustomThreadPoolExecutor extends ThreadPoolExecutor { * * static class CustomTask implements RunnableFuture {...} * * protected RunnableFuture newTaskFor(Callable c) { * return new CustomTask(c); // AbstractExecutorService这里是返回一个new FutureTask，该自定义类返回了一个new CustomTask，只要自定义的类实现了RunnableFuture接口就行。 * } * protected RunnableFuture newTaskFor(Runnable r, V v) { * return new CustomTask(r, v); * } * // ... add constructors, etc. * }} * * @since 1.5 * @author Doug Lea */ public abstract class AbstractExecutorService implements ExecutorService { /** * Returns a {@code RunnableFuture} for the given runnable and default * value. * 返回RunnableFture，通过给定的runnable与默认返回值构建。 * * @param runnable the runnable task being wrapped * runnable 被包装的runnable任务 * @param value the default value for the returned future * value 默认的future返回值 * @param the type of the given value * 给定返回值的类型 * @return a {@code RunnableFuture} which, when run, will run the * underlying runnable and which, as a {@code Future}, will yield * the given value as its result and provide for cancellation of * the underlying task * 返回一个RunnableFuture，在运行时会执行底层的runnable， * 并且作为Future，将使用给定的值作为返回结果，并提供底层任务的取消（方法） * @since 1.6 */ protected RunnableFuture newTaskFor(Runnable runnable, T value) { return new FutureTask(runnable, value); // FutureTask会调用Executors#callable方法，将runnable+value转化为callable。如果runnable为null，抛出空指针异常 } /** * Returns a {@code RunnableFuture} for the given callable task. * 返回Runnable，通过给定的callable任务构建。 * * @param callable the callable task being wrapped * @param the type of the callable's result * @return a {@code RunnableFuture} which, when run, will call the * underlying callable and which, as a {@code Future}, will yield * the callable's result as its result and provide for * cancellation of the underlying task * @since 1.6 */ protected RunnableFuture newTaskFor(Callable callable) { return new FutureTask(callable); // 如果callable为null，抛出空指针异常。否则创建FutureTask，callable=callable，state=NEW } /** * 提交返回值为null的Runnable任务 * @throws RejectedExecutionException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public Future submit(Runnable task) { if (task == null) throw new NullPointerException(); // 如果提交的任务为null，抛出异常 RunnableFuture ftask = newTaskFor(task, null); // 将任务转化为FutureTask execute(ftask); // 这里的execute是Executor接口类定义的方法，具体的调用是实现类做的，比如ThreadPoolExecutor#execute(Runnable command) return ftask; // 这里将提交的RunnableFuture对象返回了（是想拿这个Future来获取结果） } /** * 提交带有指定返回值的Runnable任务 * @throws RejectedExecutionException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public Future submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); RunnableFuture ftask = newTaskFor(task, result); execute(ftask); // 这里是交给实现类做的，比如ThreadPoolExecutor#execute return ftask; } /** * 提交callable任务 * @throws RejectedExecutionException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public Future submit(Callable task) { if (task == null) throw new NullPointerException(); RunnableFuture ftask = newTaskFor(task); execute(ftask); // 这里是交给实现类做的，比如ThreadPoolExecutor#execute return ftask; } /** * the main mechanics of invokeAny. * invokeAny的主要机制 * （执行给定的任务集合，返回其中一个成功完成的任务结果（即没有抛出异常），如果有的话。） */ private T doInvokeAny(Collection> tasks, boolean timed, long nanos) // tasks为要提交的任务集合，限时执行（该限时为拿到所有执行结果的总限时） throws InterruptedException, ExecutionException, TimeoutException { if (tasks == null) throw new NullPointerException(); int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); // 如果任务集合里没有任务，抛出IllegalArgumentException ArrayList> futures = new ArrayList>(ntasks); // 创建初识容量为任务数长度的空列表。这里使用future是为了能够方便操作任务，比如cancel等操作。 ExecutorCompletionService ecs = new ExecutorCompletionService(this); // 用AbstractExecutorService创建ExecutorCompletionService（ecs），用于执行任务集，并将完成的任务保存在完成队列中 // For efficiency, especially in executors with limited // parallelism, check to see if previously submitted tasks are // done before submitting more of them. This interleaving // plus the exception mechanics account for messiness of main // loop. // 为提高效率（efficiency），尤其是在并行性（parallelism）有限的执行器中（executors）， // 在更多的任务提交之前检查之前提交的任务是否已完成。 // 这种交错（interleaving 交叉）加上异常机制解释了（account for）主循环的混乱。 try { // Record exceptions so that if we fail to obtain any // result, we can throw the last exception we got. // 记录异常，如果无法获取任何结果，可以抛出获取到的最后一个异常。 ExecutionException ee = null; final long deadline = timed ? System.nanoTime() + nanos : 0L; // 计算限时截止时间 Iterator> it = tasks.iterator(); // Start one task for sure; the rest incrementally // 确定开始的任务，其余逐渐增加 futures.add(ecs.submit(it.next())); // ecs.submit将任务提交到Executor中执行，返回的RunnableFuture，是通过AES（也就是本类）的newTaskFor方法创建的。 --ntasks; // 执行了一个任务，等待任务数-1 int active = 1; // 活跃的任务数置为1。活跃任务=正在执行的任务 for (;;) { Future f = ecs.poll(); // 获取完成队列队首元素，如果没有则返回null（不会阻塞，take或者poll(时限)才会阻塞） if (f == null) { // f == null表示没有拿到队首元素，说明当前没有任务完成结果 if (ntasks > 0) { --ntasks; futures.add(ecs.submit(it.next())); // 如果任务没执行完，那么将下一个任务加入ecs中执行（注意使用迭代器实现获取下一个任务）。任务数-1，活跃任务数+1 ++active; } else if (active == 0) break; // 如果活跃任务数为0，表示所有任务执行完毕，退出 else if (timed) { f = ecs.poll(nanos, TimeUnit.NANOSECONDS); // 到了这里，尚未执行的任务=0，活跃的任务>0，只需要等任务完成了。如果限时等待，就用ecs.poll(时限)的方法等，等不到抛异常 if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); // 注意这里，如果等到了一个，剩余等待时间需要减去当前已用时间 } else f = ecs.take(); // 如果不限时，那就一直等了 } // 到了这里可以看到，最多有两个任务在并行执行 if (f != null) { // 如果有任务完成，拿到完成结果。（注意这个f可以是在f==null分支里面执行的结果） --active; // 活跃任务数-1 try { return f.get(); // 返回执行结果 } catch (ExecutionException eex) { ee = eex; // ee用来记录上次的异常结果 } catch (RuntimeException rex) { ee = new ExecutionException(rex); } } } if (ee == null) ee = new ExecutionException(); // 执行到这里，说明退出了for循环，但并没有执行结果的值，也没有异常信息，那么就抛出执行异常。 throw ee; } finally { for (int i = 0, size = futures.size(); i CANCELLED或者是NEW->INTERRUPTING->INTERRUPTED） } } // 执行给定的任务集合，返回其中一个成功完成的任务结果（即没有抛出异常），如果有的话。（重载ExecutorService方法） // 不限时的invokeAny public T invokeAny(Collection> tasks) throws InterruptedException, ExecutionException { try { return doInvokeAny(tasks, false, 0); // 不限时 } catch (TimeoutException cannotHappen) { assert false; // 这个有意思，一个从来不会发生的异常如果进来了，直接断言为失败，不return结果？？？（不知道有啥用） return null; } } // 执行给定的任务集合，返回其中一个成功完成的任务结果（即没有抛出异常），如果有的话。（重载ExecutorService方法） // 限时的invokeAny（该限时为拿到所有执行结果的总限时） public T invokeAny(Collection> tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return doInvokeAny(tasks, true, unit.toNanos(timeout)); } // 执行给定的任务集合，返回Future列表持有当所有任务都执行完成后的状态和结果。（该方法会等待wait，直到所有任务都完成）（重载ExecutorService方法） // 不限时的invokeAll public List> invokeAll(Collection> tasks) throws InterruptedException { if (tasks == null) throw new NullPointerException(); ArrayList> futures = new ArrayList>(tasks.size()); // 创建初识容量为任务数长度的空列表。这里使用future是为了能够方便操作任务，比如cancel等操作。 boolean done = false; // 所有任务完成标识 try { for (Callable t : tasks) { RunnableFuture f = newTaskFor(t); futures.add(f); // 将包装后的任务加入到futures execute(f); // 调用子类的execute方法执行任务（像ThreadPoolExecutor可能只是提交了任务，任务需要排队执行） } for (int i = 0, size = futures.size(); i f = futures.get(i); // 遍历futures，拿每个任务的执行future if (!f.isDone()) { // 判断该任务是否执行完成（state!=NEW） try { f.get(); // 如果没完成，通过FutureTask#get()来FutureTask#awaitDone(false, 0L)，等待完成 } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } } } done = true; // 执行到这里说明所有任务都完成了 return futures; // 返回结果是所有future集合 } finally { if (!done) // 如果任务没完成而到了这一步，说明可能该方法被中断，需要取消所有未完成的任务 for (int i = 0, size = futures.size(); i List> invokeAll(Collection> tasks, long timeout, TimeUnit unit) throws InterruptedException { if (tasks == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); ArrayList> futures = new ArrayList>(tasks.size()); boolean done = false; try { for (Callable t : tasks) futures.add(newTaskFor(t)); // 这里跟不限时的invokeAll有区别，并没有立即将任务放到Executor（具体的实现类）#execute执行 final long deadline = System.nanoTime() + nanos; final int size = futures.size(); // Interleave time checks and calls to execute in case // executor doesn't have any/much parallelism. // 交错时间检查和调用执行，以防止executor没有任何/很多并行性 // （逐个任务提交执行（不并行处理，实际由Executor实现子类来决定），记录执行时间，确保限时功能） for (int i = 0; i f = futures.get(i); if (!f.isDone()) { if (nanos "},"Doc/util/concurrent/Callable.java.html":{"url":"Doc/util/concurrent/Callable.java.html","title":"Callable.Java","keywords":"","body":"Callable /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; /** * A task that returns a result and may throw an exception. * Implementors define a single method with no arguments called * {@code call}. * 任务，能够返回结果，也可能抛出异常。 * 实现者（需要）定义一个没有入参的call方法 * * The {@code Callable} interface is similar to {@link * java.lang.Runnable}, in that both are designed for classes whose * instances are potentially executed by another thread. A * {@code Runnable}, however, does not return a result and cannot * throw a checked exception. * Callable接口与java.lang.Runnable相似，都是为了某些潜在的（potentially）想要运行在其他线程中的类实例设计的。 * 不过，Runnable不会返回执行结果，也不会抛出检查型异常（这个是值得关注的差异点） * * The {@link Executors} class contains utility methods to * convert from other common forms to {@code Callable} classes. * Executors类包含一些实用（utility）方法将其他常见形式的类转化为Callable类。 * * @see Executor * @since 1.5 * @author Doug Lea * @param the result type of method {@code call} */ @FunctionalInterface public interface Callable { /** * Computes a result, or throws an exception if unable to do so. * 计算结果，如果无法计算则抛出异常（Exception）。 * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception; } "},"Doc/util/concurrent/ConcurrentHashMap.java.html":{"url":"Doc/util/concurrent/ConcurrentHashMap.java.html","title":"ConcurrentHashMap.Java","keywords":"","body":"/* ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. */ / Written by Doug Lea with assistance from members of JCP JSR-166 Expert Group and released to the public domain, as explained at http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; import java.io.ObjectStreamField; import java.io.Serializable; import java.lang.reflect.ParameterizedType; import java.lang.reflect.Type; import java.util.AbstractMap; import java.util.Arrays; import java.util.Collection; import java.util.Comparator; import java.util.Enumeration; import java.util.HashMap; import java.util.Hashtable; import java.util.Iterator; import java.util.Map; import java.util.NoSuchElementException; import java.util.Set; import java.util.Spliterator; import java.util.concurrent.ConcurrentMap; import java.util.concurrent.ForkJoinPool; import java.util.concurrent.atomic.AtomicReference; import java.util.concurrent.locks.LockSupport; import java.util.concurrent.locks.ReentrantLock; import java.util.function.BiConsumer; import java.util.function.BiFunction; import java.util.function.BinaryOperator; import java.util.function.Consumer; import java.util.function.DoubleBinaryOperator; import java.util.function.Function; import java.util.function.IntBinaryOperator; import java.util.function.LongBinaryOperator; import java.util.function.ToDoubleBiFunction; import java.util.function.ToDoubleFunction; import java.util.function.ToIntBiFunction; import java.util.function.ToIntFunction; import java.util.function.ToLongBiFunction; import java.util.function.ToLongFunction; import java.util.stream.Stream; /** A hash table supporting full concurrency of retrievals and high expected concurrency for updates. This class obeys the same functional specification as {@link java.util.Hashtable}, and includes versions of methods corresponding to each method of {@code Hashtable}. However, even though all operations are thread-safe, retrieval operations do not entail locking, and there is not any support for locking the entire table in a way that prevents all access. This class is fully interoperable with {@code Hashtable} in programs that rely on its thread safety but not on its synchronization details. * Retrieval operations (including {@code get}) generally do not block, so may overlap with update operations (including {@code put} and {@code remove}). Retrievals reflect the results of the most recently completed update operations holding upon their onset. (More formally, an update operation for a given key bears a happens-before relation with any (non-null) retrieval for that key reporting the updated value.) For aggregate operations such as {@code putAll} and {@code clear}, concurrent retrievals may reflect insertion or removal of only some entries. Similarly, Iterators, Spliterators and Enumerations return elements reflecting the state of the hash table at some point at or since the creation of the iterator/enumeration. They do not throw {@link java.util.ConcurrentModificationException ConcurrentModificationException}. However, iterators are designed to be used by only one thread at a time. Bear in mind that the results of aggregate status methods including {@code size}, {@code isEmpty}, and {@code containsValue} are typically useful only when a map is not undergoing concurrent updates in other threads. Otherwise the results of these methods reflect transient states that may be adequate for monitoring or estimation purposes, but not for program control. * The table is dynamically expanded when there are too many collisions (i.e., keys that have distinct hash codes but fall into the same slot modulo the table size), with the expected average effect of maintaining roughly two bins per mapping (corresponding to a 0.75 load factor threshold for resizing). There may be much variance around this average as mappings are added and removed, but overall, this maintains a commonly accepted time/space tradeoff for hash tables. However, resizing this or any other kind of hash table may be a relatively slow operation. When possible, it is a good idea to provide a size estimate as an optional {@code initialCapacity} constructor argument. An additional optional {@code loadFactor} constructor argument provides a further means of customizing initial table capacity by specifying the table density to be used in calculating the amount of space to allocate for the given number of elements. Also, for compatibility with previous versions of this class, constructors may optionally specify an expected {@code concurrencyLevel} as an additional hint for internal sizing. Note that using many keys with exactly the same {@code hashCode()} is a sure way to slow down performance of any hash table. To ameliorate impact, when keys are {@link Comparable}, this class may use comparison order among keys to help break ties. * A {@link Set} projection of a ConcurrentHashMap may be created (using {@link #newKeySet()} or {@link #newKeySet(int)}), or viewed (using {@link #keySet(Object)} when only keys are of interest, and the mapped values are (perhaps transiently) not used or all take the same mapping value. * A ConcurrentHashMap can be used as scalable frequency map (a form of histogram or multiset) by using {@link java.util.concurrent.atomic.LongAdder} values and initializing via {@link #computeIfAbsent computeIfAbsent}. For example, to add a count to a {@code ConcurrentHashMap freqs}, you can use {@code freqs.computeIfAbsent(k -> new LongAdder()).increment();} * This class and its views and iterators implement all of the optional methods of the {@link Map} and {@link Iterator} interfaces. * Like {@link Hashtable} but unlike {@link HashMap}, this class does not allow {@code null} to be used as a key or value. * ConcurrentHashMaps support a set of sequential and parallel bulk operations that, unlike most {@link Stream} methods, are designed to be safely, and often sensibly, applied even with maps that are being concurrently updated by other threads; for example, when computing a snapshot summary of the values in a shared registry. There are three kinds of operation, each with four forms, accepting functions with Keys, Values, Entries, and (Key, Value) arguments and/or return values. Because the elements of a ConcurrentHashMap are not ordered in any particular way, and may be processed in different orders in different parallel executions, the correctness of supplied functions should not depend on any ordering, or on any other objects or values that may transiently change while computation is in progress; and except for forEach actions, should ideally be side-effect-free. Bulk operations on {@link java.util.Map.Entry} objects do not support method {@code setValue}. * forEach: Perform a given action on each element. A variant form applies a given transformation on each element before performing the action. * search: Return the first available non-null result of applying a given function on each element; skipping further search when a result is found. * reduce: Accumulate each element. The supplied reduction function cannot rely on ordering (more formally, it should be both associative and commutative). There are five variants: * * Plain reductions. (There is not a form of this method for (key, value) function arguments since there is no corresponding return type.) * Mapped reductions that accumulate the results of a given function applied to each element. * Reductions to scalar doubles, longs, and ints, using a given basis value. * * These bulk operations accept a {@code parallelismThreshold} argument. Methods proceed sequentially if the current map size is estimated to be less than the given threshold. Using a value of {@code Long.MAX_VALUE} suppresses all parallelism. Using a value of {@code 1} results in maximal parallelism by partitioning into enough subtasks to fully utilize the {@link ForkJoinPool#commonPool()} that is used for all parallel computations. Normally, you would initially choose one of these extreme values, and then measure performance of using in-between values that trade off overhead versus throughput. * The concurrency properties of bulk operations follow from those of ConcurrentHashMap: Any non-null result returned from {@code get(key)} and related access methods bears a happens-before relation with the associated insertion or update. The result of any bulk operation reflects the composition of these per-element relations (but is not necessarily atomic with respect to the map as a whole unless it is somehow known to be quiescent). Conversely, because keys and values in the map are never null, null serves as a reliable atomic indicator of the current lack of any result. To maintain this property, null serves as an implicit basis for all non-scalar reduction operations. For the double, long, and int versions, the basis should be one that, when combined with any other value, returns that other value (more formally, it should be the identity element for the reduction). Most common reductions have these properties; for example, computing a sum with basis 0 or a minimum with basis MAX_VALUE. * Search and transformation functions provided as arguments should similarly return null to indicate the lack of any result (in which case it is not used). In the case of mapped reductions, this also enables transformations to serve as filters, returning null (or, in the case of primitive specializations, the identity basis) if the element should not be combined. You can create compound transformations and filterings by composing them yourself under this \"null means there is nothing there now\" rule before using them in search or reduce operations. * Methods accepting and/or returning Entry arguments maintain key-value associations. They may be useful for example when finding the key for the greatest value. Note that \"plain\" Entry arguments can be supplied using {@code new AbstractMap.SimpleEntry(k,v)}. * Bulk operations may complete abruptly, throwing an exception encountered in the application of a supplied function. Bear in mind when handling such exceptions that other concurrently executing functions could also have thrown exceptions, or would have done so if the first exception had not occurred. * Speedups for parallel compared to sequential forms are common but not guaranteed. Parallel operations involving brief functions on small maps may execute more slowly than sequential forms if the underlying work to parallelize the computation is more expensive than the computation itself. Similarly, parallelization may not lead to much actual parallelism if all processors are busy performing unrelated tasks. * All arguments to all task methods must be non-null. * This class is a member of the Java Collections Framework. * @since 1.5 @author Doug Lea @param the type of keys maintained by this map @param the type of mapped values */ public class ConcurrentHashMap extends AbstractMap implements ConcurrentMap, Serializable { private static final long serialVersionUID = 7249069246763182397L; /* Overview: * The primary design goal of this hash table is to maintain concurrent readability (typically method get(), but also iterators and related methods) while minimizing update contention. Secondary goals are to keep space consumption about the same or better than java.util.HashMap, and to support high initial insertion rates on an empty table by many threads. * This map usually acts as a binned (bucketed) hash table. Each key-value mapping is held in a Node. Most nodes are instances of the basic Node class with hash, key, value, and next fields. However, various subclasses exist: TreeNodes are arranged in balanced trees, not lists. TreeBins hold the roots of sets of TreeNodes. ForwardingNodes are placed at the heads of bins during resizing. ReservationNodes are used as placeholders while establishing values in computeIfAbsent and related methods. The types TreeBin, ForwardingNode, and ReservationNode do not hold normal user keys, values, or hashes, and are readily distinguishable during search etc because they have negative hash fields and null key and value fields. (These special nodes are either uncommon or transient, so the impact of carrying around some unused fields is insignificant.) * The table is lazily initialized to a power-of-two size upon the first insertion. Each bin in the table normally contains a list of Nodes (most often, the list has only zero or one Node). Table accesses require volatile/atomic reads, writes, and CASes. Because there is no other way to arrange this without adding further indirections, we use intrinsics (sun.misc.Unsafe) operations. * We use the top (sign) bit of Node hash fields for control purposes -- it is available anyway because of addressing constraints. Nodes with negative hash fields are specially handled or ignored in map methods. * Insertion (via put or its variants) of the first node in an empty bin is performed by just CASing it to the bin. This is by far the most common case for put operations under most key/hash distributions. Other update operations (insert, delete, and replace) require locks. We do not want to waste the space required to associate a distinct lock object with each bin, so instead use the first node of a bin list itself as a lock. Locking support for these locks relies on builtin \"synchronized\" monitors. * Using the first node of a list as a lock does not by itself suffice though: When a node is locked, any update must first validate that it is still the first node after locking it, and retry if not. Because new nodes are always appended to lists, once a node is first in a bin, it remains first until deleted or the bin becomes invalidated (upon resizing). * The main disadvantage of per-bin locks is that other update operations on other nodes in a bin list protected by the same lock can stall, for example when user equals() or mapping functions take a long time. However, statistically, under random hash codes, this is not a common problem. Ideally, the frequency of nodes in bins follows a Poisson distribution (http://en.wikipedia.org/wiki/Poisson_distribution) with a parameter of about 0.5 on average, given the resizing threshold of 0.75, although with a large variance because of resizing granularity. Ignoring variance, the expected occurrences of list size k are (exp(-0.5) * pow(0.5, k) / factorial(k)). The first values are: * 0: 0.60653066 1: 0.30326533 2: 0.07581633 3: 0.01263606 4: 0.00157952 5: 0.00015795 6: 0.00001316 7: 0.00000094 8: 0.00000006 more: less than 1 in ten million * Lock contention probability for two threads accessing distinct elements is roughly 1 / (8 #elements) under random hashes. Actual hash code distributions encountered in practice sometimes deviate significantly from uniform randomness. This includes the case when N > (1 Similarly for dumb or hostile usages in which multiple keys are designed to have identical hash codes or ones that differs only in masked-out high bits. So we use a secondary strategy that applies when the number of nodes in a bin exceeds a threshold. These TreeBins use a balanced tree to hold nodes (a specialized form of red-black trees), bounding search time to O(log N). Each search step in a TreeBin is at least twice as slow as in a regular list, but given that N cannot exceed (1 steps, lock hold times, etc, to reasonable constants (roughly 100 nodes inspected per operation worst case) so long as keys are Comparable (which is very common -- String, Long, etc). TreeBin nodes (TreeNodes) also maintain the same \"next\" traversal pointers as regular nodes, so can be traversed in iterators in the same way. * The table is resized when occupancy exceeds a percentage threshold (nominally, 0.75, but see below). Any thread noticing an overfull bin may assist in resizing after the initiating thread allocates and sets up the replacement array. However, rather than stalling, these other threads may proceed with insertions etc. The use of TreeBins shields us from the worst case effects of overfilling while resizes are in progress. Resizing proceeds by transferring bins, one by one, from the table to the next table. However, threads claim small blocks of indices to transfer (via field transferIndex) before doing so, reducing contention. A generation stamp in field sizeCtl ensures that resizings do not overlap. Because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset. We eliminate unnecessary node creation by catching cases where old nodes can be reused because their next fields won't change. On average, only about one-sixth of them need cloning when a table doubles. The nodes they replace will be garbage collectable as soon as they are no longer referenced by any reader thread that may be in the midst of concurrently traversing table. Upon transfer, the old table bin contains only a special forwarding node (with hash field \"MOVED\") that contains the next table as its key. On encountering a forwarding node, access and update operations restart, using the new table. * Each bin transfer requires its bin lock, which can stall waiting for locks while resizing. However, because other threads can join in and help resize rather than contend for locks, average aggregate waits become shorter as resizing progresses. The transfer operation must also ensure that all accessible bins in both the old and new table are usable by any traversal. This is arranged in part by proceeding from the last bin (table.length - 1) up towards the first. Upon seeing a forwarding node, traversals (see class Traverser) arrange to move to the new table without revisiting nodes. To ensure that no intervening nodes are skipped even when moved out of order, a stack (see class TableStack) is created on first encounter of a forwarding node during a traversal, to maintain its place if later processing the current table. The need for these save/restore mechanics is relatively rare, but when one forwarding node is encountered, typically many more will be. So Traversers use a simple caching scheme to avoid creating so many new TableStack nodes. (Thanks to Peter Levart for suggesting use of a stack here.) * The traversal scheme also applies to partial traversals of ranges of bins (via an alternate Traverser constructor) to support partitioned aggregate operations. Also, read-only operations give up if ever forwarded to a null table, which provides support for shutdown-style clearing, which is also not currently implemented. * Lazy table initialization minimizes footprint until first use, and also avoids resizings when the first operation is from a putAll, constructor with map argument, or deserialization. These cases attempt to override the initial capacity settings, but harmlessly fail to take effect in cases of races. * The element count is maintained using a specialization of LongAdder. We need to incorporate a specialization rather than just use a LongAdder in order to access implicit contention-sensing that leads to creation of multiple CounterCells. The counter mechanics avoid contention on updates but can encounter cache thrashing if read too frequently during concurrent access. To avoid reading so often, resizing under contention is attempted only upon adding to a bin already holding two or more nodes. Under uniform hash distributions, the probability of this occurring at threshold is around 13%, meaning that only about 1 in 8 puts check threshold (and after resizing, many fewer do so). * TreeBins use a special form of comparison for search and related operations (which is the main reason we cannot use existing collections such as TreeMaps). TreeBins contain Comparable elements, but may contain others, as well as elements that are Comparable but not necessarily Comparable for the same T, so we cannot invoke compareTo among them. To handle this, the tree is ordered primarily by hash value, then by Comparable.compareTo order if applicable. On lookup at a node, if elements are not comparable or compare as 0 then both left and right children may need to be searched in the case of tied hash values. (This corresponds to the full list search that would be necessary if all elements were non-Comparable and had tied hashes.) On insertion, to keep a total ordering (or as close as is required here) across rebalancings, we compare classes and identityHashCodes as tie-breakers. The red-black balancing code is updated from pre-jdk-collections (http://gee.cs.oswego.edu/dl/classes/collections/RBCell.java) based in turn on Cormen, Leiserson, and Rivest \"Introduction to Algorithms\" (CLR). * TreeBins also require an additional locking mechanism. While list traversal is always possible by readers even during updates, tree traversal is not, mainly because of tree-rotations that may change the root node and/or its linkages. TreeBins include a simple read-write lock mechanism parasitic on the main bin-synchronization strategy: Structural adjustments associated with an insertion or removal are already bin-locked (and so cannot conflict with other writers) but must wait for ongoing readers to finish. Since there can be only one such waiter, we use a simple scheme using a single \"waiter\" field to block writers. However, readers need never block. If the root lock is held, they proceed along the slow traversal path (via next-pointers) until the lock becomes available or the list is exhausted, whichever comes first. These cases are not fast, but maximize aggregate expected throughput. * Maintaining API and serialization compatibility with previous versions of this class introduces several oddities. Mainly: We leave untouched but unused constructor arguments refering to concurrencyLevel. We accept a loadFactor constructor argument, but apply it only to initial table capacity (which is the only time that we can guarantee to honor it.) We also declare an unused \"Segment\" class that is instantiated in minimal form only when serializing. * Also, solely for compatibility with previous versions of this class, it extends AbstractMap, even though all of its methods are overridden, so it is just useless baggage. * This file is organized to make things a little easier to follow while reading than they might otherwise: First the main static declarations and utilities, then fields, then main public methods (with a few factorings of multiple public methods into internal ones), then sizing methods, trees, traversers, and bulk operations. */ / ---------------- Constants -------------- / /** The largest possible table capacity. This value must be exactly 1 bounds for power of two table sizes, and is further required because the top two bits of 32bit hash fields are used for control purposes. */ private static final int MAXIMUM_CAPACITY = 1 /** The default initial table capacity. Must be a power of 2 (i.e., at least 1) and at most MAXIMUM_CAPACITY. */ private static final int DEFAULT_CAPACITY = 16; /** The largest possible (non-power of two) array size. Needed by toArray and related methods. */ static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; /** The default concurrency level for this table. Unused but defined for compatibility with previous versions of this class. */ private static final int DEFAULT_CONCURRENCY_LEVEL = 16; /** The load factor for this table. Overrides of this value in constructors affect only the initial table capacity. The actual floating point value isn't normally used -- it is simpler to use expressions such as {@code n - (n >>> 2)} for the associated resizing threshold. */ private static final float LOAD_FACTOR = 0.75f; /** The bin count threshold for using a tree rather than list for a bin. Bins are converted to trees when adding an element to a bin with at least this many nodes. The value must be greater than 2, and should be at least 8 to mesh with assumptions in tree removal about conversion back to plain bins upon shrinkage. */ static final int TREEIFY_THRESHOLD = 8; /** The bin count threshold for untreeifying a (split) bin during a resize operation. Should be less than TREEIFY_THRESHOLD, and at most 6 to mesh with shrinkage detection under removal. */ static final int UNTREEIFY_THRESHOLD = 6; /** The smallest table capacity for which bins may be treeified. (Otherwise the table is resized if too many nodes in a bin.) The value should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts between resizing and treeification thresholds. */ static final int MIN_TREEIFY_CAPACITY = 64; /** Minimum number of rebinnings per transfer step. Ranges are subdivided to allow multiple resizer threads. This value serves as a lower bound to avoid resizers encountering excessive memory contention. The value should be at least DEFAULT_CAPACITY. */ private static final int MIN_TRANSFER_STRIDE = 16; /** The number of bits used for generation stamp in sizeCtl. Must be at least 6 for 32bit arrays. */ private static int RESIZE_STAMP_BITS = 16; /** The maximum number of threads that can help resize. Must fit in 32 - RESIZE_STAMP_BITS bits. */ private static final int MAX_RESIZERS = (1 /** The bit shift for recording size stamp in sizeCtl. */ private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS; /* Encodings for Node hash fields. See above for explanation. */ static final int MOVED = -1; // hash for forwarding nodes static final int TREEBIN = -2; // hash for roots of trees static final int RESERVED = -3; // hash for transient reservations static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash /* Number of CPUS, to place bounds on some sizings / static final int NCPU = Runtime.getRuntime().availableProcessors(); /* For serialization compatibility. / private static final ObjectStreamField[] serialPersistentFields = { new ObjectStreamField(\"segments\", Segment[].class), new ObjectStreamField(\"segmentMask\", Integer.TYPE), new ObjectStreamField(\"segmentShift\", Integer.TYPE) }; / ---------------- Nodes -------------- / /** Key-value entry. This class is never exported out as a user-mutable Map.Entry (i.e., one supporting setValue; see MapEntry below), but can be used for read-only traversals used in bulk tasks. Subclasses of Node with a negative hash field are special, and contain null keys and values (but are never exported). Otherwise, keys and vals are never null. */ static class Node implements Map.Entry { final int hash; final K key; volatile V val; volatile Node next; Node(int hash, K key, V val, Node next) { this.hash = hash; this.key = key; this.val = val; this.next = next; } public final K getKey() { return key; } public final V getValue() { return val; } public final int hashCode() { return key.hashCode() ^ val.hashCode(); } public final String toString(){ return key + \"=\" + val; } public final V setValue(V value) { throw new UnsupportedOperationException(); } public final boolean equals(Object o) { Object k, v, u; Map.Entry e; return ((o instanceof Map.Entry) && (k = (e = (Map.Entry)o).getKey()) != null && (v = e.getValue()) != null && (k == key || k.equals(key)) && (v == (u = val) || v.equals(u))); } /** Virtualized support for map.get(); overridden in subclasses. */ Node find(int h, Object k) { Node e = this; if (k != null) { do { K ek; if (e.hash == h && ((ek = e.key) == k || (ek != null && k.equals(ek)))) return e; } while ((e = e.next) != null); } return null; } } / ---------------- Static utilities -------------- / /** Spreads (XORs) higher bits of hash to lower and also forces top bit to 0. Because the table uses power-of-two masking, sets of hashes that vary only in bits above the current mask will always collide. (Among known examples are sets of Float keys holding consecutive whole numbers in small tables.) So we apply a transform that spreads the impact of higher bits downward. There is a tradeoff between speed, utility, and quality of bit-spreading. Because many common sets of hashes are already reasonably distributed (so don't benefit from spreading), and because we use trees to handle large sets of collisions in bins, we just XOR some shifted bits in the cheapest possible way to reduce systematic lossage, as well as to incorporate impact of the highest bits that would otherwise never be used in index calculations because of table bounds. */ static final int spread(int h) { return (h ^ (h >>> 16)) & HASH_BITS; } /** Returns a power of two table size for the given desired capacity. See Hackers Delight, sec 3.2 */ private static final int tableSizeFor(int c) { int n = c - 1; n |= n >>> 1; n |= n >>> 2; n |= n >>> 4; n |= n >>> 8; n |= n >>> 16; return (n = MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } /** Returns x's Class if it is of the form \"class C implements Comparable\", else null. */ static Class comparableClassFor(Object x) { if (x instanceof Comparable) { Class c; Type[] ts, as; Type t; ParameterizedType p; if ((c = x.getClass()) == String.class) // bypass checks return c; if ((ts = c.getGenericInterfaces()) != null) { for (int i = 0; i } return null; } /** Returns k.compareTo(x) if x matches kc (k's screened comparable class), else 0. */ @SuppressWarnings({\"rawtypes\",\"unchecked\"}) // for cast to Comparable static int compareComparables(Class kc, Object k, Object x) { return (x == null || x.getClass() != kc ? 0 : ((Comparable)k).compareTo(x)); } / ---------------- Table element access -------------- / /* Volatile access methods are used for table elements as well as elements of in-progress next table while resizing. All uses of the tab arguments must be null checked by callers. All callers also paranoically precheck that tab's length is not zero (or an equivalent check), thus ensuring that any index argument taking the form of a hash value anded with (length - 1) is a valid index. Note that, to be correct wrt arbitrary concurrency errors by users, these checks must operate on local variables, which accounts for some odd-looking inline assignments below. Note that calls to setTabAt always occur within locked regions, and so in principle require only release ordering, not full volatile semantics, but are currently coded as volatile writes to be conservative. */ @SuppressWarnings(\"unchecked\") static final Node tabAt(Node[] tab, int i) { return (Node)U.getObjectVolatile(tab, ((long)i static final boolean casTabAt(Node[] tab, int i, Node c, Node v) { return U.compareAndSwapObject(tab, ((long)i static final void setTabAt(Node[] tab, int i, Node v) { U.putObjectVolatile(tab, ((long)i / ---------------- Fields -------------- / /** The array of bins. Lazily initialized upon first insertion. Size is always a power of two. Accessed directly by iterators. */ transient volatile Node[] table; /** The next table to use; non-null only while resizing. */ private transient volatile Node[] nextTable; /** Base counter value, used mainly when there is no contention, but also as a fallback during table initialization races. Updated via CAS. */ private transient volatile long baseCount; /** Table initialization and resizing control. When negative, the table is being initialized or resized: -1 for initialization, else -(1 + the number of active resizing threads). Otherwise, when table is null, holds the initial table size to use upon creation, or 0 for default. After initialization, holds the next element count value upon which to resize the table. */ private transient volatile int sizeCtl; /** The next table index (plus one) to split while resizing. */ private transient volatile int transferIndex; /** Spinlock (locked via CAS) used when resizing and/or creating CounterCells. */ private transient volatile int cellsBusy; /** Table of counter cells. When non-null, size is a power of 2. */ private transient volatile CounterCell[] counterCells; // views private transient KeySetView keySet; private transient ValuesView values; private transient EntrySetView entrySet; /* ---------------- Public operations -------------- */ /** * Creates a new, empty map with the default initial table size (16). */ public ConcurrentHashMap() { } /** * Creates a new, empty map with an initial table size * accommodating the specified number of elements without the need * to dynamically resize. * * @param initialCapacity The implementation performs internal * sizing to accommodate this many elements. * @throws IllegalArgumentException if the initial capacity of * elements is negative */ public ConcurrentHashMap(int initialCapacity) { if (initialCapacity = (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1)); this.sizeCtl = cap; } /** * Creates a new map with the same mappings as the given map. * * @param m the map */ public ConcurrentHashMap(Map m) { this.sizeCtl = DEFAULT_CAPACITY; putAll(m); } /** * Creates a new, empty map with an initial table size based on * the given number of elements ({@code initialCapacity}) and * initial table density ({@code loadFactor}). * * @param initialCapacity the initial capacity. The implementation * performs internal sizing to accommodate this many elements, * given the specified load factor. * @param loadFactor the load factor (table density) for * establishing the initial table size * @throws IllegalArgumentException if the initial capacity of * elements is negative or the load factor is nonpositive * * @since 1.6 */ public ConcurrentHashMap(int initialCapacity, float loadFactor) { this(initialCapacity, loadFactor, 1); } /** * Creates a new, empty map with an initial table size based on * the given number of elements ({@code initialCapacity}), table * density ({@code loadFactor}), and number of concurrently * updating threads ({@code concurrencyLevel}). * * @param initialCapacity the initial capacity. The implementation * performs internal sizing to accommodate this many elements, * given the specified load factor. * @param loadFactor the load factor (table density) for * establishing the initial table size * @param concurrencyLevel the estimated number of concurrently * updating threads. The implementation may use this value as * a sizing hint. * @throws IllegalArgumentException if the initial capacity is * negative or the load factor or concurrencyLevel are * nonpositive */ public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor > 0.0f) || initialCapacity = (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap; } // Original (since JDK1.2) Map methods /** * {@inheritDoc} */ public int size() { long n = sumCount(); return ((n (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); } /** * {@inheritDoc} */ public boolean isEmpty() { return sumCount() More formally, if this map contains a mapping from a key * {@code k} to a value {@code v} such that {@code key.equals(k)}, * then this method returns {@code v}; otherwise it returns * {@code null}. (There can be at most one such mapping.) * * @throws NullPointerException if the specified key is null */ public V get(Object key) { Node[] tab; Node e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) { if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null && key.equals(ek))) return e.val; } else if (eh [] t; if ((t = table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) { V v; if ((v = p.val) == value || (v != null && value.equals(v))) return true; } } return false; } /** * Maps the specified key to the specified value in this table. * Neither the key nor the value can be null. * * The value can be retrieved by calling the {@code get} method * with a key that is equal to the original key. * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with {@code key}, or * {@code null} if there was no mapping for {@code key} * @throws NullPointerException if the specified key or value is null */ public V put(K key, V value) { return putVal(key, value, false); } /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { if (casTabAt(tab, i, null, new Node(hash, key, value, null))) break; // no lock when adding to empty bin } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node pred = e; if ((e = e.next) == null) { pred.next = new Node(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { Node p; binCount = 2; if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } /** * Copies all of the mappings from the specified map to this one. * These mappings replace any mappings that this map had for any of the * keys currently in the specified map. * * @param m mappings to be stored in this map */ public void putAll(Map m) { tryPresize(m.size()); for (Map.Entry e : m.entrySet()) putVal(e.getKey(), e.getValue(), false); } /** * Removes the key (and its corresponding value) from this map. * This method does nothing if the key is not in the map. * * @param key the key that needs to be removed * @return the previous value associated with {@code key}, or * {@code null} if there was no mapping for {@code key} * @throws NullPointerException if the specified key is null */ public V remove(Object key) { return replaceNode(key, null, null); } /** * Implementation for the four public remove/replace methods: * Replaces node value with v, conditional upon match of cv if * non-null. If resulting value is null, delete. */ final V replaceNode(Object key, V value, Object cv) { int hash = spread(key.hashCode()); for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0 || (f = tabAt(tab, i = (n - 1) & hash)) == null) break; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; boolean validated = false; synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { validated = true; for (Node e = f, pred = null;;) { K ek; if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { V ev = e.val; if (cv == null || cv == ev || (ev != null && cv.equals(ev))) { oldVal = ev; if (value != null) e.val = value; else if (pred != null) pred.next = e.next; else setTabAt(tab, i, e.next); } break; } pred = e; if ((e = e.next) == null) break; } } else if (f instanceof TreeBin) { validated = true; TreeBin t = (TreeBin)f; TreeNode r, p; if ((r = t.root) != null && (p = r.findTreeNode(hash, key, null)) != null) { V pv = p.val; if (cv == null || cv == pv || (pv != null && cv.equals(pv))) { oldVal = pv; if (value != null) p.val = value; else if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); } } } } } if (validated) { if (oldVal != null) { if (value == null) addCount(-1L, -1); return oldVal; } break; } } } return null; } /** * Removes all of the mappings from this map. */ public void clear() { long delta = 0L; // negative number of deletions int i = 0; Node[] tab = table; while (tab != null && i f = tabAt(tab, i); if (f == null) ++i; else if ((fh = f.hash) == MOVED) { tab = helpTransfer(tab, f); i = 0; // restart } else { synchronized (f) { if (tabAt(tab, i) == f) { Node p = (fh >= 0 ? f : (f instanceof TreeBin) ? ((TreeBin)f).first : null); while (p != null) { --delta; p = p.next; } setTabAt(tab, i++, null); } } } } if (delta != 0L) addCount(delta, -1); } /** * Returns a {@link Set} view of the keys contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. The set supports element * removal, which removes the corresponding mapping from this map, * via the {@code Iterator.remove}, {@code Set.remove}, * {@code removeAll}, {@code retainAll}, and {@code clear} * operations. It does not support the {@code add} or * {@code addAll} operations. * * The view's iterators and spliterators are * weakly consistent. * * The view's {@code spliterator} reports {@link Spliterator#CONCURRENT}, * {@link Spliterator#DISTINCT}, and {@link Spliterator#NONNULL}. * * @return the set view */ public KeySetView keySet() { KeySetView ks; return (ks = keySet) != null ? ks : (keySet = new KeySetView(this, null)); } /** * Returns a {@link Collection} view of the values contained in this map. * The collection is backed by the map, so changes to the map are * reflected in the collection, and vice-versa. The collection * supports element removal, which removes the corresponding * mapping from this map, via the {@code Iterator.remove}, * {@code Collection.remove}, {@code removeAll}, * {@code retainAll}, and {@code clear} operations. It does not * support the {@code add} or {@code addAll} operations. * * The view's iterators and spliterators are * weakly consistent. * * The view's {@code spliterator} reports {@link Spliterator#CONCURRENT} * and {@link Spliterator#NONNULL}. * * @return the collection view */ public Collection values() { ValuesView vs; return (vs = values) != null ? vs : (values = new ValuesView(this)); } /** * Returns a {@link Set} view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. The set supports element * removal, which removes the corresponding mapping from the map, * via the {@code Iterator.remove}, {@code Set.remove}, * {@code removeAll}, {@code retainAll}, and {@code clear} * operations. * * The view's iterators and spliterators are * weakly consistent. * * The view's {@code spliterator} reports {@link Spliterator#CONCURRENT}, * {@link Spliterator#DISTINCT}, and {@link Spliterator#NONNULL}. * * @return the set view */ public Set> entrySet() { EntrySetView es; return (es = entrySet) != null ? es : (entrySet = new EntrySetView(this)); } /** * Returns the hash code value for this {@link Map}, i.e., * the sum of, for each key-value pair in the map, * {@code key.hashCode() ^ value.hashCode()}. * * @return the hash code value for this map */ public int hashCode() { int h = 0; Node[] t; if ((t = table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) h += p.key.hashCode() ^ p.val.hashCode(); } return h; } /** * Returns a string representation of this map. The string * representation consists of a list of key-value mappings (in no * particular order) enclosed in braces (\"{@code {}}\"). Adjacent * mappings are separated by the characters {@code \", \"} (comma * and space). Each key-value mapping is rendered as the key * followed by an equals sign (\"{@code =}\") followed by the * associated value. * * @return a string representation of this map */ public String toString() { Node[] t; int f = (t = table) == null ? 0 : t.length; Traverser it = new Traverser(t, f, 0, f); StringBuilder sb = new StringBuilder(); sb.append('{'); Node p; if ((p = it.advance()) != null) { for (;;) { K k = p.key; V v = p.val; sb.append(k == this ? \"(this Map)\" : k); sb.append('='); sb.append(v == this ? \"(this Map)\" : v); if ((p = it.advance()) == null) break; sb.append(',').append(' '); } } return sb.append('}').toString(); } /** * Compares the specified object with this map for equality. * Returns {@code true} if the given object is a map with the same * mappings as this map. This operation may return misleading * results if either map is concurrently modified during execution * of this method. * * @param o object to be compared for equality with this map * @return {@code true} if the specified object is equal to this map */ public boolean equals(Object o) { if (o != this) { if (!(o instanceof Map)) return false; Map m = (Map) o; Node[] t; int f = (t = table) == null ? 0 : t.length; Traverser it = new Traverser(t, f, 0, f); for (Node p; (p = it.advance()) != null; ) { V val = p.val; Object v = m.get(p.key); if (v == null || (v != val && !v.equals(val))) return false; } for (Map.Entry e : m.entrySet()) { Object mk, mv, v; if ((mk = e.getKey()) == null || (mv = e.getValue()) == null || (v = get(mk)) == null || (mv != v && !mv.equals(v))) return false; } } return true; } /** * Stripped-down version of helper class used in previous version, * declared for the sake of serialization compatibility */ static class Segment extends ReentrantLock implements Serializable { private static final long serialVersionUID = 2249069246763182397L; final float loadFactor; Segment(float lf) { this.loadFactor = lf; } } /** * Saves the state of the {@code ConcurrentHashMap} instance to a * stream (i.e., serializes it). * @param s the stream * @throws java.io.IOException if an I/O error occurs * @serialData * the key (Object) and value (Object) * for each key-value mapping, followed by a null pair. * The key-value mappings are emitted in no particular order. */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException { // For serialization compatibility // Emulate segment calculation from previous version of this class int sshift = 0; int ssize = 1; while (ssize [] segments = (Segment[]) new Segment[DEFAULT_CONCURRENCY_LEVEL]; for (int i = 0; i (LOAD_FACTOR); s.putFields().put(\"segments\", segments); s.putFields().put(\"segmentShift\", segmentShift); s.putFields().put(\"segmentMask\", segmentMask); s.writeFields(); Node[] t; if ((t = table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) { s.writeObject(p.key); s.writeObject(p.val); } } s.writeObject(null); s.writeObject(null); segments = null; // throw away } /** * Reconstitutes the instance from a stream (that is, deserializes it). * @param s the stream * @throws ClassNotFoundException if the class of a serialized object * could not be found * @throws java.io.IOException if an I/O error occurs */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { /* * To improve performance in typical cases, we create nodes * while reading, then place in table once size is known. * However, we must also validate uniqueness and deal with * overpopulated bins while doing so, which requires * specialized versions of putVal mechanics. */ sizeCtl = -1; // force exclusion for table construction s.defaultReadObject(); long size = 0L; Node p = null; for (;;) { @SuppressWarnings(\"unchecked\") K k = (K) s.readObject(); @SuppressWarnings(\"unchecked\") V v = (V) s.readObject(); if (k != null && v != null) { p = new Node(spread(k.hashCode()), k, v, p); ++size; } else break; } if (size == 0L) sizeCtl = 0; else { int n; if (size >= (long)(MAXIMUM_CAPACITY >>> 1)) n = MAXIMUM_CAPACITY; else { int sz = (int)size; n = tableSizeFor(sz + (sz >>> 1) + 1); } @SuppressWarnings(\"unchecked\") Node[] tab = (Node[])new Node[n]; int mask = n - 1; long added = 0L; while (p != null) { boolean insertAtFront; Node next = p.next, first; int h = p.hash, j = h & mask; if ((first = tabAt(tab, j)) == null) insertAtFront = true; else { K k = p.key; if (first.hash t = (TreeBin)first; if (t.putTreeVal(h, k, p.val) == null) ++added; insertAtFront = false; } else { int binCount = 0; insertAtFront = true; Node q; K qk; for (q = first; q != null; q = q.next) { if (q.hash == h && ((qk = q.key) == k || (qk != null && k.equals(qk)))) { insertAtFront = false; break; } ++binCount; } if (insertAtFront && binCount >= TREEIFY_THRESHOLD) { insertAtFront = false; ++added; p.next = first; TreeNode hd = null, tl = null; for (q = p; q != null; q = q.next) { TreeNode t = new TreeNode (q.hash, q.key, q.val, null, null); if ((t.prev = tl) == null) hd = t; else tl.next = t; tl = t; } setTabAt(tab, j, new TreeBin(hd)); } } } if (insertAtFront) { ++added; p.next = first; setTabAt(tab, j, p); } p = next; } table = tab; sizeCtl = n - (n >>> 2); baseCount = added; } } // ConcurrentMap methods /** * {@inheritDoc} * * @return the previous value associated with the specified key, * or {@code null} if there was no mapping for the key * @throws NullPointerException if the specified key or value is null */ public V putIfAbsent(K key, V value) { return putVal(key, value, true); } /** * {@inheritDoc} * * @throws NullPointerException if the specified key is null */ public boolean remove(Object key, Object value) { if (key == null) throw new NullPointerException(); return value != null && replaceNode(key, null, value) != null; } /** * {@inheritDoc} * * @throws NullPointerException if any of the arguments are null */ public boolean replace(K key, V oldValue, V newValue) { if (key == null || oldValue == null || newValue == null) throw new NullPointerException(); return replaceNode(key, newValue, oldValue) != null; } /** * {@inheritDoc} * * @return the previous value associated with the specified key, * or {@code null} if there was no mapping for the key * @throws NullPointerException if the specified key or value is null */ public V replace(K key, V value) { if (key == null || value == null) throw new NullPointerException(); return replaceNode(key, value, null); } // Overrides of JDK8+ Map extension method defaults /** * Returns the value to which the specified key is mapped, or the * given default value if this map contains no mapping for the * key. * * @param key the key whose associated value is to be returned * @param defaultValue the value to return if this map contains * no mapping for the given key * @return the mapping for the key, if present; else the default value * @throws NullPointerException if the specified key is null */ public V getOrDefault(Object key, V defaultValue) { V v; return (v = get(key)) == null ? defaultValue : v; } public void forEach(BiConsumer action) { if (action == null) throw new NullPointerException(); Node[] t; if ((t = table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) { action.accept(p.key, p.val); } } } public void replaceAll(BiFunction function) { if (function == null) throw new NullPointerException(); Node[] t; if ((t = table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) { V oldValue = p.val; for (K key = p.key;;) { V newValue = function.apply(key, oldValue); if (newValue == null) throw new NullPointerException(); if (replaceNode(key, newValue, oldValue) != null || (oldValue = get(key)) == null) break; } } } } /** * If the specified key is not already associated with a value, * attempts to compute its value using the given mapping function * and enters it into this map unless {@code null}. The entire * method invocation is performed atomically, so the function is * applied at most once per key. Some attempted update operations * on this map by other threads may be blocked while computation * is in progress, so the computation should be short and simple, * and must not attempt to update any other mappings of this map. * * @param key key with which the specified value is to be associated * @param mappingFunction the function to compute a value * @return the current (existing or computed) value associated with * the specified key, or null if the computed value is null * @throws NullPointerException if the specified key or mappingFunction * is null * @throws IllegalStateException if the computation detectably * attempts a recursive update to this map that would * otherwise never complete * @throws RuntimeException or Error if the mappingFunction does so, * in which case the mapping is left unestablished */ public V computeIfAbsent(K key, Function mappingFunction) { if (key == null || mappingFunction == null) throw new NullPointerException(); int h = spread(key.hashCode()); V val = null; int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) & h)) == null) { Node r = new ReservationNode(); synchronized (r) { if (casTabAt(tab, i, null, r)) { binCount = 1; Node node = null; try { if ((val = mappingFunction.apply(key)) != null) node = new Node(h, key, val, null); } finally { setTabAt(tab, i, node); } } } if (binCount != 0) break; } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { boolean added = false; synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; V ev; if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { val = e.val; break; } Node pred = e; if ((e = e.next) == null) { if ((val = mappingFunction.apply(key)) != null) { added = true; pred.next = new Node(h, key, val, null); } break; } } } else if (f instanceof TreeBin) { binCount = 2; TreeBin t = (TreeBin)f; TreeNode r, p; if ((r = t.root) != null && (p = r.findTreeNode(h, key, null)) != null) val = p.val; else if ((val = mappingFunction.apply(key)) != null) { added = true; t.putTreeVal(h, key, val); } } } } if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (!added) return val; break; } } } if (val != null) addCount(1L, binCount); return val; } /** * If the value for the specified key is present, attempts to * compute a new mapping given the key and its current mapped * value. The entire method invocation is performed atomically. * Some attempted update operations on this map by other threads * may be blocked while computation is in progress, so the * computation should be short and simple, and must not attempt to * update any other mappings of this map. * * @param key key with which a value may be associated * @param remappingFunction the function to compute a value * @return the new value associated with the specified key, or null if none * @throws NullPointerException if the specified key or remappingFunction * is null * @throws IllegalStateException if the computation detectably * attempts a recursive update to this map that would * otherwise never complete * @throws RuntimeException or Error if the remappingFunction does so, * in which case the mapping is unchanged */ public V computeIfPresent(K key, BiFunction remappingFunction) { if (key == null || remappingFunction == null) throw new NullPointerException(); int h = spread(key.hashCode()); V val = null; int delta = 0; int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) & h)) == null) break; else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { binCount = 1; for (Node e = f, pred = null;; ++binCount) { K ek; if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { val = remappingFunction.apply(key, e.val); if (val != null) e.val = val; else { delta = -1; Node en = e.next; if (pred != null) pred.next = en; else setTabAt(tab, i, en); } break; } pred = e; if ((e = e.next) == null) break; } } else if (f instanceof TreeBin) { binCount = 2; TreeBin t = (TreeBin)f; TreeNode r, p; if ((r = t.root) != null && (p = r.findTreeNode(h, key, null)) != null) { val = remappingFunction.apply(key, p.val); if (val != null) p.val = val; else { delta = -1; if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); } } } } } if (binCount != 0) break; } } if (delta != 0) addCount((long)delta, binCount); return val; } /** * Attempts to compute a mapping for the specified key and its * current mapped value (or {@code null} if there is no current * mapping). The entire method invocation is performed atomically. * Some attempted update operations on this map by other threads * may be blocked while computation is in progress, so the * computation should be short and simple, and must not attempt to * update any other mappings of this Map. * * @param key key with which the specified value is to be associated * @param remappingFunction the function to compute a value * @return the new value associated with the specified key, or null if none * @throws NullPointerException if the specified key or remappingFunction * is null * @throws IllegalStateException if the computation detectably * attempts a recursive update to this map that would * otherwise never complete * @throws RuntimeException or Error if the remappingFunction does so, * in which case the mapping is unchanged */ public V compute(K key, BiFunction remappingFunction) { if (key == null || remappingFunction == null) throw new NullPointerException(); int h = spread(key.hashCode()); V val = null; int delta = 0; int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) & h)) == null) { Node r = new ReservationNode(); synchronized (r) { if (casTabAt(tab, i, null, r)) { binCount = 1; Node node = null; try { if ((val = remappingFunction.apply(key, null)) != null) { delta = 1; node = new Node(h, key, val, null); } } finally { setTabAt(tab, i, node); } } } if (binCount != 0) break; } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { binCount = 1; for (Node e = f, pred = null;; ++binCount) { K ek; if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { val = remappingFunction.apply(key, e.val); if (val != null) e.val = val; else { delta = -1; Node en = e.next; if (pred != null) pred.next = en; else setTabAt(tab, i, en); } break; } pred = e; if ((e = e.next) == null) { val = remappingFunction.apply(key, null); if (val != null) { delta = 1; pred.next = new Node(h, key, val, null); } break; } } } else if (f instanceof TreeBin) { binCount = 1; TreeBin t = (TreeBin)f; TreeNode r, p; if ((r = t.root) != null) p = r.findTreeNode(h, key, null); else p = null; V pv = (p == null) ? null : p.val; val = remappingFunction.apply(key, pv); if (val != null) { if (p != null) p.val = val; else { delta = 1; t.putTreeVal(h, key, val); } } else if (p != null) { delta = -1; if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); } } } } if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); break; } } } if (delta != 0) addCount((long)delta, binCount); return val; } /** * If the specified key is not already associated with a * (non-null) value, associates it with the given value. * Otherwise, replaces the value with the results of the given * remapping function, or removes if {@code null}. The entire * method invocation is performed atomically. Some attempted * update operations on this map by other threads may be blocked * while computation is in progress, so the computation should be * short and simple, and must not attempt to update any other * mappings of this Map. * * @param key key with which the specified value is to be associated * @param value the value to use if absent * @param remappingFunction the function to recompute a value if present * @return the new value associated with the specified key, or null if none * @throws NullPointerException if the specified key or the * remappingFunction is null * @throws RuntimeException or Error if the remappingFunction does so, * in which case the mapping is unchanged */ public V merge(K key, V value, BiFunction remappingFunction) { if (key == null || value == null || remappingFunction == null) throw new NullPointerException(); int h = spread(key.hashCode()); V val = null; int delta = 0; int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) & h)) == null) { if (casTabAt(tab, i, null, new Node(h, key, value, null))) { delta = 1; val = value; break; } } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { binCount = 1; for (Node e = f, pred = null;; ++binCount) { K ek; if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { val = remappingFunction.apply(e.val, value); if (val != null) e.val = val; else { delta = -1; Node en = e.next; if (pred != null) pred.next = en; else setTabAt(tab, i, en); } break; } pred = e; if ((e = e.next) == null) { delta = 1; val = value; pred.next = new Node(h, key, val, null); break; } } } else if (f instanceof TreeBin) { binCount = 2; TreeBin t = (TreeBin)f; TreeNode r = t.root; TreeNode p = (r == null) ? null : r.findTreeNode(h, key, null); val = (p == null) ? value : remappingFunction.apply(p.val, value); if (val != null) { if (p != null) p.val = val; else { delta = 1; t.putTreeVal(h, key, val); } } else if (p != null) { delta = -1; if (t.removeTreeNode(p)) setTabAt(tab, i, untreeify(t.first)); } } } } if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); break; } } } if (delta != 0) addCount((long)delta, binCount); return val; } // Hashtable legacy methods /** * Legacy method testing if some key maps into the specified value * in this table. This method is identical in functionality to * {@link #containsValue(Object)}, and exists solely to ensure * full compatibility with class {@link java.util.Hashtable}, * which supported this method prior to introduction of the * Java Collections framework. * * @param value a value to search for * @return {@code true} if and only if some key maps to the * {@code value} argument in this table as * determined by the {@code equals} method; * {@code false} otherwise * @throws NullPointerException if the specified value is null */ public boolean contains(Object value) { return containsValue(value); } /** * Returns an enumeration of the keys in this table. * * @return an enumeration of the keys in this table * @see #keySet() */ public Enumeration keys() { Node[] t; int f = (t = table) == null ? 0 : t.length; return new KeyIterator(t, f, 0, f, this); } /** * Returns an enumeration of the values in this table. * * @return an enumeration of the values in this table * @see #values() */ public Enumeration elements() { Node[] t; int f = (t = table) == null ? 0 : t.length; return new ValueIterator(t, f, 0, f, this); } // ConcurrentHashMap-only methods /** * Returns the number of mappings. This method should be used * instead of {@link #size} because a ConcurrentHashMap may * contain more mappings than can be represented as an int. The * value returned is an estimate; the actual count may differ if * there are concurrent insertions or removals. * * @return the number of mappings * @since 1.8 */ public long mappingCount() { long n = sumCount(); return (n the element type of the returned set * @return the new set * @since 1.8 */ public static KeySetView newKeySet() { return new KeySetView (new ConcurrentHashMap(), Boolean.TRUE); } /** * Creates a new {@link Set} backed by a ConcurrentHashMap * from the given type to {@code Boolean.TRUE}. * * @param initialCapacity The implementation performs internal * sizing to accommodate this many elements. * @param the element type of the returned set * @return the new set * @throws IllegalArgumentException if the initial capacity of * elements is negative * @since 1.8 */ public static KeySetView newKeySet(int initialCapacity) { return new KeySetView (new ConcurrentHashMap(initialCapacity), Boolean.TRUE); } /** * Returns a {@link Set} view of the keys in this map, using the * given common mapped value for any additions (i.e., {@link * Collection#add} and {@link Collection#addAll(Collection)}). * This is of course only appropriate if it is acceptable to use * the same value for all additions from this view. * * @param mappedValue the mapped value to use for any additions * @return the set view * @throws NullPointerException if the mappedValue is null */ public KeySetView keySet(V mappedValue) { if (mappedValue == null) throw new NullPointerException(); return new KeySetView(this, mappedValue); } /* ---------------- Special Nodes -------------- */ /** * A node inserted at head of bins during transfer operations. */ static final class ForwardingNode extends Node { final Node[] nextTable; ForwardingNode(Node[] tab) { super(MOVED, null, null, null); this.nextTable = tab; } Node find(int h, Object k) { // loop to avoid arbitrarily deep recursion on forwarding nodes outer: for (Node[] tab = nextTable;;) { Node e; int n; if (k == null || tab == null || (n = tab.length) == 0 || (e = tabAt(tab, (n - 1) & h)) == null) return null; for (;;) { int eh; K ek; if ((eh = e.hash) == h && ((ek = e.key) == k || (ek != null && k.equals(ek)))) return e; if (eh )e).nextTable; continue outer; } else return e.find(h, k); } if ((e = e.next) == null) return null; } } } } /** * A place-holder node used in computeIfAbsent and compute */ static final class ReservationNode extends Node { ReservationNode() { super(RESERVED, null, null, null); } Node find(int h, Object k) { return null; } } /* ---------------- Table Initialization and Resizing -------------- */ /** * Returns the stamp bits for resizing a table of size n. * Must be negative when shifted left by RESIZE_STAMP_SHIFT. */ static final int resizeStamp(int n) { return Integer.numberOfLeadingZeros(n) | (1 [] initTable() { Node[] tab; int sc; while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") Node[] nt = (Node[])new Node[n]; table = tab = nt; sc = n - (n >>> 2); } } finally { sizeCtl = sc; } break; } } return tab; } /** * Adds to count, and if table is too small and not already * resizing, initiates transfer. If already resizing, helps * perform transfer if work is available. Rechecks occupancy * after a transfer to see if another resize is already needed * because resizings are lagging additions. * * @param x the count to add * @param check if = 0) { Node[] tab, nt; int n, sc; while (s >= (long)(sc = sizeCtl) && (tab = table) != null && (n = tab.length) >> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex [] helpTransfer(Node[] tab, Node f) { Node[] nextTab; int sc; if (tab != null && (f instanceof ForwardingNode) && (nextTab = ((ForwardingNode)f).nextTable) != null) { int rs = resizeStamp(tab.length); while (nextTab == nextTable && table == tab && (sc = sizeCtl) >> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex = (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size >>> 1) + 1); int sc; while ((sc = sizeCtl) >= 0) { Node[] tab = table; int n; if (tab == null || (n = tab.length) == 0) { n = (sc > c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if (table == tab) { @SuppressWarnings(\"unchecked\") Node[] nt = (Node[])new Node[n]; table = nt; sc = n - (n >>> 2); } } finally { sizeCtl = sc; } } } else if (c = MAXIMUM_CAPACITY) break; else if (tab == table) { int rs = resizeStamp(n); if (sc [] nt; if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex [] tab, Node[] nextTab) { int n = tab.length, stride; if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) [] nt = (Node[])new Node[n fwd = new ForwardingNode(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) { Node f; int fh; while (advance) { int nextIndex, nextBound; if (--i >= bound || finishing) advance = false; else if ((nextIndex = transferIndex) stride ? nextIndex - stride : 0))) { bound = nextBound; i = nextIndex - 1; advance = false; } } if (i = n || i + n >= nextn) { int sc; if (finishing) { nextTable = null; table = nextTab; sizeCtl = (n >> 1); return; } if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { if ((sc - 2) != resizeStamp(n) ln, hn; if (fh >= 0) { int runBit = fh & n; Node lastRun = f; for (Node p = f.next; p != null; p = p.next) { int b = p.hash & n; if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } for (Node p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph & n) == 0) ln = new Node(ph, pk, pv, ln); else hn = new Node(ph, pk, pv, hn); } setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } else if (f instanceof TreeBin) { TreeBin t = (TreeBin)f; TreeNode lo = null, loTail = null; TreeNode hi = null, hiTail = null; int lc = 0, hc = 0; for (Node e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode p = new TreeNode (h, e.key, e.val, null, null); if ((h & n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } ln = (lc (lo) : t; hn = (hc (hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } } } } } } /* ---------------- Counter support -------------- */ /** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */ @sun.misc.Contended static final class CounterCell { volatile long value; CounterCell(long x) { value = x; } } final long sumCount() { CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) { for (int i = 0; i 0) { if ((a = as[(n - 1) & h]) == null) { if (cellsBusy == 0) { // Try to attach new Cell CounterCell r = new CounterCell(x); // Optimistic create if (cellsBusy == 0 && U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) { boolean created = false; try { // Recheck under lock CounterCell[] rs; int m, j; if ((rs = counterCells) != null && (m = rs.length) > 0 && rs[j = (m - 1) & h] == null) { rs[j] = r; created = true; } } finally { cellsBusy = 0; } if (created) break; continue; // Slot is now non-empty } } collide = false; } else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x)) break; else if (counterCells != as || n >= NCPU) collide = false; // At max size or stale else if (!collide) collide = true; else if (cellsBusy == 0 && U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) { try { if (counterCells == as) {// Expand table unless stale CounterCell[] rs = new CounterCell[n [] tab, int index) { Node b; int n, sc; if (tab != null) { if ((n = tab.length) = 0) { synchronized (b) { if (tabAt(tab, index) == b) { TreeNode hd = null, tl = null; for (Node e = b; e != null; e = e.next) { TreeNode p = new TreeNode(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; } setTabAt(tab, index, new TreeBin(hd)); } } } } } /** * Returns a list on non-TreeNodes replacing those in given list. */ static Node untreeify(Node b) { Node hd = null, tl = null; for (Node q = b; q != null; q = q.next) { Node p = new Node(q.hash, q.key, q.val, null); if (tl == null) hd = p; else tl.next = p; tl = p; } return hd; } /* ---------------- TreeNodes -------------- */ /** * Nodes for use in TreeBins */ static final class TreeNode extends Node { TreeNode parent; // red-black tree links TreeNode left; TreeNode right; TreeNode prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node next, TreeNode parent) { super(hash, key, val, next); this.parent = parent; } Node find(int h, Object k) { return findTreeNode(h, k, null); } /** * Returns the TreeNode (or null if not found) for the given key * starting at given root. */ final TreeNode findTreeNode(int h, Object k, Class kc) { if (k != null) { TreeNode p = this; do { int ph, dir; K pk; TreeNode q; TreeNode pl = p.left, pr = p.right; if ((ph = p.hash) > h) p = pl; else if (ph extends Node { TreeNode root; volatile TreeNode first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock /** * Tie-breaking utility for ordering insertions when equal * hashCodes and non-comparable. We don't require a total * order, just a consistent insertion rule to maintain * equivalence across rebalancings. Tie-breaking further than * necessary simplifies testing a bit. */ static int tieBreakOrder(Object a, Object b) { int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) b) { super(TREEBIN, null, null, null); this.first = b; TreeNode r = null; for (TreeNode x = b, next; x != null; x = next) { next = (TreeNode)x.next; x.left = x.right = null; if (r == null) { x.parent = null; x.red = false; r = x; } else { K k = x.key; int h = x.hash; Class kc = null; for (TreeNode p = r;;) { int dir, ph; K pk = p.key; if ((ph = p.hash) > h) dir = -1; else if (ph xp = p; if ((p = (dir find(int h, Object k) { if (k != null) { for (Node e = first; e != null; ) { int s; K ek; if (((s = lockState) & (WAITER|WRITER)) != 0) { if (e.hash == h && ((ek = e.key) == k || (ek != null && k.equals(ek)))) return e; e = e.next; } else if (U.compareAndSwapInt(this, LOCKSTATE, s, s + READER)) { TreeNode r, p; try { p = ((r = root) == null ? null : r.findTreeNode(h, k, null)); } finally { Thread w; if (U.getAndAddInt(this, LOCKSTATE, -READER) == (READER|WAITER) && (w = waiter) != null) LockSupport.unpark(w); } return p; } } } return null; } /** * Finds or adds a node. * @return null if added */ final TreeNode putTreeVal(int h, K k, V v) { Class kc = null; boolean searched = false; for (TreeNode p = root;;) { int dir, ph; K pk; if (p == null) { first = root = new TreeNode(h, k, v, null, null); break; } else if ((ph = p.hash) > h) dir = -1; else if (ph q, ch; searched = true; if (((ch = p.left) != null && (q = ch.findTreeNode(h, k, kc)) != null) || ((ch = p.right) != null && (q = ch.findTreeNode(h, k, kc)) != null)) return q; } dir = tieBreakOrder(k, pk); } TreeNode xp = p; if ((p = (dir x, f = first; first = x = new TreeNode(h, k, v, f, xp); if (f != null) f.prev = x; if (dir p) { TreeNode next = (TreeNode)p.next; TreeNode pred = p.prev; // unlink traversal pointers TreeNode r, rl; if (pred == null) first = next; else pred.next = next; if (next != null) next.prev = pred; if (first == null) { root = null; return true; } if ((r = root) == null || r.right == null || // too small (rl = r.left) == null || rl.left == null) return true; lockRoot(); try { TreeNode replacement; TreeNode pl = p.left; TreeNode pr = p.right; if (pl != null && pr != null) { TreeNode s = pr, sl; while ((sl = s.left) != null) // find successor s = sl; boolean c = s.red; s.red = p.red; p.red = c; // swap colors TreeNode sr = s.right; TreeNode pp = p.parent; if (s == pr) { // p was s's direct parent p.parent = s; s.right = p; } else { TreeNode sp = s.parent; if ((p.parent = sp) != null) { if (s == sp.left) sp.left = p; else sp.right = p; } if ((s.right = pr) != null) pr.parent = s; } p.left = null; if ((p.right = sr) != null) sr.parent = p; if ((s.left = pl) != null) pl.parent = s; if ((s.parent = pp) == null) r = s; else if (p == pp.left) pp.left = s; else pp.right = s; if (sr != null) replacement = sr; else replacement = p; } else if (pl != null) replacement = pl; else if (pr != null) replacement = pr; else replacement = p; if (replacement != p) { TreeNode pp = replacement.parent = p.parent; if (pp == null) r = replacement; else if (p == pp.left) pp.left = replacement; else pp.right = replacement; p.left = p.right = p.parent = null; } root = (p.red) ? r : balanceDeletion(r, replacement); if (p == replacement) { // detach pointers TreeNode pp; if ((pp = p.parent) != null) { if (p == pp.left) pp.left = null; else if (p == pp.right) pp.right = null; p.parent = null; } } } finally { unlockRoot(); } assert checkInvariants(root); return false; } /* ------------------------------------------------------------ */ // Red-black tree methods, all adapted from CLR static TreeNode rotateLeft(TreeNode root, TreeNode p) { TreeNode r, pp, rl; if (p != null && (r = p.right) != null) { if ((rl = p.right = r.left) != null) rl.parent = p; if ((pp = r.parent = p.parent) == null) (root = r).red = false; else if (pp.left == p) pp.left = r; else pp.right = r; r.left = p; p.parent = r; } return root; } static TreeNode rotateRight(TreeNode root, TreeNode p) { TreeNode l, pp, lr; if (p != null && (l = p.left) != null) { if ((lr = p.left = l.right) != null) lr.parent = p; if ((pp = l.parent = p.parent) == null) (root = l).red = false; else if (pp.right == p) pp.right = l; else pp.left = l; l.right = p; p.parent = l; } return root; } static TreeNode balanceInsertion(TreeNode root, TreeNode x) { x.red = true; for (TreeNode xp, xpp, xppl, xppr;;) { if ((xp = x.parent) == null) { x.red = false; return x; } else if (!xp.red || (xpp = xp.parent) == null) return root; if (xp == (xppl = xpp.left)) { if ((xppr = xpp.right) != null && xppr.red) { xppr.red = false; xp.red = false; xpp.red = true; x = xpp; } else { if (x == xp.right) { root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { xp.red = false; if (xpp != null) { xpp.red = true; root = rotateRight(root, xpp); } } } } else { if (xppl != null && xppl.red) { xppl.red = false; xp.red = false; xpp.red = true; x = xpp; } else { if (x == xp.left) { root = rotateRight(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; } if (xp != null) { xp.red = false; if (xpp != null) { xpp.red = true; root = rotateLeft(root, xpp); } } } } } } static TreeNode balanceDeletion(TreeNode root, TreeNode x) { for (TreeNode xp, xpl, xpr;;) { if (x == null || x == root) return root; else if ((xp = x.parent) == null) { x.red = false; return x; } else if (x.red) { x.red = false; return root; } else if ((xpl = xp.left) == x) { if ((xpr = xp.right) != null && xpr.red) { xpr.red = false; xp.red = true; root = rotateLeft(root, xp); xpr = (xp = x.parent) == null ? null : xp.right; } if (xpr == null) x = xp; else { TreeNode sl = xpr.left, sr = xpr.right; if ((sr == null || !sr.red) && (sl == null || !sl.red)) { xpr.red = true; x = xp; } else { if (sr == null || !sr.red) { if (sl != null) sl.red = false; xpr.red = true; root = rotateRight(root, xpr); xpr = (xp = x.parent) == null ? null : xp.right; } if (xpr != null) { xpr.red = (xp == null) ? false : xp.red; if ((sr = xpr.right) != null) sr.red = false; } if (xp != null) { xp.red = false; root = rotateLeft(root, xp); } x = root; } } } else { // symmetric if (xpl != null && xpl.red) { xpl.red = false; xp.red = true; root = rotateRight(root, xp); xpl = (xp = x.parent) == null ? null : xp.left; } if (xpl == null) x = xp; else { TreeNode sl = xpl.left, sr = xpl.right; if ((sl == null || !sl.red) && (sr == null || !sr.red)) { xpl.red = true; x = xp; } else { if (sl == null || !sl.red) { if (sr != null) sr.red = false; xpl.red = true; root = rotateLeft(root, xpl); xpl = (xp = x.parent) == null ? null : xp.left; } if (xpl != null) { xpl.red = (xp == null) ? false : xp.red; if ((sl = xpl.left) != null) sl.red = false; } if (xp != null) { xp.red = false; root = rotateRight(root, xp); } x = root; } } } } } /** * Recursive invariant check */ static boolean checkInvariants(TreeNode t) { TreeNode tp = t.parent, tl = t.left, tr = t.right, tb = t.prev, tn = (TreeNode)t.next; if (tb != null && tb.next != t) return false; if (tn != null && tn.prev != t) return false; if (tp != null && t != tp.left && t != tp.right) return false; if (tl != null && (tl.parent != t || tl.hash > t.hash)) return false; if (tr != null && (tr.parent != t || tr.hash k = TreeBin.class; LOCKSTATE = U.objectFieldOffset (k.getDeclaredField(\"lockState\")); } catch (Exception e) { throw new Error(e); } } } /* ----------------Table Traversal -------------- */ /** * Records the table, its length, and current traversal index for a * traverser that must process a region of a forwarded table before * proceeding with current table. */ static final class TableStack { int length; int index; Node[] tab; TableStack next; } /** * Encapsulates traversal for methods such as containsValue; also * serves as a base class for other iterators and spliterators. * * Method advance visits once each still-valid node that was * reachable upon iterator construction. It might miss some that * were added to a bin after the bin was visited, which is OK wrt * consistency guarantees. Maintaining this property in the face * of possible ongoing resizes requires a fair amount of * bookkeeping state that is difficult to optimize away amidst * volatile accesses. Even so, traversal maintains reasonable * throughput. * * Normally, iteration proceeds bin-by-bin traversing lists. * However, if the table has been resized, then all future steps * must traverse both the bin at the current index as well as at * (index + baseSize); and so on for further resizings. To * paranoically cope with potential sharing by users of iterators * across threads, iteration terminates if a bounds checks fails * for a table read. */ static class Traverser { Node[] tab; // current table; updated if resized Node next; // the next entry to use TableStack stack, spare; // to save/restore on ForwardingNodes int index; // index of bin to use next int baseIndex; // current index of initial table int baseLimit; // index bound for initial table final int baseSize; // initial table size Traverser(Node[] tab, int size, int index, int limit) { this.tab = tab; this.baseSize = size; this.baseIndex = this.index = index; this.baseLimit = limit; this.next = null; } /** * Advances if possible, returning next valid node, or null if none. */ final Node advance() { Node e; if ((e = next) != null) e = e.next; for (;;) { Node[] t; int i, n; // must use locals in checks if (e != null) return next = e; if (baseIndex >= baseLimit || (t = tab) == null || (n = t.length) )e).nextTable; e = null; pushState(t, i, n); continue; } else if (e instanceof TreeBin) e = ((TreeBin)e).first; else e = null; } if (stack != null) recoverState(n); else if ((index = i + baseSize) >= n) index = ++baseIndex; // visit upper slots if present } } /** * Saves traversal state upon encountering a forwarding node. */ private void pushState(Node[] t, int i, int n) { TableStack s = spare; // reuse if possible if (s != null) spare = s.next; else s = new TableStack(); s.tab = t; s.length = n; s.index = i; s.next = stack; stack = s; } /** * Possibly pops traversal state. * * @param n length of current table */ private void recoverState(int n) { TableStack s; int len; while ((s = stack) != null && (index += (len = s.length)) >= n) { n = len; index = s.index; tab = s.tab; s.tab = null; TableStack next = s.next; s.next = spare; // save for reuse stack = next; spare = s; } if (s == null && (index += baseSize) >= n) index = ++baseIndex; } } /** * Base of key, value, and entry Iterators. Adds fields to * Traverser to support iterator.remove. */ static class BaseIterator extends Traverser { final ConcurrentHashMap map; Node lastReturned; BaseIterator(Node[] tab, int size, int index, int limit, ConcurrentHashMap map) { super(tab, size, index, limit); this.map = map; advance(); } public final boolean hasNext() { return next != null; } public final boolean hasMoreElements() { return next != null; } public final void remove() { Node p; if ((p = lastReturned) == null) throw new IllegalStateException(); lastReturned = null; map.replaceNode(p.key, null, null); } } static final class KeyIterator extends BaseIterator implements Iterator, Enumeration { KeyIterator(Node[] tab, int index, int size, int limit, ConcurrentHashMap map) { super(tab, index, size, limit, map); } public final K next() { Node p; if ((p = next) == null) throw new NoSuchElementException(); K k = p.key; lastReturned = p; advance(); return k; } public final K nextElement() { return next(); } } static final class ValueIterator extends BaseIterator implements Iterator, Enumeration { ValueIterator(Node[] tab, int index, int size, int limit, ConcurrentHashMap map) { super(tab, index, size, limit, map); } public final V next() { Node p; if ((p = next) == null) throw new NoSuchElementException(); V v = p.val; lastReturned = p; advance(); return v; } public final V nextElement() { return next(); } } static final class EntryIterator extends BaseIterator implements Iterator> { EntryIterator(Node[] tab, int index, int size, int limit, ConcurrentHashMap map) { super(tab, index, size, limit, map); } public final Map.Entry next() { Node p; if ((p = next) == null) throw new NoSuchElementException(); K k = p.key; V v = p.val; lastReturned = p; advance(); return new MapEntry(k, v, map); } } /** * Exported Entry for EntryIterator */ static final class MapEntry implements Map.Entry { final K key; // non-null V val; // non-null final ConcurrentHashMap map; MapEntry(K key, V val, ConcurrentHashMap map) { this.key = key; this.val = val; this.map = map; } public K getKey() { return key; } public V getValue() { return val; } public int hashCode() { return key.hashCode() ^ val.hashCode(); } public String toString() { return key + \"=\" + val; } public boolean equals(Object o) { Object k, v; Map.Entry e; return ((o instanceof Map.Entry) && (k = (e = (Map.Entry)o).getKey()) != null && (v = e.getValue()) != null && (k == key || k.equals(key)) && (v == val || v.equals(val))); } /** * Sets our entry's value and writes through to the map. The * value to return is somewhat arbitrary here. Since we do not * necessarily track asynchronous changes, the most recent * \"previous\" value could be different from what we return (or * could even have been removed, in which case the put will * re-establish). We do not and cannot guarantee more. */ public V setValue(V value) { if (value == null) throw new NullPointerException(); V v = val; val = value; map.put(key, value); return v; } } static final class KeySpliterator extends Traverser implements Spliterator { long est; // size estimate KeySpliterator(Node[] tab, int size, int index, int limit, long est) { super(tab, size, index, limit); this.est = est; } public Spliterator trySplit() { int i, f, h; return (h = ((i = baseIndex) + (f = baseLimit)) >>> 1) (tab, baseSize, baseLimit = h, f, est >>>= 1); } public void forEachRemaining(Consumer action) { if (action == null) throw new NullPointerException(); for (Node p; (p = advance()) != null;) action.accept(p.key); } public boolean tryAdvance(Consumer action) { if (action == null) throw new NullPointerException(); Node p; if ((p = advance()) == null) return false; action.accept(p.key); return true; } public long estimateSize() { return est; } public int characteristics() { return Spliterator.DISTINCT | Spliterator.CONCURRENT | Spliterator.NONNULL; } } static final class ValueSpliterator extends Traverser implements Spliterator { long est; // size estimate ValueSpliterator(Node[] tab, int size, int index, int limit, long est) { super(tab, size, index, limit); this.est = est; } public Spliterator trySplit() { int i, f, h; return (h = ((i = baseIndex) + (f = baseLimit)) >>> 1) (tab, baseSize, baseLimit = h, f, est >>>= 1); } public void forEachRemaining(Consumer action) { if (action == null) throw new NullPointerException(); for (Node p; (p = advance()) != null;) action.accept(p.val); } public boolean tryAdvance(Consumer action) { if (action == null) throw new NullPointerException(); Node p; if ((p = advance()) == null) return false; action.accept(p.val); return true; } public long estimateSize() { return est; } public int characteristics() { return Spliterator.CONCURRENT | Spliterator.NONNULL; } } static final class EntrySpliterator extends Traverser implements Spliterator> { final ConcurrentHashMap map; // To export MapEntry long est; // size estimate EntrySpliterator(Node[] tab, int size, int index, int limit, long est, ConcurrentHashMap map) { super(tab, size, index, limit); this.map = map; this.est = est; } public Spliterator> trySplit() { int i, f, h; return (h = ((i = baseIndex) + (f = baseLimit)) >>> 1) (tab, baseSize, baseLimit = h, f, est >>>= 1, map); } public void forEachRemaining(Consumer> action) { if (action == null) throw new NullPointerException(); for (Node p; (p = advance()) != null; ) action.accept(new MapEntry(p.key, p.val, map)); } public boolean tryAdvance(Consumer> action) { if (action == null) throw new NullPointerException(); Node p; if ((p = advance()) == null) return false; action.accept(new MapEntry(p.key, p.val, map)); return true; } public long estimateSize() { return est; } public int characteristics() { return Spliterator.DISTINCT | Spliterator.CONCURRENT | Spliterator.NONNULL; } } // Parallel bulk operations /** * Computes initial batch value for bulk tasks. The returned value * is approximately exp2 of the number of times (minus one) to * split task by two before executing leaf action. This value is * faster to compute and more convenient to use as a guide to * splitting than is the depth, since it is used while dividing by * two anyway. */ final int batchFor(long b) { long n; if (b == Long.MAX_VALUE || (n = sumCount()) = sp) ? sp : (int)n; } /** * Performs the given action for each (key, value). * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param action the action * @since 1.8 */ public void forEach(long parallelismThreshold, BiConsumer action) { if (action == null) throw new NullPointerException(); new ForEachMappingTask (null, batchFor(parallelismThreshold), 0, 0, table, action).invoke(); } /** * Performs the given action for each non-null transformation * of each (key, value). * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case the action is not applied) * @param action the action * @param the return type of the transformer * @since 1.8 */ public void forEach(long parallelismThreshold, BiFunction transformer, Consumer action) { if (transformer == null || action == null) throw new NullPointerException(); new ForEachTransformedMappingTask (null, batchFor(parallelismThreshold), 0, 0, table, transformer, action).invoke(); } /** * Returns a non-null result from applying the given search * function on each (key, value), or null if none. Upon * success, further element processing is suppressed and the * results of any other parallel invocations of the search * function are ignored. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param searchFunction a function returning a non-null * result on success, else null * @param the return type of the search function * @return a non-null result from applying the given search * function on each (key, value), or null if none * @since 1.8 */ public U search(long parallelismThreshold, BiFunction searchFunction) { if (searchFunction == null) throw new NullPointerException(); return new SearchMappingsTask (null, batchFor(parallelismThreshold), 0, 0, table, searchFunction, new AtomicReference()).invoke(); } /** * Returns the result of accumulating the given transformation * of all (key, value) pairs using the given reducer to * combine values, or null if none. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case it is not combined) * @param reducer a commutative associative combining function * @param the return type of the transformer * @return the result of accumulating the given transformation * of all (key, value) pairs * @since 1.8 */ public U reduce(long parallelismThreshold, BiFunction transformer, BiFunction reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceMappingsTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all (key, value) pairs using the given reducer to * combine values, and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all (key, value) pairs * @since 1.8 */ public double reduceToDouble(long parallelismThreshold, ToDoubleBiFunction transformer, double basis, DoubleBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceMappingsToDoubleTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all (key, value) pairs using the given reducer to * combine values, and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all (key, value) pairs * @since 1.8 */ public long reduceToLong(long parallelismThreshold, ToLongBiFunction transformer, long basis, LongBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceMappingsToLongTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all (key, value) pairs using the given reducer to * combine values, and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all (key, value) pairs * @since 1.8 */ public int reduceToInt(long parallelismThreshold, ToIntBiFunction transformer, int basis, IntBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceMappingsToIntTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Performs the given action for each key. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param action the action * @since 1.8 */ public void forEachKey(long parallelismThreshold, Consumer action) { if (action == null) throw new NullPointerException(); new ForEachKeyTask (null, batchFor(parallelismThreshold), 0, 0, table, action).invoke(); } /** * Performs the given action for each non-null transformation * of each key. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case the action is not applied) * @param action the action * @param the return type of the transformer * @since 1.8 */ public void forEachKey(long parallelismThreshold, Function transformer, Consumer action) { if (transformer == null || action == null) throw new NullPointerException(); new ForEachTransformedKeyTask (null, batchFor(parallelismThreshold), 0, 0, table, transformer, action).invoke(); } /** * Returns a non-null result from applying the given search * function on each key, or null if none. Upon success, * further element processing is suppressed and the results of * any other parallel invocations of the search function are * ignored. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param searchFunction a function returning a non-null * result on success, else null * @param the return type of the search function * @return a non-null result from applying the given search * function on each key, or null if none * @since 1.8 */ public U searchKeys(long parallelismThreshold, Function searchFunction) { if (searchFunction == null) throw new NullPointerException(); return new SearchKeysTask (null, batchFor(parallelismThreshold), 0, 0, table, searchFunction, new AtomicReference()).invoke(); } /** * Returns the result of accumulating all keys using the given * reducer to combine values, or null if none. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param reducer a commutative associative combining function * @return the result of accumulating all keys using the given * reducer to combine values, or null if none * @since 1.8 */ public K reduceKeys(long parallelismThreshold, BiFunction reducer) { if (reducer == null) throw new NullPointerException(); return new ReduceKeysTask (null, batchFor(parallelismThreshold), 0, 0, table, null, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all keys using the given reducer to combine values, or * null if none. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case it is not combined) * @param reducer a commutative associative combining function * @param the return type of the transformer * @return the result of accumulating the given transformation * of all keys * @since 1.8 */ public U reduceKeys(long parallelismThreshold, Function transformer, BiFunction reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceKeysTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all keys using the given reducer to combine values, and * the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all keys * @since 1.8 */ public double reduceKeysToDouble(long parallelismThreshold, ToDoubleFunction transformer, double basis, DoubleBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceKeysToDoubleTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all keys using the given reducer to combine values, and * the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all keys * @since 1.8 */ public long reduceKeysToLong(long parallelismThreshold, ToLongFunction transformer, long basis, LongBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceKeysToLongTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all keys using the given reducer to combine values, and * the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all keys * @since 1.8 */ public int reduceKeysToInt(long parallelismThreshold, ToIntFunction transformer, int basis, IntBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceKeysToIntTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Performs the given action for each value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param action the action * @since 1.8 */ public void forEachValue(long parallelismThreshold, Consumer action) { if (action == null) throw new NullPointerException(); new ForEachValueTask (null, batchFor(parallelismThreshold), 0, 0, table, action).invoke(); } /** * Performs the given action for each non-null transformation * of each value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case the action is not applied) * @param action the action * @param the return type of the transformer * @since 1.8 */ public void forEachValue(long parallelismThreshold, Function transformer, Consumer action) { if (transformer == null || action == null) throw new NullPointerException(); new ForEachTransformedValueTask (null, batchFor(parallelismThreshold), 0, 0, table, transformer, action).invoke(); } /** * Returns a non-null result from applying the given search * function on each value, or null if none. Upon success, * further element processing is suppressed and the results of * any other parallel invocations of the search function are * ignored. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param searchFunction a function returning a non-null * result on success, else null * @param the return type of the search function * @return a non-null result from applying the given search * function on each value, or null if none * @since 1.8 */ public U searchValues(long parallelismThreshold, Function searchFunction) { if (searchFunction == null) throw new NullPointerException(); return new SearchValuesTask (null, batchFor(parallelismThreshold), 0, 0, table, searchFunction, new AtomicReference()).invoke(); } /** * Returns the result of accumulating all values using the * given reducer to combine values, or null if none. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param reducer a commutative associative combining function * @return the result of accumulating all values * @since 1.8 */ public V reduceValues(long parallelismThreshold, BiFunction reducer) { if (reducer == null) throw new NullPointerException(); return new ReduceValuesTask (null, batchFor(parallelismThreshold), 0, 0, table, null, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all values using the given reducer to combine values, or * null if none. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case it is not combined) * @param reducer a commutative associative combining function * @param the return type of the transformer * @return the result of accumulating the given transformation * of all values * @since 1.8 */ public U reduceValues(long parallelismThreshold, Function transformer, BiFunction reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceValuesTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all values using the given reducer to combine values, * and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all values * @since 1.8 */ public double reduceValuesToDouble(long parallelismThreshold, ToDoubleFunction transformer, double basis, DoubleBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceValuesToDoubleTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all values using the given reducer to combine values, * and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all values * @since 1.8 */ public long reduceValuesToLong(long parallelismThreshold, ToLongFunction transformer, long basis, LongBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceValuesToLongTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all values using the given reducer to combine values, * and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all values * @since 1.8 */ public int reduceValuesToInt(long parallelismThreshold, ToIntFunction transformer, int basis, IntBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceValuesToIntTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Performs the given action for each entry. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param action the action * @since 1.8 */ public void forEachEntry(long parallelismThreshold, Consumer> action) { if (action == null) throw new NullPointerException(); new ForEachEntryTask(null, batchFor(parallelismThreshold), 0, 0, table, action).invoke(); } /** * Performs the given action for each non-null transformation * of each entry. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case the action is not applied) * @param action the action * @param the return type of the transformer * @since 1.8 */ public void forEachEntry(long parallelismThreshold, Function, ? extends U> transformer, Consumer action) { if (transformer == null || action == null) throw new NullPointerException(); new ForEachTransformedEntryTask (null, batchFor(parallelismThreshold), 0, 0, table, transformer, action).invoke(); } /** * Returns a non-null result from applying the given search * function on each entry, or null if none. Upon success, * further element processing is suppressed and the results of * any other parallel invocations of the search function are * ignored. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param searchFunction a function returning a non-null * result on success, else null * @param the return type of the search function * @return a non-null result from applying the given search * function on each entry, or null if none * @since 1.8 */ public U searchEntries(long parallelismThreshold, Function, ? extends U> searchFunction) { if (searchFunction == null) throw new NullPointerException(); return new SearchEntriesTask (null, batchFor(parallelismThreshold), 0, 0, table, searchFunction, new AtomicReference()).invoke(); } /** * Returns the result of accumulating all entries using the * given reducer to combine values, or null if none. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param reducer a commutative associative combining function * @return the result of accumulating all entries * @since 1.8 */ public Map.Entry reduceEntries(long parallelismThreshold, BiFunction, Map.Entry, ? extends Map.Entry> reducer) { if (reducer == null) throw new NullPointerException(); return new ReduceEntriesTask (null, batchFor(parallelismThreshold), 0, 0, table, null, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all entries using the given reducer to combine values, * or null if none. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element, or null if there is no transformation (in * which case it is not combined) * @param reducer a commutative associative combining function * @param the return type of the transformer * @return the result of accumulating the given transformation * of all entries * @since 1.8 */ public U reduceEntries(long parallelismThreshold, Function, ? extends U> transformer, BiFunction reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceEntriesTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all entries using the given reducer to combine values, * and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all entries * @since 1.8 */ public double reduceEntriesToDouble(long parallelismThreshold, ToDoubleFunction> transformer, double basis, DoubleBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceEntriesToDoubleTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all entries using the given reducer to combine values, * and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all entries * @since 1.8 */ public long reduceEntriesToLong(long parallelismThreshold, ToLongFunction> transformer, long basis, LongBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceEntriesToLongTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /** * Returns the result of accumulating the given transformation * of all entries using the given reducer to combine values, * and the given basis as an identity value. * * @param parallelismThreshold the (estimated) number of elements * needed for this operation to be executed in parallel * @param transformer a function returning the transformation * for an element * @param basis the identity (initial default value) for the reduction * @param reducer a commutative associative combining function * @return the result of accumulating the given transformation * of all entries * @since 1.8 */ public int reduceEntriesToInt(long parallelismThreshold, ToIntFunction> transformer, int basis, IntBinaryOperator reducer) { if (transformer == null || reducer == null) throw new NullPointerException(); return new MapReduceEntriesToIntTask (null, batchFor(parallelismThreshold), 0, 0, table, null, transformer, basis, reducer).invoke(); } /* ----------------Views -------------- */ /** * Base class for views. */ abstract static class CollectionView implements Collection, java.io.Serializable { private static final long serialVersionUID = 7249069246763182397L; final ConcurrentHashMap map; CollectionView(ConcurrentHashMap map) { this.map = map; } /** * Returns the map backing this view. * * @return the map backing this view */ public ConcurrentHashMap getMap() { return map; } /** * Removes all of the elements from this view, by removing all * the mappings from the map backing this view. */ public final void clear() { map.clear(); } public final int size() { return map.size(); } public final boolean isEmpty() { return map.isEmpty(); } // implementations below rely on concrete classes supplying these // abstract methods /** * Returns an iterator over the elements in this collection. * * The returned iterator is * weakly consistent. * * @return an iterator over the elements in this collection */ public abstract Iterator iterator(); public abstract boolean contains(Object o); public abstract boolean remove(Object o); private static final String oomeMsg = \"Required array size too large\"; public final Object[] toArray() { long sz = map.mappingCount(); if (sz > MAX_ARRAY_SIZE) throw new OutOfMemoryError(oomeMsg); int n = (int)sz; Object[] r = new Object[n]; int i = 0; for (E e : this) { if (i == n) { if (n >= MAX_ARRAY_SIZE) throw new OutOfMemoryError(oomeMsg); if (n >= MAX_ARRAY_SIZE - (MAX_ARRAY_SIZE >>> 1) - 1) n = MAX_ARRAY_SIZE; else n += (n >>> 1) + 1; r = Arrays.copyOf(r, n); } r[i++] = e; } return (i == n) ? r : Arrays.copyOf(r, i); } @SuppressWarnings(\"unchecked\") public final T[] toArray(T[] a) { long sz = map.mappingCount(); if (sz > MAX_ARRAY_SIZE) throw new OutOfMemoryError(oomeMsg); int m = (int)sz; T[] r = (a.length >= m) ? a : (T[])java.lang.reflect.Array .newInstance(a.getClass().getComponentType(), m); int n = r.length; int i = 0; for (E e : this) { if (i == n) { if (n >= MAX_ARRAY_SIZE) throw new OutOfMemoryError(oomeMsg); if (n >= MAX_ARRAY_SIZE - (MAX_ARRAY_SIZE >>> 1) - 1) n = MAX_ARRAY_SIZE; else n += (n >>> 1) + 1; r = Arrays.copyOf(r, n); } r[i++] = (T)e; } if (a == r && i it = iterator(); if (it.hasNext()) { for (;;) { Object e = it.next(); sb.append(e == this ? \"(this Collection)\" : e); if (!it.hasNext()) break; sb.append(',').append(' '); } } return sb.append(']').toString(); } public final boolean containsAll(Collection c) { if (c != this) { for (Object e : c) { if (e == null || !contains(e)) return false; } } return true; } public final boolean removeAll(Collection c) { if (c == null) throw new NullPointerException(); boolean modified = false; for (Iterator it = iterator(); it.hasNext();) { if (c.contains(it.next())) { it.remove(); modified = true; } } return modified; } public final boolean retainAll(Collection c) { if (c == null) throw new NullPointerException(); boolean modified = false; for (Iterator it = iterator(); it.hasNext();) { if (!c.contains(it.next())) { it.remove(); modified = true; } } return modified; } } /** * A view of a ConcurrentHashMap as a {@link Set} of keys, in * which additions may optionally be enabled by mapping to a * common value. This class cannot be directly instantiated. * See {@link #keySet() keySet()}, * {@link #keySet(Object) keySet(V)}, * {@link #newKeySet() newKeySet()}, * {@link #newKeySet(int) newKeySet(int)}. * * @since 1.8 */ public static class KeySetView extends CollectionView implements Set, java.io.Serializable { private static final long serialVersionUID = 7249069246763182397L; private final V value; KeySetView(ConcurrentHashMap map, V value) { // non-public super(map); this.value = value; } /** * Returns the default mapped value for additions, * or {@code null} if additions are not supported. * * @return the default mapped value for additions, or {@code null} * if not supported */ public V getMappedValue() { return value; } /** * {@inheritDoc} * @throws NullPointerException if the specified key is null */ public boolean contains(Object o) { return map.containsKey(o); } /** * Removes the key from this map view, by removing the key (and its * corresponding value) from the backing map. This method does * nothing if the key is not in the map. * * @param o the key to be removed from the backing map * @return {@code true} if the backing map contained the specified key * @throws NullPointerException if the specified key is null */ public boolean remove(Object o) { return map.remove(o) != null; } /** * @return an iterator over the keys of the backing map */ public Iterator iterator() { Node[] t; ConcurrentHashMap m = map; int f = (t = m.table) == null ? 0 : t.length; return new KeyIterator(t, f, 0, f, m); } /** * Adds the specified key to this set view by mapping the key to * the default mapped value in the backing map, if defined. * * @param e key to be added * @return {@code true} if this set changed as a result of the call * @throws NullPointerException if the specified key is null * @throws UnsupportedOperationException if no default mapped value * for additions was provided */ public boolean add(K e) { V v; if ((v = value) == null) throw new UnsupportedOperationException(); return map.putVal(e, v, true) == null; } /** * Adds all of the elements in the specified collection to this set, * as if by calling {@link #add} on each one. * * @param c the elements to be inserted into this set * @return {@code true} if this set changed as a result of the call * @throws NullPointerException if the collection or any of its * elements are {@code null} * @throws UnsupportedOperationException if no default mapped value * for additions was provided */ public boolean addAll(Collection c) { boolean added = false; V v; if ((v = value) == null) throw new UnsupportedOperationException(); for (K e : c) { if (map.putVal(e, v, true) == null) added = true; } return added; } public int hashCode() { int h = 0; for (K e : this) h += e.hashCode(); return h; } public boolean equals(Object o) { Set c; return ((o instanceof Set) && ((c = (Set)o) == this || (containsAll(c) && c.containsAll(this)))); } public Spliterator spliterator() { Node[] t; ConcurrentHashMap m = map; long n = m.sumCount(); int f = (t = m.table) == null ? 0 : t.length; return new KeySpliterator(t, f, 0, f, n action) { if (action == null) throw new NullPointerException(); Node[] t; if ((t = map.table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) action.accept(p.key); } } } /** * A view of a ConcurrentHashMap as a {@link Collection} of * values, in which additions are disabled. This class cannot be * directly instantiated. See {@link #values()}. */ static final class ValuesView extends CollectionView implements Collection, java.io.Serializable { private static final long serialVersionUID = 2249069246763182397L; ValuesView(ConcurrentHashMap map) { super(map); } public final boolean contains(Object o) { return map.containsValue(o); } public final boolean remove(Object o) { if (o != null) { for (Iterator it = iterator(); it.hasNext();) { if (o.equals(it.next())) { it.remove(); return true; } } } return false; } public final Iterator iterator() { ConcurrentHashMap m = map; Node[] t; int f = (t = m.table) == null ? 0 : t.length; return new ValueIterator(t, f, 0, f, m); } public final boolean add(V e) { throw new UnsupportedOperationException(); } public final boolean addAll(Collection c) { throw new UnsupportedOperationException(); } public Spliterator spliterator() { Node[] t; ConcurrentHashMap m = map; long n = m.sumCount(); int f = (t = m.table) == null ? 0 : t.length; return new ValueSpliterator(t, f, 0, f, n action) { if (action == null) throw new NullPointerException(); Node[] t; if ((t = map.table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) action.accept(p.val); } } } /** * A view of a ConcurrentHashMap as a {@link Set} of (key, value) * entries. This class cannot be directly instantiated. See * {@link #entrySet()}. */ static final class EntrySetView extends CollectionView> implements Set>, java.io.Serializable { private static final long serialVersionUID = 2249069246763182397L; EntrySetView(ConcurrentHashMap map) { super(map); } public boolean contains(Object o) { Object k, v, r; Map.Entry e; return ((o instanceof Map.Entry) && (k = (e = (Map.Entry)o).getKey()) != null && (r = map.get(k)) != null && (v = e.getValue()) != null && (v == r || v.equals(r))); } public boolean remove(Object o) { Object k, v; Map.Entry e; return ((o instanceof Map.Entry) && (k = (e = (Map.Entry)o).getKey()) != null && (v = e.getValue()) != null && map.remove(k, v)); } /** * @return an iterator over the entries of the backing map */ public Iterator> iterator() { ConcurrentHashMap m = map; Node[] t; int f = (t = m.table) == null ? 0 : t.length; return new EntryIterator(t, f, 0, f, m); } public boolean add(Entry e) { return map.putVal(e.getKey(), e.getValue(), false) == null; } public boolean addAll(Collection> c) { boolean added = false; for (Entry e : c) { if (add(e)) added = true; } return added; } public final int hashCode() { int h = 0; Node[] t; if ((t = map.table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) { h += p.hashCode(); } } return h; } public final boolean equals(Object o) { Set c; return ((o instanceof Set) && ((c = (Set)o) == this || (containsAll(c) && c.containsAll(this)))); } public Spliterator> spliterator() { Node[] t; ConcurrentHashMap m = map; long n = m.sumCount(); int f = (t = m.table) == null ? 0 : t.length; return new EntrySpliterator(t, f, 0, f, n > action) { if (action == null) throw new NullPointerException(); Node[] t; if ((t = map.table) != null) { Traverser it = new Traverser(t, t.length, 0, t.length); for (Node p; (p = it.advance()) != null; ) action.accept(new MapEntry(p.key, p.val, map)); } } } // ------------------------------------------------------- /** * Base class for bulk tasks. Repeats some fields and code from * class Traverser, because we need to subclass CountedCompleter. */ @SuppressWarnings(\"serial\") abstract static class BulkTask extends CountedCompleter { Node[] tab; // same as Traverser Node next; TableStack stack, spare; int index; int baseIndex; int baseLimit; final int baseSize; int batch; // split control BulkTask(BulkTask par, int b, int i, int f, Node[] t) { super(par); this.batch = b; this.index = this.baseIndex = i; if ((this.tab = t) == null) this.baseSize = this.baseLimit = 0; else if (par == null) this.baseSize = this.baseLimit = t.length; else { this.baseLimit = f; this.baseSize = par.baseSize; } } /** * Same as Traverser version */ final Node advance() { Node e; if ((e = next) != null) e = e.next; for (;;) { Node[] t; int i, n; if (e != null) return next = e; if (baseIndex >= baseLimit || (t = tab) == null || (n = t.length) )e).nextTable; e = null; pushState(t, i, n); continue; } else if (e instanceof TreeBin) e = ((TreeBin)e).first; else e = null; } if (stack != null) recoverState(n); else if ((index = i + baseSize) >= n) index = ++baseIndex; } } private void pushState(Node[] t, int i, int n) { TableStack s = spare; if (s != null) spare = s.next; else s = new TableStack(); s.tab = t; s.length = n; s.index = i; s.next = stack; stack = s; } private void recoverState(int n) { TableStack s; int len; while ((s = stack) != null && (index += (len = s.length)) >= n) { n = len; index = s.index; tab = s.tab; s.tab = null; TableStack next = s.next; s.next = spare; // save for reuse stack = next; spare = s; } if (s == null && (index += baseSize) >= n) index = ++baseIndex; } } /* * Task classes. Coded in a regular but ugly format/style to * simplify checks that each variant differs in the right way from * others. The null screenings exist because compilers cannot tell * that we've already null-checked task arguments, so we force * simplest hoisted bypass to help avoid convoluted traps. */ @SuppressWarnings(\"serial\") static final class ForEachKeyTask extends BulkTask { final Consumer action; ForEachKeyTask (BulkTask p, int b, int i, int f, Node[] t, Consumer action) { super(p, b, i, f, t); this.action = action; } public final void compute() { final Consumer action; if ((action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachKeyTask (this, batch >>>= 1, baseLimit = h, f, tab, action).fork(); } for (Node p; (p = advance()) != null;) action.accept(p.key); propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class ForEachValueTask extends BulkTask { final Consumer action; ForEachValueTask (BulkTask p, int b, int i, int f, Node[] t, Consumer action) { super(p, b, i, f, t); this.action = action; } public final void compute() { final Consumer action; if ((action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachValueTask (this, batch >>>= 1, baseLimit = h, f, tab, action).fork(); } for (Node p; (p = advance()) != null;) action.accept(p.val); propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class ForEachEntryTask extends BulkTask { final Consumer> action; ForEachEntryTask (BulkTask p, int b, int i, int f, Node[] t, Consumer> action) { super(p, b, i, f, t); this.action = action; } public final void compute() { final Consumer> action; if ((action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachEntryTask (this, batch >>>= 1, baseLimit = h, f, tab, action).fork(); } for (Node p; (p = advance()) != null; ) action.accept(p); propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class ForEachMappingTask extends BulkTask { final BiConsumer action; ForEachMappingTask (BulkTask p, int b, int i, int f, Node[] t, BiConsumer action) { super(p, b, i, f, t); this.action = action; } public final void compute() { final BiConsumer action; if ((action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachMappingTask (this, batch >>>= 1, baseLimit = h, f, tab, action).fork(); } for (Node p; (p = advance()) != null; ) action.accept(p.key, p.val); propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class ForEachTransformedKeyTask extends BulkTask { final Function transformer; final Consumer action; ForEachTransformedKeyTask (BulkTask p, int b, int i, int f, Node[] t, Function transformer, Consumer action) { super(p, b, i, f, t); this.transformer = transformer; this.action = action; } public final void compute() { final Function transformer; final Consumer action; if ((transformer = this.transformer) != null && (action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachTransformedKeyTask (this, batch >>>= 1, baseLimit = h, f, tab, transformer, action).fork(); } for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p.key)) != null) action.accept(u); } propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class ForEachTransformedValueTask extends BulkTask { final Function transformer; final Consumer action; ForEachTransformedValueTask (BulkTask p, int b, int i, int f, Node[] t, Function transformer, Consumer action) { super(p, b, i, f, t); this.transformer = transformer; this.action = action; } public final void compute() { final Function transformer; final Consumer action; if ((transformer = this.transformer) != null && (action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachTransformedValueTask (this, batch >>>= 1, baseLimit = h, f, tab, transformer, action).fork(); } for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p.val)) != null) action.accept(u); } propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class ForEachTransformedEntryTask extends BulkTask { final Function, ? extends U> transformer; final Consumer action; ForEachTransformedEntryTask (BulkTask p, int b, int i, int f, Node[] t, Function, ? extends U> transformer, Consumer action) { super(p, b, i, f, t); this.transformer = transformer; this.action = action; } public final void compute() { final Function, ? extends U> transformer; final Consumer action; if ((transformer = this.transformer) != null && (action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachTransformedEntryTask (this, batch >>>= 1, baseLimit = h, f, tab, transformer, action).fork(); } for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p)) != null) action.accept(u); } propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class ForEachTransformedMappingTask extends BulkTask { final BiFunction transformer; final Consumer action; ForEachTransformedMappingTask (BulkTask p, int b, int i, int f, Node[] t, BiFunction transformer, Consumer action) { super(p, b, i, f, t); this.transformer = transformer; this.action = action; } public final void compute() { final BiFunction transformer; final Consumer action; if ((transformer = this.transformer) != null && (action = this.action) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); new ForEachTransformedMappingTask (this, batch >>>= 1, baseLimit = h, f, tab, transformer, action).fork(); } for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p.key, p.val)) != null) action.accept(u); } propagateCompletion(); } } } @SuppressWarnings(\"serial\") static final class SearchKeysTask extends BulkTask { final Function searchFunction; final AtomicReference result; SearchKeysTask (BulkTask p, int b, int i, int f, Node[] t, Function searchFunction, AtomicReference result) { super(p, b, i, f, t); this.searchFunction = searchFunction; this.result = result; } public final U getRawResult() { return result.get(); } public final void compute() { final Function searchFunction; final AtomicReference result; if ((searchFunction = this.searchFunction) != null && (result = this.result) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { if (result.get() != null) return; addToPendingCount(1); new SearchKeysTask (this, batch >>>= 1, baseLimit = h, f, tab, searchFunction, result).fork(); } while (result.get() == null) { U u; Node p; if ((p = advance()) == null) { propagateCompletion(); break; } if ((u = searchFunction.apply(p.key)) != null) { if (result.compareAndSet(null, u)) quietlyCompleteRoot(); break; } } } } } @SuppressWarnings(\"serial\") static final class SearchValuesTask extends BulkTask { final Function searchFunction; final AtomicReference result; SearchValuesTask (BulkTask p, int b, int i, int f, Node[] t, Function searchFunction, AtomicReference result) { super(p, b, i, f, t); this.searchFunction = searchFunction; this.result = result; } public final U getRawResult() { return result.get(); } public final void compute() { final Function searchFunction; final AtomicReference result; if ((searchFunction = this.searchFunction) != null && (result = this.result) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { if (result.get() != null) return; addToPendingCount(1); new SearchValuesTask (this, batch >>>= 1, baseLimit = h, f, tab, searchFunction, result).fork(); } while (result.get() == null) { U u; Node p; if ((p = advance()) == null) { propagateCompletion(); break; } if ((u = searchFunction.apply(p.val)) != null) { if (result.compareAndSet(null, u)) quietlyCompleteRoot(); break; } } } } } @SuppressWarnings(\"serial\") static final class SearchEntriesTask extends BulkTask { final Function, ? extends U> searchFunction; final AtomicReference result; SearchEntriesTask (BulkTask p, int b, int i, int f, Node[] t, Function, ? extends U> searchFunction, AtomicReference result) { super(p, b, i, f, t); this.searchFunction = searchFunction; this.result = result; } public final U getRawResult() { return result.get(); } public final void compute() { final Function, ? extends U> searchFunction; final AtomicReference result; if ((searchFunction = this.searchFunction) != null && (result = this.result) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { if (result.get() != null) return; addToPendingCount(1); new SearchEntriesTask (this, batch >>>= 1, baseLimit = h, f, tab, searchFunction, result).fork(); } while (result.get() == null) { U u; Node p; if ((p = advance()) == null) { propagateCompletion(); break; } if ((u = searchFunction.apply(p)) != null) { if (result.compareAndSet(null, u)) quietlyCompleteRoot(); return; } } } } } @SuppressWarnings(\"serial\") static final class SearchMappingsTask extends BulkTask { final BiFunction searchFunction; final AtomicReference result; SearchMappingsTask (BulkTask p, int b, int i, int f, Node[] t, BiFunction searchFunction, AtomicReference result) { super(p, b, i, f, t); this.searchFunction = searchFunction; this.result = result; } public final U getRawResult() { return result.get(); } public final void compute() { final BiFunction searchFunction; final AtomicReference result; if ((searchFunction = this.searchFunction) != null && (result = this.result) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { if (result.get() != null) return; addToPendingCount(1); new SearchMappingsTask (this, batch >>>= 1, baseLimit = h, f, tab, searchFunction, result).fork(); } while (result.get() == null) { U u; Node p; if ((p = advance()) == null) { propagateCompletion(); break; } if ((u = searchFunction.apply(p.key, p.val)) != null) { if (result.compareAndSet(null, u)) quietlyCompleteRoot(); break; } } } } } @SuppressWarnings(\"serial\") static final class ReduceKeysTask extends BulkTask { final BiFunction reducer; K result; ReduceKeysTask rights, nextRight; ReduceKeysTask (BulkTask p, int b, int i, int f, Node[] t, ReduceKeysTask nextRight, BiFunction reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.reducer = reducer; } public final K getRawResult() { return result; } public final void compute() { final BiFunction reducer; if ((reducer = this.reducer) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new ReduceKeysTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, reducer)).fork(); } K r = null; for (Node p; (p = advance()) != null; ) { K u = p.key; r = (r == null) ? u : u == null ? r : reducer.apply(r, u); } result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") ReduceKeysTask t = (ReduceKeysTask)c, s = t.rights; while (s != null) { K tr, sr; if ((sr = s.result) != null) t.result = (((tr = t.result) == null) ? sr : reducer.apply(tr, sr)); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class ReduceValuesTask extends BulkTask { final BiFunction reducer; V result; ReduceValuesTask rights, nextRight; ReduceValuesTask (BulkTask p, int b, int i, int f, Node[] t, ReduceValuesTask nextRight, BiFunction reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.reducer = reducer; } public final V getRawResult() { return result; } public final void compute() { final BiFunction reducer; if ((reducer = this.reducer) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new ReduceValuesTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, reducer)).fork(); } V r = null; for (Node p; (p = advance()) != null; ) { V v = p.val; r = (r == null) ? v : reducer.apply(r, v); } result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") ReduceValuesTask t = (ReduceValuesTask)c, s = t.rights; while (s != null) { V tr, sr; if ((sr = s.result) != null) t.result = (((tr = t.result) == null) ? sr : reducer.apply(tr, sr)); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class ReduceEntriesTask extends BulkTask> { final BiFunction, Map.Entry, ? extends Map.Entry> reducer; Map.Entry result; ReduceEntriesTask rights, nextRight; ReduceEntriesTask (BulkTask p, int b, int i, int f, Node[] t, ReduceEntriesTask nextRight, BiFunction, Map.Entry, ? extends Map.Entry> reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.reducer = reducer; } public final Map.Entry getRawResult() { return result; } public final void compute() { final BiFunction, Map.Entry, ? extends Map.Entry> reducer; if ((reducer = this.reducer) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new ReduceEntriesTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, reducer)).fork(); } Map.Entry r = null; for (Node p; (p = advance()) != null; ) r = (r == null) ? p : reducer.apply(r, p); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") ReduceEntriesTask t = (ReduceEntriesTask)c, s = t.rights; while (s != null) { Map.Entry tr, sr; if ((sr = s.result) != null) t.result = (((tr = t.result) == null) ? sr : reducer.apply(tr, sr)); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceKeysTask extends BulkTask { final Function transformer; final BiFunction reducer; U result; MapReduceKeysTask rights, nextRight; MapReduceKeysTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceKeysTask nextRight, Function transformer, BiFunction reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.reducer = reducer; } public final U getRawResult() { return result; } public final void compute() { final Function transformer; final BiFunction reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceKeysTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, reducer)).fork(); } U r = null; for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p.key)) != null) r = (r == null) ? u : reducer.apply(r, u); } result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceKeysTask t = (MapReduceKeysTask)c, s = t.rights; while (s != null) { U tr, sr; if ((sr = s.result) != null) t.result = (((tr = t.result) == null) ? sr : reducer.apply(tr, sr)); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceValuesTask extends BulkTask { final Function transformer; final BiFunction reducer; U result; MapReduceValuesTask rights, nextRight; MapReduceValuesTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceValuesTask nextRight, Function transformer, BiFunction reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.reducer = reducer; } public final U getRawResult() { return result; } public final void compute() { final Function transformer; final BiFunction reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceValuesTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, reducer)).fork(); } U r = null; for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p.val)) != null) r = (r == null) ? u : reducer.apply(r, u); } result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceValuesTask t = (MapReduceValuesTask)c, s = t.rights; while (s != null) { U tr, sr; if ((sr = s.result) != null) t.result = (((tr = t.result) == null) ? sr : reducer.apply(tr, sr)); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceEntriesTask extends BulkTask { final Function, ? extends U> transformer; final BiFunction reducer; U result; MapReduceEntriesTask rights, nextRight; MapReduceEntriesTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceEntriesTask nextRight, Function, ? extends U> transformer, BiFunction reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.reducer = reducer; } public final U getRawResult() { return result; } public final void compute() { final Function, ? extends U> transformer; final BiFunction reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceEntriesTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, reducer)).fork(); } U r = null; for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p)) != null) r = (r == null) ? u : reducer.apply(r, u); } result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceEntriesTask t = (MapReduceEntriesTask)c, s = t.rights; while (s != null) { U tr, sr; if ((sr = s.result) != null) t.result = (((tr = t.result) == null) ? sr : reducer.apply(tr, sr)); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceMappingsTask extends BulkTask { final BiFunction transformer; final BiFunction reducer; U result; MapReduceMappingsTask rights, nextRight; MapReduceMappingsTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceMappingsTask nextRight, BiFunction transformer, BiFunction reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.reducer = reducer; } public final U getRawResult() { return result; } public final void compute() { final BiFunction transformer; final BiFunction reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceMappingsTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, reducer)).fork(); } U r = null; for (Node p; (p = advance()) != null; ) { U u; if ((u = transformer.apply(p.key, p.val)) != null) r = (r == null) ? u : reducer.apply(r, u); } result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceMappingsTask t = (MapReduceMappingsTask)c, s = t.rights; while (s != null) { U tr, sr; if ((sr = s.result) != null) t.result = (((tr = t.result) == null) ? sr : reducer.apply(tr, sr)); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceKeysToDoubleTask extends BulkTask { final ToDoubleFunction transformer; final DoubleBinaryOperator reducer; final double basis; double result; MapReduceKeysToDoubleTask rights, nextRight; MapReduceKeysToDoubleTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceKeysToDoubleTask nextRight, ToDoubleFunction transformer, double basis, DoubleBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Double getRawResult() { return result; } public final void compute() { final ToDoubleFunction transformer; final DoubleBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { double r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceKeysToDoubleTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsDouble(r, transformer.applyAsDouble(p.key)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceKeysToDoubleTask t = (MapReduceKeysToDoubleTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsDouble(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceValuesToDoubleTask extends BulkTask { final ToDoubleFunction transformer; final DoubleBinaryOperator reducer; final double basis; double result; MapReduceValuesToDoubleTask rights, nextRight; MapReduceValuesToDoubleTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceValuesToDoubleTask nextRight, ToDoubleFunction transformer, double basis, DoubleBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Double getRawResult() { return result; } public final void compute() { final ToDoubleFunction transformer; final DoubleBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { double r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceValuesToDoubleTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsDouble(r, transformer.applyAsDouble(p.val)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceValuesToDoubleTask t = (MapReduceValuesToDoubleTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsDouble(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceEntriesToDoubleTask extends BulkTask { final ToDoubleFunction> transformer; final DoubleBinaryOperator reducer; final double basis; double result; MapReduceEntriesToDoubleTask rights, nextRight; MapReduceEntriesToDoubleTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceEntriesToDoubleTask nextRight, ToDoubleFunction> transformer, double basis, DoubleBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Double getRawResult() { return result; } public final void compute() { final ToDoubleFunction> transformer; final DoubleBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { double r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceEntriesToDoubleTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsDouble(r, transformer.applyAsDouble(p)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceEntriesToDoubleTask t = (MapReduceEntriesToDoubleTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsDouble(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceMappingsToDoubleTask extends BulkTask { final ToDoubleBiFunction transformer; final DoubleBinaryOperator reducer; final double basis; double result; MapReduceMappingsToDoubleTask rights, nextRight; MapReduceMappingsToDoubleTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceMappingsToDoubleTask nextRight, ToDoubleBiFunction transformer, double basis, DoubleBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Double getRawResult() { return result; } public final void compute() { final ToDoubleBiFunction transformer; final DoubleBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { double r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceMappingsToDoubleTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsDouble(r, transformer.applyAsDouble(p.key, p.val)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceMappingsToDoubleTask t = (MapReduceMappingsToDoubleTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsDouble(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceKeysToLongTask extends BulkTask { final ToLongFunction transformer; final LongBinaryOperator reducer; final long basis; long result; MapReduceKeysToLongTask rights, nextRight; MapReduceKeysToLongTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceKeysToLongTask nextRight, ToLongFunction transformer, long basis, LongBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Long getRawResult() { return result; } public final void compute() { final ToLongFunction transformer; final LongBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { long r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceKeysToLongTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsLong(r, transformer.applyAsLong(p.key)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceKeysToLongTask t = (MapReduceKeysToLongTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsLong(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceValuesToLongTask extends BulkTask { final ToLongFunction transformer; final LongBinaryOperator reducer; final long basis; long result; MapReduceValuesToLongTask rights, nextRight; MapReduceValuesToLongTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceValuesToLongTask nextRight, ToLongFunction transformer, long basis, LongBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Long getRawResult() { return result; } public final void compute() { final ToLongFunction transformer; final LongBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { long r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceValuesToLongTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsLong(r, transformer.applyAsLong(p.val)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceValuesToLongTask t = (MapReduceValuesToLongTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsLong(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceEntriesToLongTask extends BulkTask { final ToLongFunction> transformer; final LongBinaryOperator reducer; final long basis; long result; MapReduceEntriesToLongTask rights, nextRight; MapReduceEntriesToLongTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceEntriesToLongTask nextRight, ToLongFunction> transformer, long basis, LongBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Long getRawResult() { return result; } public final void compute() { final ToLongFunction> transformer; final LongBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { long r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceEntriesToLongTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsLong(r, transformer.applyAsLong(p)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceEntriesToLongTask t = (MapReduceEntriesToLongTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsLong(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceMappingsToLongTask extends BulkTask { final ToLongBiFunction transformer; final LongBinaryOperator reducer; final long basis; long result; MapReduceMappingsToLongTask rights, nextRight; MapReduceMappingsToLongTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceMappingsToLongTask nextRight, ToLongBiFunction transformer, long basis, LongBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Long getRawResult() { return result; } public final void compute() { final ToLongBiFunction transformer; final LongBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { long r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceMappingsToLongTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsLong(r, transformer.applyAsLong(p.key, p.val)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceMappingsToLongTask t = (MapReduceMappingsToLongTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsLong(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceKeysToIntTask extends BulkTask { final ToIntFunction transformer; final IntBinaryOperator reducer; final int basis; int result; MapReduceKeysToIntTask rights, nextRight; MapReduceKeysToIntTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceKeysToIntTask nextRight, ToIntFunction transformer, int basis, IntBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Integer getRawResult() { return result; } public final void compute() { final ToIntFunction transformer; final IntBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { int r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceKeysToIntTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsInt(r, transformer.applyAsInt(p.key)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceKeysToIntTask t = (MapReduceKeysToIntTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsInt(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceValuesToIntTask extends BulkTask { final ToIntFunction transformer; final IntBinaryOperator reducer; final int basis; int result; MapReduceValuesToIntTask rights, nextRight; MapReduceValuesToIntTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceValuesToIntTask nextRight, ToIntFunction transformer, int basis, IntBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Integer getRawResult() { return result; } public final void compute() { final ToIntFunction transformer; final IntBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { int r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceValuesToIntTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsInt(r, transformer.applyAsInt(p.val)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceValuesToIntTask t = (MapReduceValuesToIntTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsInt(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceEntriesToIntTask extends BulkTask { final ToIntFunction> transformer; final IntBinaryOperator reducer; final int basis; int result; MapReduceEntriesToIntTask rights, nextRight; MapReduceEntriesToIntTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceEntriesToIntTask nextRight, ToIntFunction> transformer, int basis, IntBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Integer getRawResult() { return result; } public final void compute() { final ToIntFunction> transformer; final IntBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { int r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceEntriesToIntTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsInt(r, transformer.applyAsInt(p)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceEntriesToIntTask t = (MapReduceEntriesToIntTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsInt(t.result, s.result); s = t.rights = s.nextRight; } } } } } @SuppressWarnings(\"serial\") static final class MapReduceMappingsToIntTask extends BulkTask { final ToIntBiFunction transformer; final IntBinaryOperator reducer; final int basis; int result; MapReduceMappingsToIntTask rights, nextRight; MapReduceMappingsToIntTask (BulkTask p, int b, int i, int f, Node[] t, MapReduceMappingsToIntTask nextRight, ToIntBiFunction transformer, int basis, IntBinaryOperator reducer) { super(p, b, i, f, t); this.nextRight = nextRight; this.transformer = transformer; this.basis = basis; this.reducer = reducer; } public final Integer getRawResult() { return result; } public final void compute() { final ToIntBiFunction transformer; final IntBinaryOperator reducer; if ((transformer = this.transformer) != null && (reducer = this.reducer) != null) { int r = this.basis; for (int i = baseIndex, f, h; batch > 0 && (h = ((f = baseLimit) + i) >>> 1) > i;) { addToPendingCount(1); (rights = new MapReduceMappingsToIntTask (this, batch >>>= 1, baseLimit = h, f, tab, rights, transformer, r, reducer)).fork(); } for (Node p; (p = advance()) != null; ) r = reducer.applyAsInt(r, transformer.applyAsInt(p.key, p.val)); result = r; CountedCompleter c; for (c = firstComplete(); c != null; c = c.nextComplete()) { @SuppressWarnings(\"unchecked\") MapReduceMappingsToIntTask t = (MapReduceMappingsToIntTask)c, s = t.rights; while (s != null) { t.result = reducer.applyAsInt(t.result, s.result); s = t.rights = s.nextRight; } } } } } // Unsafe mechanics private static final sun.misc.Unsafe U; private static final long SIZECTL; private static final long TRANSFERINDEX; private static final long BASECOUNT; private static final long CELLSBUSY; private static final long CELLVALUE; private static final long ABASE; private static final int ASHIFT; static { try { U = sun.misc.Unsafe.getUnsafe(); Class k = ConcurrentHashMap.class; SIZECTL = U.objectFieldOffset (k.getDeclaredField(\"sizeCtl\")); TRANSFERINDEX = U.objectFieldOffset (k.getDeclaredField(\"transferIndex\")); BASECOUNT = U.objectFieldOffset (k.getDeclaredField(\"baseCount\")); CELLSBUSY = U.objectFieldOffset (k.getDeclaredField(\"cellsBusy\")); Class ck = CounterCell.class; CELLVALUE = U.objectFieldOffset (ck.getDeclaredField(\"value\")); Class ak = Node[].class; ABASE = U.arrayBaseOffset(ak); int scale = U.arrayIndexScale(ak); if ((scale & (scale - 1)) != 0) throw new Error(\"data type scale not a power of two\"); ASHIFT = 31 - Integer.numberOfLeadingZeros(scale); } catch (Exception e) { throw new Error(e); } } } "},"Doc/util/concurrent/ConcurrentMap.java.html":{"url":"Doc/util/concurrent/ConcurrentMap.java.html","title":"ConcurrentMap.Java","keywords":"","body":"ConcurrentMap /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; import java.util.Map; import java.util.Objects; import java.util.function.BiConsumer; import java.util.function.BiFunction; import java.util.function.Function; /** * A {@link java.util.Map} providing thread safety and atomicity * guarantees. * 提供线程安全与原子操作保证的Map。 * * Memory consistency effects: As with other concurrent * collections, actions in a thread prior to placing an object into a * {@code ConcurrentMap} as a key or value * happen-before * actions subsequent to the access or removal of that object from * the {@code ConcurrentMap} in another thread. * 内存一致性影响：与其他并发集合一样，在线程A将对象作为key或者value放入ConcurrentMap之前， * 线程A的操作发生在另一个线程从ConcurrentMap访问或删除该对象之前。 * （保证插入的操作对插入后的访问操作是可见的） * * This interface is a member of the * * Java Collections Framework. * 该接口是Java Collections Framework的一员。 * * @since 1.5 * @author Doug Lea * @param the type of keys maintained by this map * @param the type of mapped values */ public interface ConcurrentMap extends Map { /** * {@inheritDoc} * 在Map接口也有default实现 * * @implNote This implementation assumes that the ConcurrentMap cannot * contain null values and {@code get()} returning null unambiguously means * the key is absent. Implementations which support null values * must override this default implementation. * 实现说明，该实现假定ConcurrentMap不能包含value为null值，并且get()返回null明确（unambiguously）表示key不存在（absent）。 * 支持value为null的实现必须重写（override）该默认实现。 * * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @since 1.8 */ @Override default V getOrDefault(Object key, V defaultValue) { V v; return ((v = get(key)) != null) ? v : defaultValue; // 与Map接口的default不同在于，value不能为null（或者说value为null会返回给定的默认值） } /** * {@inheritDoc} * * @implSpec The default implementation is equivalent to, for this * {@code map}: * {@code * for ((Map.Entry entry : map.entrySet()) * action.accept(entry.getKey(), entry.getValue()); * } * 对于该map，默认实现等效于： * for ((Map.Entry entry : map.entrySet()) * action.accept(entry.getKey(), entry.getValue()); * * @implNote The default implementation assumes that * {@code IllegalStateException} thrown by {@code getKey()} or * {@code getValue()} indicates that the entry has been removed and cannot * be processed. Operation continues for subsequent entries. * 默认实现假定，当getKey()或者getValue()抛出IllegalStateException时，表示该entry已经被移除并且无法处理。 * 会继续操作后续的entry * * @throws NullPointerException {@inheritDoc} * @since 1.8 */ @Override default void forEach(BiConsumer action) { Objects.requireNonNull(action); for (Map.Entry entry : entrySet()) { K k; V v; try { k = entry.getKey(); v = entry.getValue(); } catch(IllegalStateException ise) { // this usually means the entry is no longer in the map. continue; } action.accept(k, v); // 不太清楚这个action.accept做了啥 } } /** * If the specified key is not already associated * with a value, associate it with the given value. * This is equivalent to * {@code * if (!map.containsKey(key)) * return map.put(key, value); * else * return map.get(key); * } * 如果给定的key尚未关联value，则关联到给定的value。 * 等价于： * if (!map.containsKey(key)) * return map.put(key, value); * else * return map.get(key); * * except that the action is performed atomically. * 除了动作是原子执行的。 * （这句话意思是与上面的等价操作非原子性的，而这个方法提供的操作是原子的） * * @implNote This implementation intentionally re-abstracts the * inappropriate default provided in {@code Map}. * 该实现试图（有意）重新抽象由Map提供的不适当的默认实现。 * * @param key key with which the specified value is to be associated * @param value value to be associated with the specified key * @return the previous value associated with the specified key, or * {@code null} if there was no mapping for the key. * (A {@code null} return can also indicate that the map * previously associated {@code null} with the key, * if the implementation supports null values.) * 返回原关联的value值（支持value为null的话也可能返回null），没关联的话返回null * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * @throws NullPointerException if the specified key or value is null, * and this map does not permit null keys or values * @throws IllegalArgumentException if some property of the specified key * or value prevents it from being stored in this map */ V putIfAbsent(K key, V value); /** * Removes the entry for a key only if currently mapped to a given value. * This is equivalent to * {@code * if (map.containsKey(key) && Objects.equals(map.get(key), value)) { * map.remove(key); * return true; * } else * return false; * } * 根据key移除entry，当且仅当当前key映射的value为给定value。 * 等价于： * if (map.containsKey(key) && Objects.equals(map.get(key), value)) { // 用了1.7之后的Objects类 * map.remove(key); * return true; * } else * return false; * * except that the action is performed atomically. * 除了动作是原子执行的。 * （这句话意思是与上面的等价操作非原子性的，而这个方法提供的操作是原子的） * * @implNote This implementation intentionally re-abstracts the * inappropriate default provided in {@code Map}. * 该实现试图（有意）重新抽象由Map提供的不适当的默认实现。 * * @param key key with which the specified value is associated * @param value value expected to be associated with the specified key * @return {@code true} if the value was removed * 移除成功返回true * @throws UnsupportedOperationException if the {@code remove} operation * is not supported by this map * @throws ClassCastException if the key or value is of an inappropriate * type for this map * (optional) * @throws NullPointerException if the specified key or value is null, * and this map does not permit null keys or values * (optional) */ boolean remove(Object key, Object value); /** * Replaces the entry for a key only if currently mapped to a given value. * This is equivalent to * {@code * if (map.containsKey(key) && Objects.equals(map.get(key), oldValue)) { * map.put(key, newValue); * return true; * } else * return false; * } * 根据key替换entry，当且仅当当前key映射的value值为给定的value值。 * 等价于： * if (map.containsKey(key) && Objects.equals(map.get(key), oldValue)) { * map.put(key, newValue); * return true; * } else * return false; * * except that the action is performed atomically. * 除了动作是原子执行的。 * （这句话意思是与上面的等价操作非原子性的，而这个方法提供的操作是原子的） * * @implNote This implementation intentionally re-abstracts the * inappropriate default provided in {@code Map}. * 该实现试图（有意）重新抽象由Map提供的不适当的默认实现。 * * @param key key with which the specified value is associated * @param oldValue value expected to be associated with the specified key * @param newValue value to be associated with the specified key * @return {@code true} if the value was replaced * 替换成功返回true * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * @throws ClassCastException if the class of a specified key or value * prevents it from being stored in this map * @throws NullPointerException if a specified key or value is null, * and this map does not permit null keys or values * @throws IllegalArgumentException if some property of a specified key * or value prevents it from being stored in this map */ boolean replace(K key, V oldValue, V newValue); /** * Replaces the entry for a key only if currently mapped to some value. * This is equivalent to * {@code * if (map.containsKey(key)) { * return map.put(key, value); * } else * return null; * } * 根据key替换entry，当且仅当当前key映射到某些value（某些是指保证key存在，但不关心key具体映射的value值）。 * 等价于 * if (map.containsKey(key)) { * return map.put(key, value); * } else * return null; * * except that the action is performed atomically. * 除了动作是原子执行的。 * （这句话意思是与上面的等价操作非原子性的，而这个方法提供的操作是原子的） * * @implNote This implementation intentionally re-abstracts the * inappropriate default provided in {@code Map}. * 该实现试图（有意）重新抽象由Map提供的不适当的默认实现。 * * @param key key with which the specified value is associated * @param value value to be associated with the specified key * @return the previous value associated with the specified key, or * {@code null} if there was no mapping for the key. * (A {@code null} return can also indicate that the map * previously associated {@code null} with the key, * if the implementation supports null values.) * 返回该key关联的原value值（如果实现支持null，则返回的值可能为null），没有该key原没有映射value，则返回null。 * @throws UnsupportedOperationException if the {@code put} operation * is not supported by this map * @throws ClassCastException if the class of the specified key or value * prevents it from being stored in this map * @throws NullPointerException if the specified key or value is null, * and this map does not permit null keys or values * @throws IllegalArgumentException if some property of the specified key * or value prevents it from being stored in this map */ V replace(K key, V value); /** * {@inheritDoc} * * @implSpec * The default implementation is equivalent to, for this {@code map}: * {@code * for ((Map.Entry entry : map.entrySet()) * do { * K k = entry.getKey(); * V v = entry.getValue(); * } while(!replace(k, v, function.apply(k, v))); * } * 对于该map，默认实现等价于： * for ((Map.Entry entry : map.entrySet()) * do { * K k = entry.getKey(); * V v = entry.getValue(); * } while(!replace(k, v, function.apply(k, v))); * * The default implementation may retry these steps when multiple * threads attempt updates including potentially calling the function * repeatedly for a given key. * 当多个线程尝试更新时，默认实现可能会多次尝试这些步骤，包括可能（potentially 潜在地）为给定的key重复调用该function。 * * This implementation assumes that the ConcurrentMap cannot contain null * values and {@code get()} returning null unambiguously means the key is * absent. Implementations which support null values must * override this default implementation. * 该实现假定ConcurrentMap不能包含为null值的value，并且get()返回null明确（unambiguously）表示key不存在（absent）。 * 支持value为null的实现必须重写（override）该默认实现。 * * @throws UnsupportedOperationException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws IllegalArgumentException {@inheritDoc} * @since 1.8 */ @Override default void replaceAll(BiFunction function) { Objects.requireNonNull(function); forEach((k,v) -> { while(!replace(k, v, function.apply(k, v))) { // v changed or k is gone if ( (v = get(k)) == null) { // k is no longer in the map. break; } } }); } /** * {@inheritDoc} * 通过给定的方法与原value值计算出新value值，并更新 * * @implSpec * The default implementation is equivalent to the following steps for this * {@code map}, then returning the current value or {@code null} if now * absent: * 对于该map，默认实现等价于下面的步骤，然后返回当前（原）value，如果当前key不存在，返回null： * * {@code * if (map.get(key) == null) { * V newValue = mappingFunction.apply(key); * if (newValue != null) * return map.putIfAbsent(key, newValue); * } * } * * The default implementation may retry these steps when multiple * threads attempt updates including potentially calling the mapping * function multiple times. * 当多个线程尝试更新时，默认实现可能会多次尝试这些步骤，包括可能为给定的key重复调用该映射function。 * * This implementation assumes that the ConcurrentMap cannot contain null * values and {@code get()} returning null unambiguously means the key is * absent. Implementations which support null values must * override this default implementation. * 该实现假定ConcurrentMap不能包含为null值的value，并且get()返回null明确（unambiguously）表示key不存在（absent）。 * 支持value为null的实现必须重写（override）该默认实现。 * * @throws UnsupportedOperationException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @since 1.8 */ @Override default V computeIfAbsent(K key, Function mappingFunction) { Objects.requireNonNull(mappingFunction); V v, newValue; return ((v = get(key)) == null && (newValue = mappingFunction.apply(key)) != null && // 用旧值计算新值 (v = putIfAbsent(key, newValue)) == null) ? newValue : v; // 如果key不存在，返回计算后value，否则返回原value } /** * {@inheritDoc} * * @implSpec * The default implementation is equivalent to performing the following * steps for this {@code map}, then returning the current value or * {@code null} if now absent. : * 对于该map，默认实现等价于下面的步骤，然后返回当前（原）value，如果当前key不存在，返回null： * * {@code * if (map.get(key) != null) { * V oldValue = map.get(key); * V newValue = remappingFunction.apply(key, oldValue); * if (newValue != null) * map.replace(key, oldValue, newValue); * else * map.remove(key, oldValue); * } * } * * The default implementation may retry these steps when multiple threads * attempt updates including potentially calling the remapping function * multiple times. * 当多个线程尝试更新时，默认实现可能会多次尝试这些步骤，包括可能为给定的key重复调用该重新映射的function。 * * This implementation assumes that the ConcurrentMap cannot contain null * values and {@code get()} returning null unambiguously means the key is * absent. Implementations which support null values must * override this default implementation. * 该实现假定ConcurrentMap不能包含为null值的value，并且get()返回null明确（unambiguously）表示key不存在（absent）。 * 支持value为null的实现必须重写（override）该默认实现。 * * @throws UnsupportedOperationException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @since 1.8 */ @Override default V computeIfPresent(K key, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); V oldValue; while((oldValue = get(key)) != null) { // 这里循环是为了当并发时，replace由于竞争导致失败，需要重新进行replace。 V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) { if (replace(key, oldValue, newValue)) return newValue; } else if (remove(key, oldValue)) // 如果计算的新值为null，则直接移除该key的映射关系 return null; } return oldValue; } /** * {@inheritDoc} * * @implSpec * The default implementation is equivalent to performing the following * steps for this {@code map}, then returning the current value or * {@code null} if absent: * 对于该map，默认实现等价于下面的步骤，然后返回当前（原）value，如果当前key不存在，返回null： * * {@code * V oldValue = map.get(key); * V newValue = remappingFunction.apply(key, oldValue); * if (oldValue != null ) { * if (newValue != null) * map.replace(key, oldValue, newValue); * else * map.remove(key, oldValue); * } else { * if (newValue != null) * map.putIfAbsent(key, newValue); * else * return null; * } * } * * The default implementation may retry these steps when multiple * threads attempt updates including potentially calling the remapping * function multiple times. * 当多个线程尝试更新时，默认实现可能会多次尝试这些步骤，包括可能为给定的key重复调用该重新映射的function。 * * This implementation assumes that the ConcurrentMap cannot contain null * values and {@code get()} returning null unambiguously means the key is * absent. Implementations which support null values must * override this default implementation. * 该实现假定ConcurrentMap不能包含为null值的value，并且get()返回null明确（unambiguously）表示key不存在（absent）。 * 支持value为null的实现必须重写（override）该默认实现。 * * @throws UnsupportedOperationException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @since 1.8 */ @Override default V compute(K key, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); V oldValue = get(key); for(;;) { V newValue = remappingFunction.apply(key, oldValue); if (newValue == null) { // 计算新值为null，尝试删除给定key的映射关系 // delete mapping if (oldValue != null || containsKey(key)) { // 考虑了key映射的value为null的情况 // something to remove if (remove(key, oldValue)) { // removed the old value as expected return null; } // some other value replaced old value. try again. // 尝试失败，获取给定key当前value值继续尝试 oldValue = get(key); } else { // nothing to do. Leave things as they were. return null; } } else { // 新值不为null，尝试更新给定key的映射关系 // add or replace old mapping if (oldValue != null) { // replace if (replace(key, oldValue, newValue)) { // replaced as expected. return newValue; } // some other value replaced old value. try again. // 尝试失败，获取给定key当前value值继续尝试 oldValue = get(key); } else { // add (replace if oldValue was null) if ((oldValue = putIfAbsent(key, newValue)) == null) { // 原值为null的情况下，新增key与计算后value的映射关系 // replaced return newValue; } // some other value replaced old value. try again. } } } } /** * {@inheritDoc} * merge与compute的区别是，merge依赖给定的value与原value进行计算，compute只基于原value计算 * * @implSpec * The default implementation is equivalent to performing the following * steps for this {@code map}, then returning the current value or * {@code null} if absent: * 对于该map，默认实现等价于下面的步骤，然后返回当前（原）value，如果当前key不存在，返回null： * * {@code * V oldValue = map.get(key); * V newValue = (oldValue == null) ? value : * remappingFunction.apply(oldValue, value); * if (newValue == null) * map.remove(key); * else * map.put(key, newValue); * } * * The default implementation may retry these steps when multiple * threads attempt updates including potentially calling the remapping * function multiple times. * 当多个线程尝试更新时，默认实现可能会多次尝试这些步骤，包括可能为给定的key重复调用该重新映射的function。 * * This implementation assumes that the ConcurrentMap cannot contain null * values and {@code get()} returning null unambiguously means the key is * absent. Implementations which support null values must * override this default implementation. * 该实现假定ConcurrentMap不能包含为null值的value，并且get()返回null明确（unambiguously）表示key不存在（absent）。 * 支持value为null的实现必须重写（override）该默认实现。 * * @throws UnsupportedOperationException {@inheritDoc} * @throws ClassCastException {@inheritDoc} * @throws NullPointerException {@inheritDoc} * @since 1.8 */ @Override default V merge(K key, V value, BiFunction remappingFunction) { Objects.requireNonNull(remappingFunction); Objects.requireNonNull(value); V oldValue = get(key); for (;;) { if (oldValue != null) { V newValue = remappingFunction.apply(oldValue, value); if (newValue != null) { if (replace(key, oldValue, newValue)) return newValue; } else if (remove(key, oldValue)) { return null; } oldValue = get(key); } else { if ((oldValue = putIfAbsent(key, value)) == null) { return value; } } } } } "},"Doc/util/concurrent/Executor.java.html":{"url":"Doc/util/concurrent/Executor.java.html","title":"Executor.Java","keywords":"","body":"Executor /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; /** * An object that executes submitted {@link Runnable} tasks. This * interface provides a way of decoupling task submission from the * mechanics of how each task will be run, including details of thread * use, scheduling, etc. An {@code Executor} is normally used * instead of explicitly creating threads. For example, rather than * invoking {@code new Thread(new(RunnableTask())).start()} for each * of a set of tasks, you might use: * 一个执行提交的Runnable任务的对象。 * 该接口提供了一种将任务提交与每个任务将如何运行的机制分离的方法，包含线程使用、调度等细节。 * Executor通常用于替代显式（explicitly）创建线程。 * 例如：不想为了task集合中的的每一个都调用new Thread(new(RunnableTask())).start()，可以使用下面的方法： * * * Executor executor = anExecutor; * executor.execute(new RunnableTask1()); * executor.execute(new RunnableTask2()); * ... * * * However, the {@code Executor} interface does not strictly * require that execution be asynchronous. In the simplest case, an * executor can run the submitted task immediately in the caller's * thread: * 但是，Executor接口并不严格（strictly）要求执行是异步的。 * 举一个简单的例子：executor可以在调用者的线程里立即执行task： * * {@code * class DirectExecutor implements Executor { * public void execute(Runnable r) { * r.run(); // 没有通过传入线程对象执行，那么run就作为普通方法执行了 * } * }} * * More typically, tasks are executed in some thread other * than the caller's thread. The executor below spawns a new thread * for each task. * 通常情况，task在调用者线程之外，启动线程执行。 * 下面的执行程序为每个任务生成一个新线程： * * {@code * class ThreadPerTaskExecutor implements Executor { * public void execute(Runnable r) { * new Thread(r).start(); // 每个run方法都会在不同的Thread中执行 * } * }} * * Many {@code Executor} implementations impose some sort of * limitation on how and when tasks are scheduled. The executor below * serializes the submission of tasks to a second executor, * illustrating a composite executor. * 许多Executor的实现，对task调度的方式和时间施加（impose 强加）了一些限制。 * 下面的executor将任务的提交序列化到了第二个executor，说明（illustrating）了一个复合（composite）executor * * {@code * class SerialExecutor implements Executor { * final Queue tasks = new ArrayDeque(); * final Executor executor; // 内部有一个Executor * Runnable active; * * SerialExecutor(Executor executor) { * this.executor = executor; * } * * public synchronized void execute(final Runnable r) { * tasks.offer(new Runnable() { * public void run() { * try { * r.run(); * } finally { * scheduleNext(); * } * } * }); * if (active == null) { * scheduleNext(); * } * } * * protected synchronized void scheduleNext() { * if ((active = tasks.poll()) != null) { * executor.execute(active); // 本类的execute方法执行完后，继续执行下一个executor的execute * } * } * }} * * The {@code Executor} implementations provided in this package * implement {@link ExecutorService}, which is a more extensive * interface. The {@link ThreadPoolExecutor} class provides an * extensible thread pool implementation. The {@link Executors} class * provides convenient factory methods for these Executors. * Executor在包里提供了一个ExecutorService实现类，该类是一个更广泛的接口。 * ThreadPoolExecutor类提供了一个可扩展的线程池实现。 * Executors类为这些Executor提供了方便的（convenient）的工厂方法。 * * Memory consistency effects: Actions in a thread prior to * submitting a {@code Runnable} object to an {@code Executor} * happen-before * its execution begins, perhaps in another thread. * 内存一致性影响：在线程提交Runnable对象给Executor之前，内存可见性happen-before执行之前，可能在其它线程（不知道啥意思） * * @since 1.5 * @author Doug Lea */ public interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * 执行给定的命令（实现Runnable接口的）在未来的某个时间。 * 该命令可能在一个新的线程中执行，或者在一个线程池执行，或者在调用者的线程里执行，执行方式由Executor的实现来决定。 * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command); } "},"Doc/util/concurrent/ExecutorCompletionService.java.html":{"url":"Doc/util/concurrent/ExecutorCompletionService.java.html","title":"ExecutorCompletionService.Java","keywords":"","body":"ExecutorCompletionService /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; /** * A {@link CompletionService} that uses a supplied {@link Executor} * to execute tasks. This class arranges that submitted tasks are, * upon completion, placed on a queue accessible using {@code take}. * The class is lightweight enough to be suitable for transient use * when processing groups of tasks. * CompletionService，使用提供的Executor来执行任务。 * 该类安排提交的任务完成后，通过take放到可访问的队列中。 * 该类足够轻量级，适合在处理任务组时临时使用。 * * * * Usage Examples. * 用例 * * Suppose you have a set of solvers for a certain problem, each * returning a value of some type {@code Result}, and would like to * run them concurrently, processing the results of each of them that * return a non-null value, in some method {@code use(Result r)}. You * could write this as: * 假设你有一组对某个核心问题的求解器，每个求解器都返回某种Result类型的值，并且希望并发运行他们， * 在某些方法中使用use(Result r)处理他们返回的每一个非null结果。 * 你可以这样写： * * {@code * void solve(Executor e, * Collection> solvers) * throws InterruptedException, ExecutionException { * CompletionService ecs * = new ExecutorCompletionService(e); // 用给定的executor创建CompletionService * for (Callable s : solvers) * ecs.submit(s); // 提交任务，将完成结果写入完成队列汇总 * int n = solvers.size(); // 这里遍历的是solvers的数量 * for (int i = 0; i * * Suppose instead that you would like to use the first non-null result * of the set of tasks, ignoring any that encounter exceptions, * and cancelling all other tasks when the first one is ready: * 假设你想使用任务集里的第一个非空结果，忽略任何遇到（encounter）的异常结果，并且在第一个已完成后取消所有其他线程 * * {@code * void solve(Executor e, * Collection> solvers) * throws InterruptedException { * CompletionService ecs * = new ExecutorCompletionService(e); * int n = solvers.size(); * List> futures * = new ArrayList>(n); // 这里用Future，是为了可以cancel任务 * Result result = null; * try { * for (Callable s : solvers) * futures.add(ecs.submit(s)); * for (int i = 0; i f : futures) * f.cancel(true); * } * * if (result != null) * use(result); // 如果有非空结果，进行自定义处理 * }} */ public class ExecutorCompletionService implements CompletionService { private final Executor executor; // 保存给定的executor private final AbstractExecutorService aes; // 如果给定的executor是aes，保存该对象 private final BlockingQueue> completionQueue; // 保存完成的任务 /** * FutureTask extension to enqueue upon completion * 对FutureTask的扩展，在任务完成时入队（入完成队列） */ private class QueueingFuture extends FutureTask { QueueingFuture(RunnableFuture task) { super(task, null); // 调用FutureTask的FutureTask(Runnable runnable, V result)构造函数，这里设置返回结果为null this.task = task; // 本类中新增的属性，用于记录提交的任务。（FutureTask里需要执行的任务用callable来引用的） } protected void done() { completionQueue.add(task); } // 这里是重点，对FutureTask的done方法进行重载，将完成的任务加入ExecutorCompletionService的完成队列中 private final Future task; } // 将callable任务转化为RunnableFuture // 如果aes为null，表示当前executor不是AbstractExecutorService实现的，创建FutureTask对象返回 // 如果aes不为null，那么直接使用AbstractExecutorService#newTaskFor方法创建RunnableFuture结果 // 看AbstractExecutorService#newTaskFor方法，也是用的new FutureTask， // 推测是为了方便如果aes的实现类重载了newTaskFor方法，那么该方法就可以调用aes的实现类方法 private RunnableFuture newTaskFor(Callable task) { if (aes == null) return new FutureTask(task); else return aes.newTaskFor(task); } // 与上面的方法类似 private RunnableFuture newTaskFor(Runnable task, V result) { if (aes == null) return new FutureTask(task, result); else return aes.newTaskFor(task, result); } /** * Creates an ExecutorCompletionService using the supplied * executor for base task execution and a * {@link LinkedBlockingQueue} as a completion queue. * 创建一个ExecutorCompletionService，用提供的执行器（executor）执行基础任务， * 和创建一个LinkedBlockingQueue作为完成队列。 * * @param executor the executor to use * @throws NullPointerException if executor is {@code null} */ public ExecutorCompletionService(Executor executor) { if (executor == null) throw new NullPointerException(); // 如果给定的执行器为null，抛出空指针异常 this.executor = executor; // 设置执行器 this.aes = (executor instanceof AbstractExecutorService) ? // 判断如果给定的执行器是AbstractExecutorService实例，那么设置aes为给定执行器，否则为null。这里设置aes是为了后续使用aes现有的方法 (AbstractExecutorService) executor : null; this.completionQueue = new LinkedBlockingQueue>(); // 设置completionQueue为新的LinkedBlockingQueue，元素为Future } /** * Creates an ExecutorCompletionService using the supplied * executor for base task execution and the supplied queue as its * completion queue. * 创建一个ExecutorCompletionService，用提供的执行器（executor）执行基础任务， * 和使用提供的队列作为完成队列 * * @param executor the executor to use * @param completionQueue the queue to use as the completion queue * normally one dedicated for use by this service. This * queue is treated as unbounded -- failed attempted * {@code Queue.add} operations for completed tasks cause * them not to be retrievable. * 给定的completionQueue通常专用于（delicated）该服务作为完成队列。 * 该队列被视为（treated 对待的）无界的 -- 已完成任务尝试Queue.add操作失败的话，会导致他们不可取回。 * * @throws NullPointerException if executor or completionQueue are {@code null} */ public ExecutorCompletionService(Executor executor, BlockingQueue> completionQueue) { if (executor == null || completionQueue == null) throw new NullPointerException(); this.executor = executor; this.aes = (executor instanceof AbstractExecutorService) ? (AbstractExecutorService) executor : null; this.completionQueue = completionQueue; // 使用给定的等待队列 } // 提交任务 public Future submit(Callable task) { if (task == null) throw new NullPointerException(); RunnableFuture f = newTaskFor(task); // 将callable任务转化为RunnableFuture executor.execute(new QueueingFuture(f)); // return f; } public Future submit(Runnable task, V result) { if (task == null) throw new NullPointerException(); RunnableFuture f = newTaskFor(task, result); executor.execute(new QueueingFuture(f)); return f; } // 获取队首元素，必要时需等待（如果队列为空，就需阻塞等待） public Future take() throws InterruptedException { return completionQueue.take(); // 调用的是BlockingQueue#take方法 } // 获取队首元素，如果队列为空返回null（这个不会阻塞） public Future poll() { return completionQueue.poll(); // 调用的是Queue#poll方法 } // 获取队首元素，必要时在有限时间内等待队首，如果仍等不到返回null // 与take的不同就是这个是有限时间等待 public Future poll(long timeout, TimeUnit unit) throws InterruptedException { return completionQueue.poll(timeout, unit); // 调用的是BlockingQueue#poll } } "},"Doc/util/concurrent/ExecutorService.java.html":{"url":"Doc/util/concurrent/ExecutorService.java.html","title":"ExecutorService.Java","keywords":"","body":"ExecutorService /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; import java.util.List; import java.util.Collection; /** * An {@link Executor} that provides methods to manage termination and * methods that can produce a {@link Future} for tracking progress of * one or more asynchronous tasks. * 一个Executor提供管理终止的方法，并且可以生成Future来跟踪一个或多个异步任务的执行进度的方法。 * * An {@code ExecutorService} can be shut down, which will cause * it to reject new tasks. Two different methods are provided for * shutting down an {@code ExecutorService}. The {@link #shutdown} * method will allow previously submitted tasks to execute before * terminating, while the {@link #shutdownNow} method prevents waiting * tasks from starting and attempts to stop currently executing tasks. * Upon termination, an executor has no tasks actively executing, no * tasks awaiting execution, and no new tasks can be submitted. An * unused {@code ExecutorService} should be shut down to allow * reclamation of its resources. * 可以关闭（shut down）ExecutorService，将它导致拒绝新任务。 * 提供了两种不同的方法来shutdownExecutorService。 * 1、shutdown方法，将允许之前提交的任务在终止之前继续执行。 * 2、shutdownNow方法，防止（prevent）等待任务开始，并且尝试结束当前正在执行的任务。 * 终止时，executor没有正在执行的任务，没有等待执行的任务，没有新任务可以提交。 * 应关闭未使用的ExecutorService，以回收资源。 * * Method {@code submit} extends base method {@link * Executor#execute(Runnable)} by creating and returning a {@link Future} * that can be used to cancel execution and/or wait for completion. * Methods {@code invokeAny} and {@code invokeAll} perform the most * commonly useful forms of bulk execution, executing a collection of * tasks and then waiting for at least one, or all, to * complete. (Class {@link ExecutorCompletionService} can be used to * write customized variants of these methods.) * submit方法基于Executor#execute(Runnable)方法扩展，通过创建和返回Future对象，Future可以用来取消执行的任务，并且/或等待任务完成。 * invokeAny方法和invokeAll方法最常用于批量（bulk）任务执行，执行一组任务，然后等待至少一个或者所有执行完成。 *（ExecutorCompletionService类可用于编写这些方法的自定义变体（variants 变种）） * * The {@link Executors} class provides factory methods for the * executor services provided in this package. * 在本包里的Executors类为executor服务提供了工厂方法 * * Usage Examples * 用例 * * Here is a sketch of a network service in which threads in a thread * pool service incoming requests. It uses the preconfigured {@link * Executors#newFixedThreadPool} factory method: * 这是一个网络服务的草图，在线程池里的线程服务进来的请求。 * 使用预配置的Executors#newFixedThreadPool工厂方法： * * {@code * class NetworkService implements Runnable { // 为什么要实现Runnable接口，为了表明这是个要执行的类？ * private final ServerSocket serverSocket; * private final ExecutorService pool; * * public NetworkService(int port, int poolSize) * throws IOException { * serverSocket = new ServerSocket(port); * pool = Executors.newFixedThreadPool(poolSize); * } * * public void run() { // run the service * try { * for (;;) { * pool.execute(new Handler(serverSocket.accept())); * } * } catch (IOException ex) { * pool.shutdown(); // 这里给手工shutdown了 * } * } * } * * class Handler implements Runnable { * private final Socket socket; * Handler(Socket socket) { this.socket = socket; } * public void run() { * // read and service request on socket * } * }} * * The following method shuts down an {@code ExecutorService} in two phases, * first by calling {@code shutdown} to reject incoming tasks, and then * calling {@code shutdownNow}, if necessary, to cancel any lingering tasks: * 接下来的方法从两个阶段停止ExecutorService， * 1、首先调用shutdown方法拒绝传入任务（拒绝新增任务） * 2、然后在有必要的时候，调用shutdownNow方法，取消任何延迟（linger）任务 * * {@code * void shutdownAndAwaitTermination(ExecutorService pool) { * pool.shutdown(); // Disable new tasks from being submitted * try { * // Wait a while for existing tasks to terminate * if (!pool.awaitTermination(60, TimeUnit.SECONDS)) { * pool.shutdownNow(); // Cancel currently executing tasks * // Wait a while for tasks to respond to being cancelled * if (!pool.awaitTermination(60, TimeUnit.SECONDS)) * System.err.println(\"Pool did not terminate\"); * } * } catch (InterruptedException ie) { * // (Re-)Cancel if current thread also interrupted * pool.shutdownNow(); * // Preserve interrupt status * Thread.currentThread().interrupt(); * } * }} * * Memory consistency effects: Actions in a thread prior to the * submission of a {@code Runnable} or {@code Callable} task to an * {@code ExecutorService} * happen-before * any actions taken by that task, which in turn happen-before the * result is retrieved via {@code Future.get()}. * 内存一致性影响：在将Runnable或者Callable任务提交ExecutorService之前，MemoryVisibility发生在该任务采取的任何操作之前（happen-before） * 而后者又发生在通过Future.get()检索结果之前。 * * @since 1.5 * @author Doug Lea */ public interface ExecutorService extends Executor { /** * Initiates an orderly shutdown in which previously submitted * tasks are executed, but no new tasks will be accepted. * Invocation has no additional effect if already shut down. * 启动有序的关闭，之前提交的任务将继续执行，但不会接受新的任务。 * 如果已经shutdown关闭了，多次调用该方法不会有任何额外效果（或者说影响）。 * * This method does not wait for previously submitted tasks to * complete execution. Use {@link #awaitTermination awaitTermination} * to do that. * 该方法不会等之前提交的任务执行完毕。 * 想要做到这一点的话，使用awaitTermination方法 * * @throws SecurityException if a security manager exists and * shutting down this ExecutorService may manipulate * threads that the caller is not permitted to modify * because it does not hold {@link * java.lang.RuntimePermission}{@code (\"modifyThread\")}, * or the security manager's {@code checkAccess} method * denies access. * 如果安全管理器存在，并且关闭这个ExecutorService可能会操纵不允许调用者修改的线程，因为它没有持有修改线程的执行权限（RuntimePermission）， * 或者安全管理器的checkAccess方法拒绝访问。 */ void shutdown(); /** * Attempts to stop all actively executing tasks, halts the * processing of waiting tasks, and returns a list of the tasks * that were awaiting execution. * 尝试停止全部正在执行的活跃任务，停止（halt）等待任务的处理，并返回等待执行的任务列表。 * * This method does not wait for actively executing tasks to * terminate. Use {@link #awaitTermination awaitTermination} to * do that. * 该方法不会等待正在执行的任务停止。（停止而不是完成） * 如果想做到这一点，使用awaitTermination方法 * * There are no guarantees beyond best-effort attempts to stop * processing actively executing tasks. For example, typical * implementations will cancel via {@link Thread#interrupt}, so any * task that fails to respond to interrupts may never terminate. * 不保证，除了尽力尝试停止正在执行的任务处理。例如，典型的实现方式为通过interrupt来取消（正在执行的线程），因此任何未能响应中断的任务可能永远不会终止。 *（意思就是调用了shutdownNow方法，只是会尝试去取消正在执行的任务，通常是用interrupt来实现，如果任务不响应中断，那任务还是会正常执行） * * @return list of tasks that never commenced execution * 从未开始（commenced）执行的任务列表（等待任务列表） * @throws SecurityException if a security manager exists and * shutting down this ExecutorService may manipulate * threads that the caller is not permitted to modify * because it does not hold {@link * java.lang.RuntimePermission}{@code (\"modifyThread\")}, * or the security manager's {@code checkAccess} method * denies access. */ List shutdownNow(); /** * Returns {@code true} if this executor has been shut down. * 如果该executor被关闭了，返回true * * @return {@code true} if this executor has been shut down */ boolean isShutdown(); /** * Returns {@code true} if all tasks have completed following shut down. * Note that {@code isTerminated} is never {@code true} unless * either {@code shutdown} or {@code shutdownNow} was called first. * 如果所有任务伴随着shutdown都结束了，返回true * 注意，除非shutdown()或者shutdownNow()方法首先被调用，否则直接调用该方法并不会返回true。 * * @return {@code true} if all tasks have completed following shut down */ boolean isTerminated(); /** * Blocks until all tasks have completed execution after a shutdown * request, or the timeout occurs, or the current thread is * interrupted, whichever happens first. * 在shutdown请求之后进行阻塞，直到所有任务完成处理，或者处理超时，或者当前线程被中断，以先发生者为准。 * * @param timeout the maximum time to wait * timeout参数，最大等待时间 * @param unit the time unit of the timeout argument * @return {@code true} if this executor terminated and * {@code false} if the timeout elapsed before termination * true 如果executor终止 * false 如果在终止前超时 * @throws InterruptedException if interrupted while waiting * 抛出InterruptedException，如果在等待时被中断。 */ boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; /** * Submits a value-returning task for execution and returns a * Future representing the pending results of the task. The * Future's {@code get} method will return the task's result upon * successful completion. * 提交一个有返回值的任务执行，并且返回一个代表等待task执行结果的Future。 * Future的get方法将在task执行成功后返回执行结果。 * * * If you would like to immediately block waiting * for a task, you can use constructions of the form * {@code result = exec.submit(aCallable).get();} * 如果想立即阻塞等待任务完成，可以使用如下结构形式 * result=exec.submit(aCallable).get(); // 提交任务，直接get等待 * * Note: The {@link Executors} class includes a set of methods * that can convert some other common closure-like objects, * for example, {@link java.security.PrivilegedAction} to * {@link Callable} form so they can be submitted. * 注意：Executors类包含了一系列的方法，可以将一些其他常见的类似闭包（closure-like）的对象（例如PrivilegedAction）转化为Callable形式， * 以便他们可以被提交 * * @param task the task to submit * task 提交的任务 * @param the type of the task's result * 泛型T代表任务的执行结果类型 * @return a Future representing pending completion of the task * Future代表等待task的执行 * @throws RejectedExecutionException if the task cannot be * scheduled for execution * RejectedExecutionException 如果该任务无法被execution安排执行（调度） * @throws NullPointerException if the task is null */ Future submit(Callable task); /** * Submits a Runnable task for execution and returns a Future * representing that task. The Future's {@code get} method will * return the given result upon successful completion. * 提交一个Runnable任务执行并返回一个表示该任务的Future。 * Future的get方法将在任务执行完成后返回给定的result（通过参数传入的result） * * @param task the task to submit * @param result the result to return * result 任务执行结束后的返回值 * @param the type of the result * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ Future submit(Runnable task, T result); /** * Submits a Runnable task for execution and returns a Future * representing that task. The Future's {@code get} method will * return {@code null} upon successful completion. * 提交一个Runnable任务执行并返回一个表示该任务的Future。 * Future的get方法在任务成功执行完成将返回null。 * * @param task the task to submit * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ Future submit(Runnable task); /** * Executes the given tasks, returning a list of Futures holding * their status and results when all complete. * {@link Future#isDone} is {@code true} for each * element of the returned list. * Note that a completed task could have * terminated either normally or by throwing an exception. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * 执行给定的任务集合，返回Future列表持有当所有任务都执行完成后的状态和结果。（该方法会等待wait，直到所有任务都完成） * Future的isDone方法对每一个返回列表元素都是true。 * 注意，已完成的任务可能是正常终止或者是抛出了异常。 * 如果给定的集合在此操作期间被修改，该方法的结果是未定义。 * * @param tasks the collection of tasks * @param the type of the values returned from the tasks * @return a list of Futures representing the tasks, in the same * sequential order as produced by the iterator for the * given task list, each of which has completed * 返回值 代表任务的Future列表，通过给定的task列表迭代器生成相同顺序的序列，每个任务都已完成。（因为这个方法会等待所有集合里的任务都执行完成） * @throws InterruptedException if interrupted while waiting, in * which case unfinished tasks are cancelled * InterruptedException，如果在等待时中断，在这种情况下未完成的任务将取消。 * @throws NullPointerException if tasks or any of its elements are {@code null} * @throws RejectedExecutionException if any task cannot be * scheduled for execution */ List> invokeAll(Collection> tasks) throws InterruptedException; /** * Executes the given tasks, returning a list of Futures holding * their status and results * when all complete or the timeout expires, whichever happens first. * {@link Future#isDone} is {@code true} for each * element of the returned list. * Upon return, tasks that have not completed are cancelled. * Note that a completed task could have * terminated either normally or by throwing an exception. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * 执行给定的任务集合，返回一个Future列表，持有当所有task完成，或者发生超时（以先发生的为准）后的状态与结果。 * Future的Done方法对每一个返回列表中的元素都是true。 * 返回后，未完成的任务将被取消。（在运行超时时，对于还没完成的任务就直接取消） * 注意，已完成的任务可能是正常终止或者是抛出了异常。 * 如果给定的集合在此操作期间被修改，该方法的结果是未定义 * * @param tasks the collection of tasks * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @param the type of the values returned from the tasks * @return a list of Futures representing the tasks, in the same * sequential order as produced by the iterator for the * given task list. If the operation did not time out, * each task will have completed. If it did time out, some * of these tasks will not have completed. * 如果没有超时操作，每个任务都将完成。 * 如果有超时，一些任务将无法完成。 * @throws InterruptedException if interrupted while waiting, in * which case unfinished tasks are cancelled * @throws NullPointerException if tasks, any of its elements, or * unit are {@code null} * @throws RejectedExecutionException if any task cannot be scheduled * for execution */ List> invokeAll(Collection> tasks, long timeout, TimeUnit unit) throws InterruptedException; /** * Executes the given tasks, returning the result * of one that has completed successfully (i.e., without throwing * an exception), if any do. Upon normal or exceptional return, * tasks that have not completed are cancelled. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * 执行给定的任务集合，返回其中一个成功完成的任务结果（即没有抛出异常），如果有的话。 * 在正常或者异常返回时，未完成的task将被取消。（意思是所有任务有一个正常执行完，其他任务就都取消？？？这大概就是invokeAny（执行任意一个）的含义） * 如果给定的集合在此操作期间被修改，该方法的结果是未定义 * * @param tasks the collection of tasks * @param the type of the values returned from the tasks * @return the result returned by one of the tasks * 返回值 返回其中一个任务的执行结果 * @throws InterruptedException if interrupted while waiting * @throws NullPointerException if tasks or any element task * subject to execution is {@code null} * @throws IllegalArgumentException if tasks is empty * @throws ExecutionException if no task successfully completes * @throws RejectedExecutionException if tasks cannot be scheduled * for execution */ T invokeAny(Collection> tasks) throws InterruptedException, ExecutionException; /** * Executes the given tasks, returning the result * of one that has completed successfully (i.e., without throwing * an exception), if any do before the given timeout elapses. * Upon normal or exceptional return, tasks that have not * completed are cancelled. * The results of this method are undefined if the given * collection is modified while this operation is in progress. * 执行给定的任务集合，返回其中一个成功完成的任务结果（即没有抛出异常），如果在超时之前有的话。 * 在正常或者异常返回时，未完成的task将被取消。（意思是所有任务有一个正常执行完，其他任务就都取消？？？） * 如果给定的集合在此操作期间被修改，该方法的结果是未定义 * * @param tasks the collection of tasks * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @param the type of the values returned from the tasks * @return the result returned by one of the tasks * @throws InterruptedException if interrupted while waiting * @throws NullPointerException if tasks, or unit, or any element * task subject to execution is {@code null} * @throws TimeoutException if the given timeout elapses before * any task successfully completes * @throws ExecutionException if no task successfully completes * @throws RejectedExecutionException if tasks cannot be scheduled * for execution */ T invokeAny(Collection> tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } "},"Doc/util/concurrent/Future.java.html":{"url":"Doc/util/concurrent/Future.java.html","title":"Future.Java","keywords":"","body":"Future /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; /** * A {@code Future} represents the result of an asynchronous * computation. Methods are provided to check if the computation is * complete, to wait for its completion, and to retrieve the result of * the computation. The result can only be retrieved using method * {@code get} when the computation has completed, blocking if * necessary until it is ready. Cancellation is performed by the * {@code cancel} method. Additional methods are provided to * determine if the task completed normally or was cancelled. Once a * computation has completed, the computation cannot be cancelled. * If you would like to use a {@code Future} for the sake * of cancellability but not provide a usable result, you can * declare types of the form {@code Future} and * return {@code null} as a result of the underlying task. * Future表示一个异步计算的结果。 * 提供的方法可以检查计算是否完成，等待计算完成，取回（retrieve）计算结果。 * 只能使用get方法在计算完成时取回结果，必要时阻塞，直到计算完成（结果准备好）。 * 通过cancel方法执行（performed）取消。 * 提供了额外的（additional）方法支持判断任务是正常完成还是被取消了。 * 一旦计算完成，那么计算就不能被取消了。 * 如果只是为了可取消性而想使用Future，不想提供可用的结果，可以声明Future这种类型的形式，返回null作为底层任务执行结果 * * * Sample Usage (Note that the following classes are all * made-up.) * 简单用例（下面的类都是虚构的（made-up）） * {@code * interface ArchiveSearcher { String search(String target); } * class App { * ExecutorService executor = ... * ArchiveSearcher searcher = ... * void showSearch(final String target) * throws InterruptedException { * Future future // -- 带有submit的方法start * = executor.submit(new Callable() { * public String call() { * return searcher.search(target); * }}); // -- 带有submit的方法end * displayOtherThings(); // do other things while searching * try { * displayText(future.get()); // use future * } catch (ExecutionException ex) { cleanup(); return; } * } * }} * * The {@link FutureTask} class is an implementation of {@code Future} that * implements {@code Runnable}, and so may be executed by an {@code Executor}. * FutureTask类是Future的实现类，实现了Runnable接口，可以被Executor执行。 * （因为Executor接口只有一个execute方法，执行传入的Runnable类型的对象） * * For example, the above construction with {@code submit} could be replaced by: * 例如，上面带有submit结构的代码，可以改成这个样子（这个样例看不出来改FutureTask的必要） * {@code * FutureTask future = * new FutureTask(new Callable() { * public String call() { * return searcher.search(target); * }}); * executor.execute(future);} * * Memory consistency effects: Actions taken by the asynchronous computation * happen-before * actions following the corresponding {@code Future.get()} in another thread. * 内存一致性的影响 * （跟以前的一样，不太明白这块的含义，这次不直译了） * * @see FutureTask * @see Executor * @since 1.5 * @author Doug Lea * @param The result type returned by this Future's {@code get} method */ public interface Future { /** * Attempts to cancel execution of this task. This attempt will * fail if the task has already completed, has already been cancelled, * or could not be cancelled for some other reason. If successful, * and this task has not started when {@code cancel} is called, * this task should never run. If the task has already started, * then the {@code mayInterruptIfRunning} parameter determines * whether the thread executing this task should be interrupted in * an attempt to stop the task. * 尝试取消该任务执行。 * 如果有以下情况任意一种发生，该尝试会失败： * 1、任务已经执行完毕 * 2、任务已经被取消 * 3、由于其他原因任务不能被取消 * 如果取消成功，若任务在被调用cancel取消之前尚未启动，那么该任务将永远不会启动了（任务还没开始执行就被取消了，那任务就不会启动了） * 如果任务已经开始执行了，那么通过mayInterruptIfRunning参数决定，是否通过中断执行该任务的线程来尝试停止任务执行。 * * After this method returns, subsequent calls to {@link #isDone} will * always return {@code true}. Subsequent calls to {@link #isCancelled} * will always return {@code true} if this method returned {@code true}. * 在该方法返回后，后续调用isDone方法将总是返回true。 * 如果该方法返回true，后续调用isCancelled方法也总是返回true * * @param mayInterruptIfRunning {@code true} if the thread executing this * task should be interrupted; otherwise, in-progress tasks are allowed * to complete * mayInterruptIfRunning参数为true时，执行该任务的线程应该被中断； * 除此之外，正在执行的任务被运行执行完毕。 * @return {@code false} if the task could not be cancelled, * typically because it has already completed normally; * 返回false，如果任务不能被取消，通常是由于该任务已经正常执行完毕了。 * {@code true} otherwise */ boolean cancel(boolean mayInterruptIfRunning); /** * Returns {@code true} if this task was cancelled before it completed * normally. * 如果该任务在正常完成前被取消，返回true * * @return {@code true} if this task was cancelled before it completed */ boolean isCancelled(); /** * Returns {@code true} if this task completed. * * Completion may be due to normal termination, an exception, or * cancellation -- in all of these cases, this method will return * {@code true}. * 完成有以下几种情况： * 1、正常结束 * 2、发生异常 * 3、被取消 * 所有这些场景，该方法都会返回true * * @return {@code true} if this task completed */ boolean isDone(); /** * Waits if necessary for the computation to complete, and then * retrieves its result. * 必要时等待计算完成，然后返回执行结果 * * @return the computed result * @throws CancellationException if the computation was cancelled * 如果在等待时发生取消，抛出CancellationException * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * 如果在等待时执行该任务的线程发生中断，抛出InterruptedException * while waiting */ V get() throws InterruptedException, ExecutionException; /** * Waits if necessary for at most the given time for the computation * to complete, and then retrieves its result, if available. * 必要时等待，如果在给定的时间内能够计算完成，那么返回结果。 * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting * @throws TimeoutException if the wait timed out */ V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } "},"Doc/util/concurrent/FutureTask.java.html":{"url":"Doc/util/concurrent/FutureTask.java.html","title":"FutureTask.Java","keywords":"","body":"FutureTask /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; import java.util.concurrent.locks.LockSupport; /** * A cancellable asynchronous computation. This class provides a base * implementation of {@link Future}, with methods to start and cancel * a computation, query to see if the computation is complete, and * retrieve the result of the computation. The result can only be * retrieved when the computation has completed; the {@code get} * methods will block if the computation has not yet completed. Once * the computation has completed, the computation cannot be restarted * or cancelled (unless the computation is invoked using * {@link #runAndReset}). * 支持取消的异步计算。 * 该类基于Future实现了一些方法，支持启动和取消计算，查询计算是否完成，返回计算结果。 * 只有在计算完成时，才能返回结果； * get方法将阻塞直到计算完成。 * 一旦计算完成，计算不能重新启动或者取消（除非该计算使用runAndReset调用） * * A {@code FutureTask} can be used to wrap a {@link Callable} or * {@link Runnable} object. Because {@code FutureTask} implements * {@code Runnable}, a {@code FutureTask} can be submitted to an * {@link Executor} for execution. * FutureTask可以用来包装（wrap）Callable或者Runnable对象。 * 因为FutureTask实现了Runnable接口，可以用于提交到Executor中执行（通过execute方法执行）。 * * In addition to serving as a standalone class, this class provides * {@code protected} functionality that may be useful when creating * customized task classes. * 除了作为独立使用的类外，该类提供的受保护的方法，在创建自定义任务类时可能很有用。 * * @since 1.5 * @author Doug Lea * @param The result type returned by this FutureTask's {@code get} methods * V表示get方法的返回值类型 */ public class FutureTask implements RunnableFuture { /* * Revision notes: This differs from previous versions of this * class that relied on AbstractQueuedSynchronizer, mainly to * avoid surprising users about retaining interrupt status during * cancellation races. Sync control in the current design relies * on a \"state\" field updated via CAS to track completion, along * with a simple Treiber stack to hold waiting threads. * 修订（revision）说明：与之前依赖AQS的版本不同，主要为了避免用户对于在取消竞争时仍保留中断状态而感到惊讶。 * 在当前设计中同步器依赖通过CAS更新的state字段来跟踪完成状态，以及简单的Treiber栈来保存等待线程。 * （Treiber Stack Algorithm是一个可扩展的无锁栈，利用细粒度的并发原语CAS来实现的） * * Style note: As usual, we bypass overhead of using * AtomicXFieldUpdaters and instead directly use Unsafe intrinsics. * 样式说明：像往常一样，绕过使用AtomicXFieldUpdaters的开销，直接使用Unsafe内部函数。 * */ /** * The run state of this task, initially NEW. The run state * transitions to a terminal state only in methods set, * setException, and cancel. During completion, state may take on * transient values of COMPLETING (while outcome is being set) or * INTERRUPTING (only while interrupting the runner to satisfy a * cancel(true)). Transitions from these intermediate to final * states use cheaper ordered/lazy writes because values are unique * and cannot be further modified. * 任务的执行状态（state），初始化是NEW。 * 运行状态仅在set、setException、cancel方法中会转变为终止（terminal）状态。 * 在完成期间，状态可能采用COMPLIETING（在设置结果时）或者INTERRUPTING（仅在中断运行程序以满足取消为true时）这种瞬时态。 * 从这些中间态到最终态的转化，使用cheaper有序/懒惰写入，因为值是唯一的并且无法进一步（further）修改。 * * Possible state transitions: * 可能的状态转化 * * NEW -> COMPLETING -> NORMAL * NEW -> COMPLETING -> EXCEPTIONAL * NEW -> CANCELLED * NEW -> INTERRUPTING -> INTERRUPTED */ private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; /** The underlying callable; nulled out after running */ // 底层的callable；执行完成后置为null。 private Callable callable; // 是需要执行的任务。 /** The result to return or exception to throw from get() */ // 通过get()返回的结果或者抛出的异常 private Object outcome; // non-volatile, protected by state reads/writes // 非volatile，受state的读/写保护 /** The thread running the callable; CASed during run() */ // 执行callable的线程；在run()期间CAS控制 private volatile Thread runner; // 执行任务的线程 /** Treiber stack of waiting threads */ // Treiber栈保存的等待线程 private volatile WaitNode waiters; // 用来指向第一个等待线程WaitNode，没有的话为null。这里的等待线程，是指的等待获取结果的线程，而不是执行任务的线程 /** * Returns result or throws exception for completed task. * 对于执行完成的任务，返回结果或者抛出异常 * * @param s completed state value */ @SuppressWarnings(\"unchecked\") private V report(int s) throws ExecutionException { Object x = outcome; if (s == NORMAL) // 当state处于NORMAL状态，直接返回执行结果 return (V)x; if (s >= CANCELLED) // 当state处于CANCELLED、INTERRUPTING、INTERRUPTED状态，抛出已取消异常。 throw new CancellationException(); throw new ExecutionException((Throwable)x); // 能到这里就剩EXCEPTIONAL了，因为只有state>COMPLETING的才能进入该方法，需要注意，这里把执行结果封装成了Exception给抛出了 // 构造该异常的流程为：public ExecutionException(Throwable cause)->public Exception(Throwable cause)->public Throwable(Throwable cause) } /** * Creates a {@code FutureTask} that will, upon running, execute the * given {@code Callable}. * FutureTask构造函数，将在运行时执行给定的Callable。 * * @param callable the callable task * @throws NullPointerException if the callable is null */ public FutureTask(Callable callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable } /** * Creates a {@code FutureTask} that will, upon running, execute the * given {@code Runnable}, and arrange that {@code get} will return the * given result on successful completion. * FutureTask构造函数，将在运行时执行给定的Runnable，并且安排（arrange）在成功完成后，get方法返回给定的result。 * * @param runnable the runnable task * @param result the result to return on successful completion. If * you don't need a particular result, consider using * constructions of the form: * {@code Future f = new FutureTask(runnable, null)} * result参数表示成功执行后的返回值，如果不需要特定的result，考虑使用这样形式的结构： * Future f = new FutureTask(runnable, null) * Void是java.lang.Void，是一个不可实例化的占位符类，用于对void关键字的引用。在这里表示无返回值。 * * @throws NullPointerException if the runnable is null */ public FutureTask(Runnable runnable, V result) { this.callable = Executors.callable(runnable, result); // 使用Executors工具类将Runnable适配为Callable（Executors.callable->Executors#RunnableAdapter类） this.state = NEW; // ensure visibility of callable } public boolean isCancelled() { return state >= CANCELLED; // 包括CANCELLED、INTERRUPTING、INTERRUPTED } public boolean isDone() { return state != NEW; // 不是NEW就算结束（包含瞬时态与其他结束态） } // 除了将NEW状态转化为INTERRUPTING/CANCELLED // 或者对于支持mayInterruptedIfRunning的，将非NEW状态转化为INTERRUPTED public boolean cancel(boolean mayInterruptIfRunning) { // 如果state=NEW，尝试直接设置state=INTERRUPTING（如果这样设置的话），否则设置state=CANCELLED来表示任务取消。（这里只是设置了状态，具体取消在后面） if (!(state == NEW && UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) // 如果mayInterruptIfRunning为true，表示通过中断执行该任务的线程来尝试停止任务执行，这里直接设置state=INTERRUPTING return false; try { // in case call to interrupt throws exception // 如果调用中断会抛出异常 if (mayInterruptIfRunning) { // 如果允许通过中断执行该任务的线程来停止任务执行 try { Thread t = runner; // runner是执行该callable的线程 if (t != null) t.interrupt(); // 中断该线程 } finally { // final state UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); // 最后，将state置为最终态INTERRUPTED（根据类开始的状态转化关系，只能是从瞬时态INTERRUPTING转化为INTERRUPTED） } } } finally { finishCompletion(); // 调用该方法，将所有的等待线程都唤醒与移除。这里runner线程与waitnode线程没有关系，runner是执行任务（callable）的线程，waitnode里的线程是想获取结果的线程 } return true; } /** * @throws CancellationException {@inheritDoc} */ public V get() throws InterruptedException, ExecutionException { int s = state; // 1、获取当前执行的状态state if (s COMPLETING）返回state值（如果本次加入了waiterNode，需要删除），如果=COMPLETING，那么让出CPU时间等待完成，如果不是完成态，那么park等待 return report(s); // 4、state表示正常结束就返回实际结果outcome，如果是CANCELLED或者两个INTERRUPT，抛出取消异常，如果是EXCEPTIONAL，抛出对应的异常。 } /** * @throws CancellationException {@inheritDoc} * 带有限时等待的get方法 */ public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { if (unit == null) // 如果限时为null，直接抛出异常 throw new NullPointerException(); int s = state; if (s This method is invoked internally by the {@link #run} method * upon successful completion of the computation. * 当计算成功结束的时候，该方法由run方法内部调用。 * * @param v the value */ protected void set(V v) { if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { // 将state从NEW更新为COMPLETING（如果已经设置过了，那么就不会重复设置） outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state // 用NORMAL覆盖瞬时态 finishCompletion(); // 释放所有阻塞等待执行结果的等待线程（基本都在awaitDone方法上阻塞了），好让他们拿到结果返回。 } } /** * Causes this future to report an {@link ExecutionException} * with the given throwable as its cause, unless this future has * already been set or has been cancelled. * 该future使用给定的throwable作为原因上报ExecutionException，除非该future已经被设置过或者被取消。 * * This method is invoked internally by the {@link #run} method * upon failure of the computation. * 当计算失败的时候，该方法由run方法内部调用。 * * @param t the cause of failure // t表示失败原因 */ protected void setException(Throwable t) { if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { // 将state从NEW更新为COMPLETING（如果已经设置过了，那么就不会重复设置） outcome = t; // 设置结果为异常原因 UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state // 用EXCEPTIONAL覆盖瞬时态 finishCompletion(); // 释放所有阻塞等待执行结果的等待线程 } } // run()是不返回结果的，结果需要通过get()方法获取 public void run() { if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) // 如果state不是NEW或者设置runner为当前线程失败，直接返回（有其他线程抢着做runner） return; try { Callable c = callable; if (c != null && state == NEW) { // 再次判断state V result; boolean ran; try { result = c.call(); // 等待执行完成 ran = true; } catch (Throwable ex) { result = null; ran = false; setException(ex); // 将outcome设置为对应的异常 } if (ran) set(result); // 将outcome设置为执行结果 } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() // runner必须不为null，直到state稳定（settled 固定的），以防止（prevent）并发调用run()方法。（是null的话run方法就可被并发调用执行） runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts // 将runner重置为null后，必须重新读取state，以防止泄露中断。（就是执行了上面那一步之后必须重新读取state） int s = state; if (s >= INTERRUPTING) handlePossibleCancellationInterrupt(s); // 如果进finally是因为cancel(true)引起的中断，那么等待中断完成。 } } /** * Executes the computation without setting its result, and then * resets this future to initial state, failing to do so if the * computation encounters an exception or is cancelled. This is * designed for use with tasks that intrinsically execute more * than once. * 执行计算多次但不设置结果，然后重置future为初识状态， * 如果计算遇到（encounter）异常或者被取消，则无法这么做。（无法重置为初始值） * 设计用于本质上（intrinsically）执行多次的任务。 * * @return {@code true} if successfully run and reset */ protected boolean runAndReset() { if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) // 如果state不是NEW或者设置runner为当前线程失败，直接返回（有其他线程抢着做runner） return false; boolean ran = false; int s = state; try { Callable c = callable; if (c != null && s == NEW) { try { c.call(); // don't set result // 不设置结果 ran = true; } catch (Throwable ex) { setException(ex); } } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts s = state; if (s >= INTERRUPTING) handlePossibleCancellationInterrupt(s); } return ran && s == NEW; // 如果执行成功，返回true（完成且没发生异常，异常有两个方面，一个是执行c.call的时候发生异常，一个是当前runner被cancel的异常） } /** * Ensures that any interrupt from a possible cancel(true) is only * delivered to a task while in run or runAndReset. * 确保可能来自cancel(true)的任何中断，仅在任务处于run或者runAndReset时传递给任务。 * 只有一个地方会设置state为INTERRUPTING状态，就是调用cancel(true)的时候。 * 调用cancel(true)，如果满足state==NEW，那么就设置为INTERRUPTING，直到runner.interrupt()执行完毕才设置INTERRUPTING状态为INTERRUPTED状态。 * */ private void handlePossibleCancellationInterrupt(int s) { // It is possible for our interrupter to stall before getting a // chance to interrupt us. Let's spin-wait patiently. // 可能我们的interrupter在获取机会中断我们之前会停止，只需要耐心的（patiently）自旋等待。 // if (s == INTERRUPTING) while (state == INTERRUPTING) Thread.yield(); // wait out pending interrupt // assert state == INTERRUPTED; // We want to clear any interrupt we may have received from // cancel(true). However, it is permissible to use interrupts // as an independent mechanism for a task to communicate with // its caller, and there is no way to clear only the // cancellation interrupt. // 我们想清除通过cancel(true)可能获得的任何中断。 // 然而，允许使用中断作为任务与其调用者之间的通信（communicate）的独立机制（java的基础机制）， // 所以没办法仅取消cancel中断。 // // Thread.interrupted(); } /** * Simple linked list nodes to record waiting threads in a Treiber * stack. See other classes such as Phaser and SynchronousQueue * for more detailed explanation. * 简单的链表节点，用于记录Treiber stack里等待线程。 * 有关更详细的说明，可以参阅其他类，例如Phaser与SynchronousQueue * */ static final class WaitNode { volatile Thread thread; // 保存当前线程（当前线程是一个等待获取执行结果的线程，不是执行任务的线程） volatile WaitNode next; // 用于指向下一个等待线程WaitNode WaitNode() { thread = Thread.currentThread(); } // 将线程封装成WaitNode } /** * Removes and signals all waiting threads, invokes done(), and * nulls out callable. * 移除和唤醒所有等待（想要拿到执行结果的）线程，调用done()方法，并将调用对象设置为null。 * */ private void finishCompletion() { // assert state > COMPLETING; // 这个assert本来就注释了 for (WaitNode q; (q = waiters) != null;) { // 遍历Treiber stack结构的等待线程队列（其实是个栈）（这里是不断的从第一个WaitNode（头）开始遍历） if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) { // 将q置为null for (;;) { Thread t = q.thread; if (t != null) { q.thread = null; LockSupport.unpark(t); // 唤醒当前WaitNode的线程 } WaitNode next = q.next; if (next == null) // 如果该节点的next为null，退出本层循环（说明这一次对等待线程的遍历完成了，已唤醒所有等待线程） break; q.next = null; // unlink to help gc // 将next打断，方便GC q = next; // 让q成为下一个waitNode，继续遍历 } break; } } done(); // 本类是空，子类可以根据需要自定义 callable = null; // to reduce footprint // 减少足迹？？？ } /** * Awaits completion or aborts on interrupt or timeout. * 等待完成，或者由于中断或者超时导致的终止。 * * @param timed true if use timed waits * timed true 如果使用限时等待 * @param nanos time to wait, if timed * nanos 时间值 如果需要限时等待 * @return state upon completion * 完成（或者超时）后返回状态（中断抛出异常） */ private int awaitDone(boolean timed, long nanos) throws InterruptedException { final long deadline = timed ? System.nanoTime() + nanos : 0L; // 1、如果需要限时等待，计算截止时间 WaitNode q = null; // 2、声明一个等待线程节点，等待执行结果 boolean queued = false; // queued表示当前等待节点是否已在Treiber stack等待队列（其实是个栈）里 for (;;) { if (Thread.interrupted()) { // 如果当前线程发生中断，移除等待结果的线程节点，抛出异常 removeWaiter(q); // 为什么要做这个呢？因为q可能在等待栈里，要从等待栈里给移除 throw new InterruptedException(); } int s = state; if (s > COMPLETING) { // 如果state状态成为完成态（包含完成、中断、取消） if (q != null) // 如果等待节点不为null，将等待节点的线程置为null（相当于打个标记，为以后removeWaiter()的时候可以删除，当然本次是不会去调用removeWaiter()了） q.thread = null; return s; // 返回执行状态 } else if (s == COMPLETING) // cannot time out yet Thread.yield(); // 处在完成的瞬时态，提示调度器当前线程可以暂时放弃CPU调度，等再被调度时不会走进park分支，直接判断state是否为完成态。 else if (q == null) q = new WaitNode(); // 第一轮没有拿到完成态，创建一个等待节点 else if (!queued) // 如果等待节点没在等待队列（其实是个栈）中，尝试入队 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); // 新入栈的在栈顶，让当前节点next指向原栈顶元素，然后将当前节点入栈 else if (timed) { // 如果需要限时，判断是否等待超时，超时的等待将从等待栈中移除 nanos = deadline - System.nanoTime(); if (nanos k = FutureTask.class; stateOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"state\")); runnerOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"runner\")); waitersOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"waiters\")); } catch (Exception e) { throw new Error(e); } } } "},"Doc/util/concurrent/RunnableFuture.java.html":{"url":"Doc/util/concurrent/RunnableFuture.java.html","title":"RunnableFuture.Java","keywords":"","body":"RunnableFuture /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; /** * A {@link Future} that is {@link Runnable}. Successful execution of * the {@code run} method causes completion of the {@code Future} * and allows access to its results. * Runnable形式的Future。 * run方法的成功执行会导致Future完成，并允许通过Future访问执行结果。 * * @see FutureTask * @see Executor * @since 1.6 * @author Doug Lea * @param The result type returned by this Future's {@code get} method */ public interface RunnableFuture extends Runnable, Future { /** * Sets this Future to the result of its computation * unless it has been cancelled. * 设置该Future为计算结果，除非被取消 */ void run(); } "},"Doc/util/concurrent/ThreadPoolExecutor.java.html":{"url":"Doc/util/concurrent/ThreadPoolExecutor.java.html","title":"ThreadPoolExecutor.Java","keywords":"","body":"ThreadPoolExecutor /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent; import java.util.concurrent.locks.AbstractQueuedSynchronizer; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.ReentrantLock; import java.util.concurrent.atomic.AtomicInteger; import java.util.*; /** * An {@link ExecutorService} that executes each submitted task using * one of possibly several pooled threads, normally configured * using {@link Executors} factory methods. * 一个ExecutorService，使用可能的几个线程池之一执行提交的任务， * 通常使用Executors工厂方法来配置。 * （通常用Executors工厂方法来生成该类实例，比如给定线程池、线程数等，不过现在不推荐使用） * * Thread pools address two different problems: they usually * provide improved performance when executing large numbers of * asynchronous tasks, due to reduced per-task invocation overhead, * and they provide a means of bounding and managing the resources, * including threads, consumed when executing a collection of tasks. * Each {@code ThreadPoolExecutor} also maintains some basic * statistics, such as the number of completed tasks. * 线程池解决（address）两个不同的问题： * 1、通过减少每个任务的调用开销，通常在执行大量异步任务时提供高效（improved）性能（performance）。 * 2、提供限制（bounding）和管理资源的方法，包括执行任务集合时消耗的线程。 * 每个ThreadPoolExecutor也维护（maintain）一些基本的统计信息，例如已完成任务的数量。 * * To be useful across a wide range of contexts, this class * provides many adjustable parameters and extensibility * hooks. However, programmers are urged to use the more convenient * {@link Executors} factory methods {@link * Executors#newCachedThreadPool} (unbounded thread pool, with * automatic thread reclamation), {@link Executors#newFixedThreadPool} * (fixed size thread pool) and {@link * Executors#newSingleThreadExecutor} (single background thread), that * preconfigure settings for the most common usage * scenarios. Otherwise, use the following guide when manually * configuring and tuning this class: * 为了在广泛的上下文中有用，该类提供了许多可调整的参数和可扩展的钩子方法（hooks）。 * 但是，强烈建议（urge 敦促）程序员使用更方便的（convenient）Executors提供的工厂方法： * Executors#newCachedThreadPool：无界线程池，具有自动线程回收（reclamation） * Executors#newFixedThreadPool：固定大小线程池 * Executors#newSingleThreadExecutor：单个后台线程 * 他们预先配置了最常见的使用场景（scenarios）。 * 否则，在手工（manually）配置与调整（tuning）此类时，使用如下指南： * * * * Core and maximum pool sizes * 核心和最大（池中）线程数 * * A {@code ThreadPoolExecutor} will automatically adjust the * pool size (see {@link #getPoolSize}) * according to the bounds set by * corePoolSize (see {@link #getCorePoolSize}) and * maximumPoolSize (see {@link #getMaximumPoolSize}). * ThreadPoolExecutor会依据corePoolSize（getCorePoolSize）与maximumPoolSize（getMaximumPoolSize）设置的边界， * 自动调整池大小（用getPoolSize查询） * * When a new task is submitted in method {@link #execute(Runnable)}, * and fewer than corePoolSize threads are running, a new thread is * created to handle the request, even if other worker threads are * idle. If there are more than corePoolSize but less than * maximumPoolSize threads running, a new thread will be created only * if the queue is full. By setting corePoolSize and maximumPoolSize * the same, you create a fixed-size thread pool. By setting * maximumPoolSize to an essentially unbounded value such as {@code * Integer.MAX_VALUE}, you allow the pool to accommodate an arbitrary * number of concurrent tasks. Most typically, core and maximum pool * sizes are set only upon construction, but they may also be changed * dynamically using {@link #setCorePoolSize} and {@link * #setMaximumPoolSize}. * 当使用execute(Runnable)提交任务， * 1、如果当前运行的线程数小于corePoolSize时，新的线程被创建来处理该请求（任务），即使其他线程空闲。 * 2、如果当前运行的线程数大于corePoolSize但小于maximumPoolSize时，只有在队列（等待处理的队列）满的时候才会创建新的线程。 * 通过设置corePoolSize等于maximumPoolSize，就创建了一个固定大小的线程池。 * 通过设置maximumPoolSize设置为一个本质上（essentially）无界值（例如Integer.MAX_VALUE），可以允许线程池适应（accommodate 容纳）任意（arbitrary）数量的并发线程。 * 最典型的是，核心和最大线程池大小只在构造时设置，但也可以视同setCorePoolSize与setMaximumPoolSize来动态更改。 * * On-demand construction * 按需构建 * * By default, even core threads are initially created and * started only when new tasks arrive, but this can be overridden * dynamically using method {@link #prestartCoreThread} or {@link * #prestartAllCoreThreads}. You probably want to prestart threads if * you construct the pool with a non-empty queue. * 默认情况下，即使核心线程也仅在新的任务到达时才初始化创建与启动，但可以使用prestartCoreThread或者prestartAllCoreThreads方法动态覆盖（该模式） * 如果使用非空队列构建线程池时，可能想预启动线程。 * * Creating new threads * 创建新线程 * * New threads are created using a {@link ThreadFactory}. If not * otherwise specified, a {@link Executors#defaultThreadFactory} is * used, that creates threads to all be in the same {@link * ThreadGroup} and with the same {@code NORM_PRIORITY} priority and * non-daemon status. By supplying a different ThreadFactory, you can * alter the thread's name, thread group, priority, daemon status, * etc. If a {@code ThreadFactory} fails to create a thread when asked * by returning null from {@code newThread}, the executor will * continue, but might not be able to execute any tasks. Threads * should possess the \"modifyThread\" {@code RuntimePermission}. If * worker threads or other threads using the pool do not possess this * permission, service may be degraded: configuration changes may not * take effect in a timely manner, and a shutdown pool may remain in a * state in which termination is possible but not completed. * 使用ThreadFactory创建新的线程。 * 如果没有另外指定，使用Executors#defaultThreadFactory，所有创建的线程使用相同的ThreadGroup、相同的NORM_PRIORITY优先级和非守护的进程状态。 * 通过提供不同的ThreadFactory，可以更改线程名、线程组、优先级、守护进程状态等。 * 如果在调用ThreadFactory的newThread方法返回null时，则创建线程失败，executor将继续运行，但可能无法执行任何任务。 * 线程应该拥有modifyThread的RuntimePermission（运行时权限）。 * 如果使用线程池的worker线程或者其他线程没有拥有该权限，则服务可能会被降级（degrade）： * 1、参数修改可能无法及时生效 * 2、关闭线程池可能停留在可以终止但未完成状态 * * Keep-alive times * 保持活跃的时间 * * If the pool currently has more than corePoolSize threads, * excess threads will be terminated if they have been idle for more * than the keepAliveTime (see {@link #getKeepAliveTime(TimeUnit)}). * This provides a means of reducing resource consumption when the * pool is not being actively used. If the pool becomes more active * later, new threads will be constructed. This parameter can also be * changed dynamically using method {@link #setKeepAliveTime(long, * TimeUnit)}. Using a value of {@code Long.MAX_VALUE} {@link * TimeUnit#NANOSECONDS} effectively disables idle threads from ever * terminating prior to shut down. By default, the keep-alive policy * applies only when there are more than corePoolSize threads. But * method {@link #allowCoreThreadTimeOut(boolean)} can be used to * apply this time-out policy to core threads as well, so long as the * keepAliveTime value is non-zero. * 如果当前线程池中线程数超过corePoolSize，多余的线程将在空闲时间超过KeepAliveTime（见getKeepAliveTime(TimeUnit)）时被终止。 * 这提供了一种方法，在线程池未充分利用的情况下减少资源的消耗（consumption）。 * 如果线程池稍后变得活跃（使用频率变高），则将构建新的线程。 * 该参数可以使用setKeepAliveTime(long, TimeUnit)方法动态修改。 * 使用Long.MAX_VALUE TimeUnit#NANOSECONDS值可以有效禁止空闲线程在线程池关闭之前被终止。 * 默认情况下，keep-alive策略仅在有线程超过corePoolSize的时候才会适用。 * 但是allowCoreThreadTimeOut(boolean)方法，可以用于核心线程的time-out策略，前提是keepAliveTime值不为0。 *（就是默认情况下，keepAliveTime仅能控制非核心线程的存活时间，allowCoreThreadTimeOut方法可以控制将keepAliveTime用于核心线程） * * Queuing * 队列 * * Any {@link BlockingQueue} may be used to transfer and hold * submitted tasks. The use of this queue interacts with pool sizing: * 任意BlockingQueue都可以用于传递和保存提交的任务。 * 使用该队列与线程池大小交互如下： * * * * If fewer than corePoolSize threads are running, the Executor * always prefers adding a new thread * rather than queuing. * 如果运行线程数 If corePoolSize or more threads are running, the Executor * always prefers queuing a request rather than adding a new * thread. * 如果运行线程数 >= coolPoolSize，Executor总是喜欢将请求入队而不是添加新线程。 * * If a request cannot be queued, a new thread is created unless * this would exceed maximumPoolSize, in which case, the task will be * rejected. * 如果请求无法入队，创建新线程，除非线程数将超过（exceed）maximumPoolSize，在这种情况下，该任务将被拒绝（reject） * * * * There are three general strategies for queuing: * 对于队列的三种常见策略： * * * * Direct handoffs. A good default choice for a work * queue is a {@link SynchronousQueue} that hands off tasks to threads * without otherwise holding them. Here, an attempt to queue a task * will fail if no threads are immediately available to run it, so a * new thread will be constructed. This policy avoids lockups when * handling sets of requests that might have internal dependencies. * Direct handoffs generally require unbounded maximumPoolSizes to * avoid rejection of new submitted tasks. This in turn admits the * possibility of unbounded thread growth when commands continue to * arrive on average faster than they can be processed. * Direct handoffs（直接交接/直接握手）。 * 工作队列一个好的默认选择是SynchronousQueue，将任务提交（hand off）给线程而不用其他方式保留任务。 * 在这里，如果没有线程可立即执行任务，尝试将任务入队会失败，所以将创建新的线程。 * 该策略避免锁定，当处理的请求集可能含有内部依赖的时候。 * Direct handoffs通常需要maximumPoolSize是无界的，以避免新提交的任务被拒绝。 * 这反过来（turn）又承认（admit）了存在这种可能性：当commands持续到达的平均速度比处理速度快时，线程将无限增长。 * * Unbounded queues. Using an unbounded queue (for * example a {@link LinkedBlockingQueue} without a predefined * capacity) will cause new tasks to wait in the queue when all * corePoolSize threads are busy. Thus, no more than corePoolSize * threads will ever be created. (And the value of the maximumPoolSize * therefore doesn't have any effect.) This may be appropriate when * each task is completely independent of others, so tasks cannot * affect each others execution; for example, in a web page server. * While this style of queuing can be useful in smoothing out * transient bursts of requests, it admits the possibility of * unbounded work queue growth when commands continue to arrive on * average faster than they can be processed. * Unbounded queues（无界队列） * 使用无界队列（例如没有预先设置容量的LinkedBlockingQueue）将导致在所有corePoolSize的线程都忙的时候，新任务在队列中等待。 * 因此，创建的线程数不会超过corePoolSize。（并且，maximumPoolSize值因此不会有任何影响（没啥用）） * 这可能适用于：每个任务完全互相独立，因此每个任务不会影响彼此的执行； * 例如，在网页服务中，尽管这种风格的队列对于平滑处理突发请求很有用，但在commands持续到达平均速度超过服务处理速度时，会导致工作队列无限增长。 * * Bounded queues. A bounded queue (for example, an * {@link ArrayBlockingQueue}) helps prevent resource exhaustion when * used with finite maximumPoolSizes, but can be more difficult to * tune and control. Queue sizes and maximum pool sizes may be traded * off for each other: Using large queues and small pools minimizes * CPU usage, OS resources, and context-switching overhead, but can * lead to artificially low throughput. If tasks frequently block (for * example if they are I/O bound), a system may be able to schedule * time for more threads than you otherwise allow. Use of small queues * generally requires larger pool sizes, which keeps CPUs busier but * may encounter unacceptable scheduling overhead, which also * decreases throughput. * Bounded queues（有界队列） * 有界队列（例如ArrayBlockingQueue）当与有限的（finite）maximumPoolSize一起使用时，有助于避免资源耗尽（exhaustion），但可能难以调整和控制。 * 队列大小和最大线程池大小可能互相影响（traded off 折中）： * 使用大队列和小线程池数将最大限度的减少CPU使用率、OS资源和上下文切换开销，但是会认为的（artificially）降低吞吐量。 * 如果任务频繁（frequently）阻塞（例如受限于I/O），跟你允许的线程数比，系统可能能够安排时间给更多的线程。 * （就是对于I/O密集型的任务，那么系统可以设置更多的线程来使用CPU等资源，如果设置的线程池数过小，就会导致吞吐量降低） * 使用小队列通常需要大线程池数，用于保持CPU繁忙，但是可能会遇到不可接受的调度开销，这也会降低吞吐量。 * （就是对于CPU密集型任务，如果线程过多，会频繁发生线程调用上下文切换，额外的调度开销） * * * * * * Rejected tasks * 拒绝任务 * * New tasks submitted in method {@link #execute(Runnable)} will be * rejected when the Executor has been shut down, and also when * the Executor uses finite bounds for both maximum threads and work queue * capacity, and is saturated. In either case, the {@code execute} method * invokes the {@link * RejectedExecutionHandler#rejectedExecution(Runnable, ThreadPoolExecutor)} * method of its {@link RejectedExecutionHandler}. Four predefined handler * policies are provided: * 通过execute(Runnable)方法提交新任务可能被拒绝，1、当Executor已经被关闭，2、或者当Executor在最大线程数与工作队列容量使用有界限制达到饱和（saturated）。 * 无论哪种场景，execute方法都会调用RejectedExecutionHandler的RejectedExecutionHandle#rejectedException(Runnable, ThreadPoolExecutor)方法。 * 支持四种预定义的handler策略： * * * * In the default {@link ThreadPoolExecutor.AbortPolicy}, the * handler throws a runtime {@link RejectedExecutionException} upon * rejection. * （本任务丢弃策略，抛出异常） * 默认策略为ThreadPoolExecutor.AbortPolicy，该处理器在拒绝时抛出运行时RejectedExecutionException * * In {@link ThreadPoolExecutor.CallerRunsPolicy}, the thread * that invokes {@code execute} itself runs the task. This provides a * simple feedback control mechanism that will slow down the rate that * new tasks are submitted. * （调用者执行策略） * 在ThreadPoolExecutor.CallerRunsPolicy，调用execute的线程自己执行该任务（被线程池拒绝的任务）。 * 这提供了一种简单的反馈（feedback）控制机制，可以减慢提交新任务的速度（rate）。 * * In {@link ThreadPoolExecutor.DiscardPolicy}, a task that * cannot be executed is simply dropped. * （本任务直接丢弃策略） * 在ThreadPoolExecutor.DiscardPolicy，无法执行的任务只是简单的丢弃。（不执行也不抛出异常） * （discard 丢弃） * * In {@link ThreadPoolExecutor.DiscardOldestPolicy}, if the * executor is not shut down, the task at the head of the work queue * is dropped, and then execution is retried (which can fail again, * causing this to be repeated.) * （最老任务丢弃策略） * 在ThreadPoolExecutor.DiscardOldestPolicy，如果执行器没有被关闭，在工作队列队首的任务被抛弃，然后重试（retried）执行（有可能再次失败，导致该操作不断重复执行） * * * * It is possible to define and use other kinds of {@link * RejectedExecutionHandler} classes. Doing so requires some care * especially when policies are designed to work only under particular * capacity or queuing policies. * 可以定义和使用其他类型的RejectedExceptionHandler类。 * 这样做需要谨慎，尤其是当策略设计仅在特定（particular）容量或者排队策略下工作时。 * * Hook methods * 钩子函数 * * This class provides {@code protected} overridable * {@link #beforeExecute(Thread, Runnable)} and * {@link #afterExecute(Runnable, Throwable)} methods that are called * before and after execution of each task. These can be used to * manipulate the execution environment; for example, reinitializing * ThreadLocals, gathering statistics, or adding log entries. * Additionally, method {@link #terminated} can be overridden to perform * any special processing that needs to be done once the Executor has * fully terminated. * 该类提供受保护的可覆盖的beforeExecute(Thread, Runnable)和afterExecute(Runnable, Throwable)方法，在每个任务执行之前与之后被调用。 * 这些可以用于操作（manipulate）执行环境；例如，重新初始化Threadlocals、收集（gather）统计信息、或者添加日志条目（entries）。 * 此外，可以覆盖terminated方法，在Executor完全（fully）终止后，执行（perform）需要做的特殊处理。 * （提及三个钩子方法：beforeExecute、afterExecute、terminated） * * If hook or callback methods throw exceptions, internal worker * threads may in turn fail and abruptly terminate. * 如果hook或者回调（callback）方法抛出异常，内部worker线程可能反过来失败并且突然（abruptly）终止。 * （就是钩子方法或者回调方法抛出异常的话，会影响该worker线程失败与终止） * * Queue maintenance * 队列维护 * * Method {@link #getQueue()} allows access to the work queue * for purposes of monitoring and debugging. Use of this method for * any other purpose is strongly discouraged. Two supplied methods, * {@link #remove(Runnable)} and {@link #purge} are available to * assist in storage reclamation when large numbers of queued tasks * become cancelled. * getQueue()方法允许访问该线程队列，用于监控和debug目的。 * 强烈建议不要（discouraged 不建议）将该方法用于其他目的。 * 提供的两个方法remove(Runnable)和purge，在大量入队的任务被取消时，可用于协助存储回收（reclamation）。 * * Finalization * 定稿？？？ * * A pool that is no longer referenced in a program AND * has no remaining threads will be {@code shutdown} automatically. If * you would like to ensure that unreferenced pools are reclaimed even * if users forget to call {@link #shutdown}, then you must arrange * that unused threads eventually die, by setting appropriate * keep-alive times, using a lower bound of zero core threads and/or * setting {@link #allowCoreThreadTimeOut(boolean)}. * 程序中不再被引用并且没有剩余（remain）线程的线程池将被自动关闭。 * 如果你想确保未引用的线程池被回收，即使使用者忘记调用shutdown， * 那么你必须安排未使用的线程最终（eventually）死亡，通过设置适当的（appropriate）keep-alive时间、使用0核心线程数的下限并且/或者设置allowCoreThreadTimeOut(boolean)。 * （corePoolSize为0时，allowCoreThreadTimeOut这个方法可设可不设，corePoolSize不为0时，必须设） * （如果线程池中没有存活线程，并且线程池没有被引用，那么线程池对象就会被自动回收） * * * * Extension example. Most extensions of this class * override one or more of the protected hook methods. For example, * here is a subclass that adds a simple pause/resume feature: * 扩展样例。大多数该类的扩展类都会覆盖一个或多个受保护的hook方法。 * 例如，下面这个子类增加了一个简单的暂停/恢复功能（feature 特性）。 * * {@code * class PausableThreadPoolExecutor extends ThreadPoolExecutor { * private boolean isPaused; * private ReentrantLock pauseLock = new ReentrantLock(); // 看着陌生的话可以先看看Lock、Condition、AQS、ReentrantLock部分源码 * private Condition unpaused = pauseLock.newCondition(); * * public PausableThreadPoolExecutor(...) { super(...); } * * protected void beforeExecute(Thread t, Runnable r) { * super.beforeExecute(t, r); * pauseLock.lock(); * try { * while (isPaused) unpaused.await(); * } catch (InterruptedException ie) { * t.interrupt(); * } finally { * pauseLock.unlock(); * } * } * * public void pause() { * pauseLock.lock(); * try { * isPaused = true; * } finally { * pauseLock.unlock(); * } * } * * public void resume() { * pauseLock.lock(); * try { * isPaused = false; * unpaused.signalAll(); * } finally { * pauseLock.unlock(); * } * } * }} * * @since 1.5 * @author Doug Lea */ public class ThreadPoolExecutor extends AbstractExecutorService { /** * The main pool control state, ctl, is an atomic integer packing * two conceptual fields * workerCount, indicating the effective number of threads * runState, indicating whether running, shutting down etc * ctl，线程池主要的控制状态，是一个原子integer，包含两个概念（conceptual）字段 * workerCount，代表有效的线程数 * runState， 代表线程池状态是否为运行、关闭等 * * In order to pack them into one int, we limit workerCount to * (2^29)-1 (about 500 million) threads rather than (2^31)-1 (2 * billion) otherwise representable. If this is ever an issue in * the future, the variable can be changed to be an AtomicLong, * and the shift/mask constants below adjusted. But until the need * arises, this code is a bit faster and simpler using an int. * 为了将这两个字段打包成一个int，将workerCount限制为(2^29)-1个线程，而不是(2^31)-1个其他可表示的线程。 * 如果这在将来成为问题，该变量（variable）ctl可以改为AtomicLong类型，并调整下面的移位/掩码常量。（常量指的COUNT_BITS） * 但是在需要之前（arises 出现），这段代码使用int会更快更简单。 * * The workerCount is the number of workers that have been * permitted to start and not permitted to stop. The value may be * transiently different from the actual number of live threads, * for example when a ThreadFactory fails to create a thread when * asked, and when exiting threads are still performing * bookkeeping before terminating. The user-visible pool size is * reported as the current size of the workers set. * workerCount表示已经被允许启动但未允许停止的worker数量。 * 这个值可能和实际活动线程数暂时（transiently）不一致，（不保证一致是因为workerCount-1操作与workers.remove(w)不是一个Lock锁下的同步操作） * 例如，当ThreadFactory创建线程失败，当退出线程在终止前仍旧执行bookkeeping。 * 用户可见的线程池大小代表worker集当前大小。 * * The runState provides the main lifecycle control, taking on values: * runState提供主要的生命周期控制，取值如下： * * RUNNING: Accept new tasks and process queued tasks * 接受新任务并处理队列中的任务 * SHUTDOWN: Don't accept new tasks, but process queued tasks * 不接受新任务，但处理队列中的任务 * STOP: Don't accept new tasks, don't process queued tasks, * and interrupt in-progress tasks * 不接受新任务，不处理队列中的任务 * 并且中断正在处理的任务 * TIDYING: All tasks have terminated, workerCount is zero, * the thread transitioning to state TIDYING * will run the terminated() hook method * 所有任务已经终止，workerCount为0， * 线程转化为TIDYING状态（TIDYING 整理） * 将执行terminated()钩子方法 * TERMINATED: terminated() has completed * terminated()方法执行完毕 * * * The numerical order among these values matters, to allow * ordered comparisons. The runState monotonically increases over * time, but need not hit each state. The transitions are: * 该值（指的runState）之间的数字（numerical）顺序很重要（matter），以允许进行有序比较。 * runState跟随时间单调（monotonically）递增，但不需要命中每个状态（就是不需要按顺序递增，比如不需要-1、0、1、2、3这样增，可以跳为-1、1这样，只要单调递增就行） * 过渡是： * * RUNNING -> SHUTDOWN * On invocation of shutdown(), perhaps implicitly in finalize() * 从RUNNING转化为SHUTDOWN：在调用shutdown()时，可能（perhaps）隐藏（implicitly）在finalize()方法中（finalize()中会执行shutdown()） * (RUNNING or SHUTDOWN) -> STOP * On invocation of shutdownNow() * （RUNNING或者SHUTDOWN）转化为STOP：在调用shutdownNow()的时候（转化为STOP状态会remove掉队列里的所有任务？？？） * SHUTDOWN -> TIDYING * When both queue and pool are empty * SHUTDOWN转化为TIDYING：当队列与线程池都为空时 * STOP -> TIDYING * When pool is empty * STOP转化为TIDYING：当线程池为空时 * TIDYING -> TERMINATED * When the terminated() hook method has completed * TIDYING转化为TERMINATED：当terminated()钩子方法执行完毕 * * Threads waiting in awaitTermination() will return when the * state reaches TERMINATED. * 在awaitTermination()方法上等待的线程，将在状态到达TERMINATED时返回。 * * Detecting the transition from SHUTDOWN to TIDYING is less * straightforward than you'd like because the queue may become * empty after non-empty and vice versa during SHUTDOWN state, but * we can only terminate if, after seeing that it is empty, we see * that workerCount is 0 (which sometimes entails a recheck -- see * below). * 检测（detecting）从SHUTDOWN到TIDYING的转变并不像你想要的那么直接（straightforward）， * 因为在SHUTDOWN状态期间，队列可能从非空变为空，反之亦然（vice versa），（就是不能保证队列是否一定为空，因为会变化） * 但是我们只能在看到队列为空之后，再检查workerCount也是0时，才终止（有些时候需要（entail 包含）复查 -- 见下文） * */ private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 线程池主要控制状态，初始化为runState=RUNNING，workerCount=0 private static final int COUNT_BITS = Integer.SIZE - 3; // 总位数 private static final int CAPACITY = (1 = s; } // 判断线程池状态是否为running（c workQueue; /** * Lock held on access to workers set and related bookkeeping. * While we could use a concurrent set of some sort, it turns out * to be generally preferable to use a lock. Among the reasons is * that this serializes interruptIdleWorkers, which avoids * unnecessary interrupt storms, especially during shutdown. * Otherwise exiting threads would concurrently interrupt those * that have not yet interrupted. It also simplifies some of the * associated statistics bookkeeping of largestPoolSize etc. We * also hold mainLock on shutdown and shutdownNow, for the sake of * ensuring workers set is stable while separately checking * permission to interrupt and actually interrupting. * 对设置（操作）workers与关联bookkeeping进行加锁访问。 * 尽管可以使用某种（some sort）并发集，结果（turn out）证明通常最好使用锁。 * 其中一个原因是它序列化了interruptIdleWorkers，避免了不必要的中断风暴，尤其是在线程池shutdown的时候。 * 否则退出线程将同时中断那些尚未中断的线程。（可能n个中断线程并发去中断1个尚未中断的线程） * 它还简化了最大线程池数等关联统计bookkeeping。 * 也在shutdown与shutdownNow的时候持有mainLock，为了确保worker集合在分别检查中断权限和实际中断时保持稳定 * （几乎所有涉及到对workers这个集合的操作，都要加mainLock锁） * */ private final ReentrantLock mainLock = new ReentrantLock(); /** * Set containing all worker threads in pool. Accessed only when * holding mainLock. * 集合包含线程池里所有的worker线程。 * 只有在持有mainLock锁时才能访问。 * */ private final HashSet workers = new HashSet(); /** * Wait condition to support awaitTermination * 在条件上等待，支持awaitTermination * （不好翻译，可以先看看Condition接口源码） * */ private final Condition termination = mainLock.newCondition(); /** * Tracks largest attained pool size. Accessed only under * mainLock. * 跟踪线程池到达的最大线程数。 * 只有持有mainLock时才能访问。 * */ private int largestPoolSize; /** * Counter for completed tasks. Updated only on termination of * worker threads. Accessed only under mainLock. * 统计已完成任务数。 * 仅在worker线程结束后更新该值。（可见processWorkerExit方法） * 只有持有mainLock才能访问。 * */ private long completedTaskCount; /* * All user control parameters are declared as volatiles so that * ongoing actions are based on freshest values, but without need * for locking, since no internal invariants depend on them * changing synchronously with respect to other actions. * 所有用户控制的参数都被声明为volatile，以便在进行的动作都基于最新的值， * 但不需要加锁，因为没有内部不变量（invariants）依赖其他动作进行同步修改。 * */ /** * Factory for new threads. All threads are created using this * factory (via method addWorker). All callers must be prepared * for addWorker to fail, which may reflect a system or user's * policy limiting the number of threads. Even though it is not * treated as an error, failure to create threads may result in * new tasks being rejected or existing ones remaining stuck in * the queue. * 新线程的工厂。所有线程都通过该factory来创建（通过addWorker方法）。 * 所有调用者都必须准备好对addWorker失败的处理，这可能反映了系统或者使用者限制线程数的策略。 * 即使它没有被作为（treat 对待）error，创建线程失败可能导致新的任务被拒绝或者现有任务卡在队列中。 * * We go further and preserve pool invariants even in the face of * errors such as OutOfMemoryError, that might be thrown while * trying to create threads. Such errors are rather common due to * the need to allocate a native stack in Thread.start, and users * will want to perform clean pool shutdown to clean up. There * will likely be enough memory available for the cleanup code to * complete without encountering yet another OutOfMemoryError. * 我们更进一步，即使在面临异常例如在创建线程时可能抛出OOM异常，也保留线程池的不变量。 * 由于在Thread.start时需要从本地栈中分配，因此这类error相当常见，并且用户希望干净的shutdown线程池来进行清理。（清理从栈上分配的线程空间？？？） * 可能有足够的内存可用于清理代码完成，而不会遇到其他OOM异常。 * */ private volatile ThreadFactory threadFactory; /** * Handler called when saturated or shutdown in execute. * 当饱和（saturated 饱和的）或者shutdown时执行的handler。（用于处理那些线程池处理不了的task） * */ private volatile RejectedExecutionHandler handler; /** * Timeout in nanoseconds for idle threads waiting for work. * Threads use this timeout when there are more than corePoolSize * present or if allowCoreThreadTimeOut. Otherwise they wait * forever for new work. * 空闲线程最大等待作业时间。（单位：纳秒） * 线程使用此超时： * 1、当前线程数超过corePoolSize（核心线程数） * 2、允许核心线程超时退出（allowCoreThreadTimeOut） * 否则会永久等待新的作业。 * */ private volatile long keepAliveTime; /** * If false (default), core threads stay alive even when idle. * If true, core threads use keepAliveTime to time out waiting * for work. * 如果为false（也是默认值），核心线程即使空闲也会保持活跃（alive）。 * 如果为true，核心线程在等待作业时使用keepAliveTime设置的限时时间。（超时退出） * */ private volatile boolean allowCoreThreadTimeOut; /** * Core pool size is the minimum number of workers to keep alive * (and not allow to time out etc) unless allowCoreThreadTimeOut * is set, in which case the minimum is zero. * 核心线程池大小是保持活跃（并且不允许超时等）的worker最小值，除非设置了allowCoreThreadTimeOut（设置allowCoreThreadTimeOut的场景下，线程数最小值为0） * （注意：0= 0 && (t = thread) != null && !t.isInterrupted()) { // 判断执行当前worker的线程是否已启动。state有值，thread不为null，thread没有中断 try { t.interrupt(); } catch (SecurityException ignore) { // 捕获异常并忽略 } } } } /* * Methods for setting control state * 设置控制状态的方法 */ /** * Transitions runState to given target, or leaves it alone if * already at least the given target. * 将runState转化为给定的目标值，如果runState的值已经>=给定的目标值，则不做任何操作。 * * @param targetState the desired state, either SHUTDOWN or STOP * (but not TIDYING or TERMINATED -- use tryTerminate for that) * targetState，所需的状态，只能为SHUTDOWN或者STOP * 如果想修改runState为TIDYING或者TERMINATED，那么使用tryTerminate方法 */ private void advanceRunState(int targetState) { for (;;) { int c = ctl.get(); if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) break; } } /** * Transitions to TERMINATED state if either (SHUTDOWN and pool * and queue empty) or (STOP and pool empty). If otherwise * eligible to terminate but workerCount is nonzero, interrupts an * idle worker to ensure that shutdown signals propagate. This * method must be called following any action that might make * termination possible -- reducing worker count or removing tasks * from the queue during shutdown. The method is non-private to * allow access from ScheduledThreadPoolExecutor. * runState值转化为TERMINATED，当以下两种情况任意一种发生： * 1、runState=SHUTDOWN，并且线程池与任务队列都为空 * 2、runState=STOP，并且线程池为空 * 如果有资格（eligible）终止但是workerCount不为0，则中断空闲的worker保证关闭信号传播。 * 必须在可能会导致线程池终止的操作发生后调用该方法，可能的操作包括： * 1、在shutdown期间减少worker数量 * 2、在shutdown期间从任务队列移除任务 * （就是涉及上面两种操作的方法A可能会导致线程池关闭，那就在A方法之后调用该方法更新runState值为TERMINATED） * 该方法是非私有的，允许从ScheduledThreadPoolExecutor来访问。 * */ final void tryTerminate() { // 要注意该方法目标是要把线程池的runState更新为TERMINATED for (;;) { int c = ctl.get(); if (isRunning(c) || // 如果线程池还在运行， runStateAtLeast(c, TIDYING) || // 或者状态已经>=TIDYING（包含TIDYING、TERMINATED）（TIDYING状态是钩子方法还没执行完，执行完就成TERMINATED） (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty())) // 或者状态=SHUTDOWN但是还有任务没完成 return; // 则不能设置runState为TERMINATED if (workerCountOf(c) != 0) { // Eligible to terminate // 走到这一步，runState=SHUTDOWN或者STOP，此时任务队列为空，如果worker数不为0（还有存活的worker线程） interruptIdleWorkers(ONLY_ONE); // 尝试中断空闲的worker（只中断一个）。（因为现在没任务了并且线程池处于即将关闭状态，空闲线程留着也没用） return; } final ReentrantLock mainLock = this.mainLock; // 到此runState=SHUTDOWN或者STOP，任务队列与worker都为empty，开始修改runState值 mainLock.lock(); // 获取mainLock try { if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { // 尝试将ctl转化成runState=TIDYING，workerCount=0 try { terminated(); // 调用钩子方法ThreadPoolExecutor#terminated()，本类该方法为空，子类可以按照自己的需求实现 } finally { ctl.set(ctlOf(TERMINATED, 0)); // terminated()钩子方法执行完毕，ctl转化为runState=TERMINATED，workerCount=0 termination.signalAll(); // 唤醒所有在Condition上等待的线程（还没有见到Condition的用处） } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } /* * Methods for controlling interrupts to worker threads. * 控制worker线程中断的方法 * */ /** * If there is a security manager, makes sure caller has * permission to shut down threads in general (see shutdownPerm). * If this passes, additionally makes sure the caller is allowed * to interrupt each worker thread. This might not be true even if * first check passed, if the SecurityManager treats some threads * specially. * 如果有线程管理器，通常需要确保调用者拥有关闭线程的权限（见shutdownPrem）。 * 如果上面的通过了，另外需要确保允许调用者中断所有worker线程。 * 即使第一个检查通过了，如果SecurityManager特殊对待某些线程，这也不一定成立。 * */ private void checkShutdownAccess() { SecurityManager security = System.getSecurityManager(); // 如果当前应用创建了安全管理器，那么返回该管理器，否则返回null if (security != null) { security.checkPermission(shutdownPerm); // 检查是否有shutdown权限，如果没有抛出基于SecurityException的异常 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 加锁是为了防止在遍历workers的时候，worker集合有变化 try { for (Worker w : workers) security.checkAccess(w.thread); // 逐个检查是否有对每个worker线程的访问权限（具体是MODIFY_THREAD_PERMISSION权限），如果没有抛出基于SecurityException的异常 } finally { mainLock.unlock(); } } } /** * Interrupts all threads, even if active. Ignores SecurityExceptions * (in which case some threads may remain uninterrupted). * 中断所有线程，即使线程是活跃的。忽略各种SecurityException * （在某些情况下，某些线程可能会保持不中断（不响应中断）） * */ private void interruptWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) w.interruptIfStarted(); // 中断处于运行状态的worker线程 } finally { mainLock.unlock(); } } /** * Interrupts threads that might be waiting for tasks (as * indicated by not being locked) so they can check for * termination or configuration changes. Ignores * SecurityExceptions (in which case some threads may remain * uninterrupted). * 中断可能正在等待任务的线程（通过没有被lock来表明（如果该worker没有内部加锁，那么就判断为正在等待任务））， * 以便他们（至正在等待任务的worker）可以检查终止或者配置变化。 * 忽略SecurityException（在某些情况下，某些线程可能会保持不中断（不响应中断）） * * @param onlyOne If true, interrupt at most one worker. This is * called only from tryTerminate when termination is otherwise * enabled but there are still other workers. In this case, at * most one waiting worker is interrupted to propagate shutdown * signals in case all threads are currently waiting. * Interrupting any arbitrary thread ensures that newly arriving * workers since shutdown began will also eventually exit. * To guarantee eventual termination, it suffices to always * interrupt only one idle worker, but shutdown() interrupts all * idle workers so that redundant workers exit promptly, not * waiting for a straggler task to finish. * 参数onlyOne如果为true，则最多中断一个worker。 * 只会通过tryTerminate进行这种调用（当其他都可以终止但是仍有worker的时候）（就是除了有worker，其他条件都满足可以终止的时候，才会这样调用该方法） * 在这种情况下，所有worker线程当前都处于等待状态，最多一个等待worker被中断来广播shutdown信号。 * 中断任意线程可以保证自shutdown开始以来，新到达的worker也将最终退出。 * 为保证最终全部退出，每次只中断一个空闲worker就足够了，（通过多次调用来中断所有worker） * 但是shutdown()中断所有空闲线程，以便冗余（redundant）的worker立即（promptly）退出，而不是等待一个落后的（straggler）任务完成。 * */ private void interruptIdleWorkers(boolean onlyOne) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 所有workers操作需要加锁mainLock try { for (Worker w : workers) { Thread t = w.thread; if (!t.isInterrupted() && w.tryLock()) { try { t.interrupt(); } catch (SecurityException ignore) { } finally { w.unlock(); } } if (onlyOne) break; } } finally { mainLock.unlock(); } } /** * Common form of interruptIdleWorkers, to avoid having to * remember what the boolean argument means. * interruptIdleWorkers的通用形式，避免需要记住入参的实际含义 * （默认无入参的会中断所有空闲worker） * */ private void interruptIdleWorkers() { interruptIdleWorkers(false); } // 用于interruptIdleWorkers的常量 private static final boolean ONLY_ONE = true; /* * Misc utilities, most of which are also exported to * ScheduledThreadPoolExecutor * 其他方法，大多数暴露给ScheduledThreadPoolExecutor * */ /** * Invokes the rejected execution handler for the given command. * Package-protected for use by ScheduledThreadPoolExecutor. * 对给定的命令调用拒绝执行处理器 * protected权限，供ScheduledThreadPoolExecutor使用。 * */ final void reject(Runnable command) { handler.rejectedExecution(command, this); } /** * Performs any further cleanup following run state transition on * invocation of shutdown. A no-op here, but used by * ScheduledThreadPoolExecutor to cancel delayed tasks. * 在调用shutdown运行状态转化后，执行进一步的清理。 * 此处无操作，被用于ScheduledThreadPoolExecutor去取消延迟任务。 * */ void onShutdown() { } /** * State check needed by ScheduledThreadPoolExecutor to * enable running tasks during shutdown. * 用于ScheduledThreadPoolExecutor进行状态检查，确保shutdown期间能够运行任务。 * * @param shutdownOK true if should return true if SHUTDOWN */ final boolean isRunningOrShutdown(boolean shutdownOK) { int rs = runStateOf(ctl.get()); return rs == RUNNING || (rs == SHUTDOWN && shutdownOK); } /** * Drains the task queue into a new list, normally using * drainTo. But if the queue is a DelayQueue or any other kind of * queue for which poll or drainTo may fail to remove some * elements, it deletes them one by one. * 将任务队列转移到新的列表中，通常使用drainTo。 * 但如果队列是DelayQueue或任何其他类型的queue，对于他们的poll或者drainTo可能无法移除某些元素，它会一个一个的删除他们 * */ private List drainQueue() { BlockingQueue q = workQueue; ArrayList taskList = new ArrayList(); q.drainTo(taskList); // 从q中移除所有元素，并转移到给定的taskList里 if (!q.isEmpty()) { for (Runnable r : q.toArray(new Runnable[0])) { if (q.remove(r)) taskList.add(r); } } return taskList; } /* * Methods for creating, running and cleaning up after workers * 用于创建、执行、清理worker的方法 */ /** * Checks if a new worker can be added with respect to current * pool state and the given bound (either core or maximum). If so, * the worker count is adjusted accordingly, and, if possible, a * new worker is created and started, running firstTask as its * first task. This method returns false if the pool is stopped or * eligible to shut down. It also returns false if the thread * factory fails to create a thread when asked. If the thread * creation fails, either due to the thread factory returning * null, or due to an exception (typically OutOfMemoryError in * Thread.start()), we roll back cleanly. * 检查根据当前线程池状态和给定的边界（线程池的核心线程数与最大线程数），判断是否可以增加新的worker。 * 如果可以，相应（accordingly）调整worker数量，并且，如何可能的话，创建新worker并启动，执行firstTask作为它的第一个任务。 * 如果线程池已经停止或者有资格（eligible）关闭，该方法返回false。 * 如果调用线程的工厂方法时创建线程失败，该方法返回false。 * 如果该线程创建失败，可能有两种情况： * 1、由于线程工厂返回null * 2、由于异常（典型的如在Thread.start()时发生OOM） * 那我们会干净利落的进行回滚。 * * @param firstTask the task the new thread should run first (or * null if none). Workers are created with an initial first task * (in method execute()) to bypass queuing when there are fewer * than corePoolSize threads (in which case we always start one), * or when the queue is full (in which case we must bypass queue). * Initially idle threads are usually created via * prestartCoreThread or to replace other dying workers. * firstTask参数，是新线程应该首先执行的任务（如果没有则为null）。 * 有以下两种情况之一时，使用初始的第一个任务（通过execute()方法传入）创建新的Worker： * 1、当线程数少于corePoolSize（这种情况下总是启动一个新线程） * 2、或者当任务队列已满（这种情况下必须要绕过（bypass）queue） * 最初的空闲进程通常通过preStartCoreThread创建，或者替换其他将要挂掉的worker。 * （上面说的这个替换，是指的原来将要退出的worker还没remove掉，就进行了wc+1，然后add新的worker了？） * * @param core if true use corePoolSize as bound, else * maximumPoolSize. (A boolean indicator is used here rather than a * value to ensure reads of fresh values after checking other pool * state). * core参数，如果为true则使用corePoolSize作为边界，否则使用maximumPoolSize。 * （这里使用boolean指示符而不是具体的线程数value，是确保在检查完其他线程池状态后重新读取最新的线程数value） * * @return true if successful */ private boolean addWorker(Runnable firstTask, boolean core) { // addWorker里增加workerCount与创建启动worker不是同步的 retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 根据线程池状态与工作队列，有的情况下是不允许创建新的worker的 if (rs >= SHUTDOWN && // 1、runState为STOP、TIDYING、TERMINATED，此时线程池处于关闭状态，工作队列中已没有任务 ! (rs == SHUTDOWN && // 2、runState为SHUTDOWN时，firstTask不为null（表示在SHUTDOWN状态提交的新任务，这种的直接拒绝） firstTask == null && // 3、runState为SHUTDOWN时，工作队列为空（这种的也不能创建新worker） ! workQueue.isEmpty())) // （2、3）的判断是为了允许如果线程池处于SHUTDOWN状态，且工作队列不为空，那么允许创建firstTask为null的worker处理积压的工作队列任务 return false; for (;;) { int wc = workerCountOf(c); if (wc >= CAPACITY || wc >= (core ? corePoolSize : maximumPoolSize)) // 判断当前workerCount是否大于边界（根据入参core判断corePoolSize或者maximumPoolSize） return false; if (compareAndIncrementWorkerCount(c)) // 如果增加workerCount成功，则跳出这两个for循环，进入该方法的新worker创建与启动部分 break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) // 如果增加workerCount失败，并且runState发生了变化，那么重新判断是否允许创建新的worker（从第一个for循环开始分析） continue retry; // else CAS failed due to workerCount change; retry inner loop // 如果增加workerCount失败，并且runState没有变化，那么可能是并发导致workerCount发生了变化，重新CAS来增加workerCount } } boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try { w = new Worker(firstTask); // 创建新的worker final Thread t = w.thread; // 获取当前worker的线程t（这个线程t是用于执行该worker里面的任务的，这个线程t是通过线程工厂创建的） if (t != null) { // t != null，表示线程工厂成功创建线程。 final ReentrantLock mainLock = this.mainLock; // 对于workers的操作都需要加mainLock锁 mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. // 保持锁的状态下重新检查，在ThreadFactory失败或者在获取锁之前线程池shutdown，则退出？？？ int rs = runStateOf(ctl.get()); if (rs largestPoolSize) largestPoolSize = s; // 如果当前workers集合数量大于largestPoolSize，那么更新largestPoolSize为当前值。这个值仅用于跟踪线程池达到的最大值 workerAdded = true; // 新worker加入workers集合成功，允许新的worker启动 } } finally { mainLock.unlock(); } if (workerAdded) { t.start(); // 执行t.start()，会调用worker.run()方法（具体见Thread.start()） workerStarted = true; // 到这一步表示worker启动没有异常（如果有OOM等异常，就走不到这一步了） } } } finally { if (! workerStarted) // 如果新worker启动失败，那么需要从workers集合中删除该worker（当然也有可能worker就没加入到workers集合，不过没影响） addWorkerFailed(w); } return workerStarted; } /** * Rolls back the worker thread creation. * - removes worker from workers, if present * - decrements worker count * - rechecks for termination, in case the existence of this * worker was holding up termination * 回滚worker线程的创建 * 1、如果存在的话，从workers集合中移除该worker * 2、worker数量减一 * 3、重新检查终止，以防止该worker的存在耽误了线程池终止。 * */ private void addWorkerFailed(Worker w) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 对workers的操作都要加mainLock锁 try { if (w != null) workers.remove(w); // 从workers集合中移除该worker（如果集合中没有该worker，会返回false） decrementWorkerCount(); // 如果走到了增加worker这一步（不管worker有没有创建加入成功），那workerCount必须减一 tryTerminate(); // 尝试终止线程池，为的是避免由于该worker的存在阻碍了原本终止线程池操作 } finally { mainLock.unlock(); } } /** * Performs cleanup and bookkeeping for a dying worker. Called * only from worker threads. Unless completedAbruptly is set, * assumes that workerCount has already been adjusted to account * for exit. This method removes thread from worker set, and * possibly terminates the pool or replaces the worker if either * it exited due to user task exception or if fewer than * corePoolSize workers are running or queue is non-empty but * there are no workers. * 清理将死worker并进行相关bookkeeping。（将死worker为即将退出worker序列的线程，不再执行提交给线程池的任务） * 只能由worker线程调用。 * 除非设置了completedAbruptly（突然完成），否则假定workerCount已经调整为认定退出。（就是非completedAbruptly情况下，已经从workerCount中减去了该worker（wc-1））。 * 该方法从worker集合中移除对应的线程，并尝试终止线程池或者替换该worker，替换worker的场景为： * 1、用户的任务异常导致该worker线程异常退出（此时completedAbruptly为true） * 2、运行的worker线程数小于corePoolSize * 3、工作队列非空但是没有存活的worker * * @param w the worker * @param completedAbruptly if the worker died due to user exception * completedAbruptly参数，如果worker由于用户任务异常导致挂掉的情况下为true */ private void processWorkerExit(Worker w, boolean completedAbruptly) { if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted // 如果突然中断，workerCount没有来得及调整 decrementWorkerCount(); // wc - 1 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 任何对worker集合的操作都要加mainLock锁 try { completedTaskCount += w.completedTasks; // 更新已完成任务数，注意这里用的w.completedTasks。 workers.remove(w); // 从worker集合中移除该worker } finally { mainLock.unlock(); } tryTerminate(); // 因为有worker退出，防止该worker的存在影响线程池正常终止，例行公事尝试终止线程池 int c = ctl.get(); if (runStateLessThan(c, STOP)) { // 判断当前线程池运行状态是否= min) return; // replacement not needed // 如果不满足上面的条件，就不用替换worker } addWorker(null, false); // 如果是异常退出或者满足上面的条件，那么需要新增一个初始任务为null的worker来消费工作队列中的任务 } } /** * Performs blocking or timed wait for a task, depending on * current configuration settings, or returns null if this worker * must exit because of any of: * 1. There are more than maximumPoolSize workers (due to * a call to setMaximumPoolSize). * 2. The pool is stopped. * 3. The pool is shutdown and the queue is empty. * 4. This worker timed out waiting for a task, and timed-out * workers are subject to termination (that is, * {@code allowCoreThreadTimeOut || workerCount > corePoolSize}) * both before and after the timed wait, and if the queue is * non-empty, this worker is not the last thread in the pool. * 阻塞或者限时等待获取任务，选取哪种方式取决于当前参数设置， * 如果该worker由于以下原因必须退出，则会返回null： * 1、当前worker数量超过maximumPoolSize（由于调用了setMaximumPoolSize重新设置了最大线程池数） * 2、线程池被停止（runState>=STOP） * 3、线程池被关闭（runState=SHUTDOWN），并且工作队列为空 * 4、该worker等待任务超时，并且超时worker在限时等待之前与之后都会终止（即allowCoreThreadTimeOut || workerCount > corePoolSize），如果工作队列非空，那么该worker不会是线程池里最后一个线程。 * （第4条这个，不明白注释说的啥，具体看代码吧） * * @return task, or null if the worker must exit, in which case * workerCount is decremented */ private Runnable getTask() { boolean timedOut = false; // Did the last poll() time out? // 最近poll是否超时（poll进行限时阻塞获取） for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) { // 想不出来这个判断怎么写才会更简洁 decrementWorkerCount(); // 这里decrementWorkerCount，是因为在线程池状态为关闭并且任务队列没任务时，可以清理所有worker（不用管并发下清理的worker太多） return null; // wc-1之后直接返回null，让worker自己去执行退出 } int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc > corePoolSize; // 判断是否允许超时退出 if ((wc > maximumPoolSize || (timed && timedOut)) // 当前wc超过最大线程池数或者允许超时退出情况下上次获取已超时 && (wc > 1 || workQueue.isEmpty())) { // 还需注意工作队列非空时，最后一个worker线程不能退出 if (compareAndDecrementWorkerCount(c)) // 这里compareAndDecrementWorkerCount(c)，要拿当前的worker数-1，是防止并发下清理的worker过多（比如现在一共有俩worker，都等待超时了，任务队列还不为空，结果并发都走到了这一步，如果直接-1.这俩就都被清理了） return null; continue; } try { Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); // 如果worker可以超时退出，那么使用限时阻塞的poll方法，否则使用take方法 if (r != null) return r; timedOut = true; // 如果限时拿不到任务，则记录上次获取已超时 } catch (InterruptedException retry) { timedOut = false; // 如果在从工作队列中拿任务时被中断退出，那么不算上次获取超时 } } } /** * Main worker run loop. Repeatedly gets tasks from queue and * executes them, while coping with a number of issues: * 主要的worker执行循环。 * 重复从工作队列中获取任务然后执行他们，同时处理（cope）以下这些问题： * * 1. We may start out with an initial task, in which case we * don't need to get the first one. Otherwise, as long as pool is * running, we get tasks from getTask. If it returns null then the * worker exits due to changed pool state or configuration * parameters. Other exits result from exception throws in * external code, in which case completedAbruptly holds, which * usually leads processWorkerExit to replace this thread. * 1、我们可以从一个初始任务开始执行，在这种情况下我们不需要获取第一个任务。 * 否则，只要线程池在运行，我们就通过getTask方法获取任务。 * 如果由于线程池状态改变或者参数配置发生变化，getTask返回null，那么该worker退出。 * 其他退出是由于外部代码抛出异常引起的，在这种情况下completedAbruptly成立（满足completedAbruptly条件）， * 这通常会导致processWorkerExit来替换该worker线程。 * * 2. Before running any task, the lock is acquired to prevent * other pool interrupts while the task is executing, and then we * ensure that unless pool is stopping, this thread does not have * its interrupt set. * 2、在运行任何任务之前，要获取lock来防止运行任务时发生其他线程池中断， * 并且确保除非线程池被stopping，否则该线程不会设置中断。 * * 3. Each task run is preceded by a call to beforeExecute, which * might throw an exception, in which case we cause thread to die * (breaking loop with completedAbruptly true) without processing * the task. * 3、每个任务执行之前都会调用beforeExecute方法，这可能会抛出异常， * 在这种情况下会导致线程挂掉（设置completedAbruptly为true然后跳出循环）而不处理任务。 * * 4. Assuming beforeExecute completes normally, we run the task, * gathering any of its thrown exceptions to send to afterExecute. * We separately handle RuntimeException, Error (both of which the * specs guarantee that we trap) and arbitrary Throwables. * Because we cannot rethrow Throwables within Runnable.run, we * wrap them within Errors on the way out (to the thread's * UncaughtExceptionHandler). Any thrown exception also * conservatively causes thread to die. * 4、假设beforeExecute正常完成，然后执行task，收集执行任务期间抛出的任何异常发送给afterExecute方法。 * 分别处理RuntimeException、Error（规范（spec）保证我们可以捕获到这两个），和任意Throwables。 * 由于在Runnable.run方法内部不能重新抛出Throwables。所以将Throwables包装到Errors中输出（到线程的UncaughtExceptionHandler）。 * 任何抛出的异常也会保守的（conservatively）导致线程挂掉。 * * 5. After task.run completes, we call afterExecute, which may * also throw an exception, which will also cause thread to * die. According to JLS Sec 14.20, this exception is the one that * will be in effect even if task.run throws. * 5、当task.run方法执行完成，调用afterExecute方法，可能也会抛出异常，也会导致该worker线程挂掉。 * 根据JLS Sec 14.20，该异常即使是task.run抛出，也会生效。（？？？） * * The net effect of the exception mechanics is that afterExecute * and the thread's UncaughtExceptionHandler have as accurate * information as we can provide about any problems encountered by * user code. * 这种异常机制的最终效果是：afterExecute与线程的UncaughtExceptionHandler，具有我们可以提供的关于用户代码遇到的任何问题的准确（accurate）信息。 * * @param w the worker */ final void runWorker(Worker w) { Thread wt = Thread.currentThread(); // 因为是thread调用的worker#run，当前线程为worker线程，该线程也就是worker的thread，通过线程工厂创建出来的。 Runnable task = w.firstTask; // 拿到给定worker的firstTask，然后将worker的firstTask置为null w.firstTask = null; w.unlock(); // allow interrupts // unlock->AQS#release->tryRelease，state变为0，表示该worker进入运行阶段，允许interruptIfStarted。 boolean completedAbruptly = true; // 突然完成的标识，用于判断是否要替换该worker try { while (task != null || (task = getTask()) != null) { // 如果有需要执行的任务，就获取任务 w.lock(); // 上来加锁，表示该worker在执行任务。防止被interruptIdleWorkers方法认为是空闲线程给中断了 // If pool is stopping, ensure thread is interrupted; // 如果线程池被停止，确保线程被中断 // if not, ensure thread is not interrupted. This // 如果线程池没有停止，确保线程没有被中断。 // requires a recheck in second case to deal with // 这需要在第二种情况下重新检查线程中断状态，以在清除中断的同时处理shutdownNow的竞争。 // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || // 这个if有两个功能：1、判断出该线程是否应该中断，runState>=STOP的就直接中断；2、如果该线程不应该中断，那么清理中断状态； (Thread.interrupted() && // 在满足runState=STOP，并且此时线程未设置中断状态，需要worker线程中断并退出 try { beforeExecute(wt, task); // 任务执行之前先调用beforeExecute Throwable thrown = null; try { task.run(); // 执行任务。注意这里不会再开新线程来执行了，只是调用了Runnable的run方法（可能是RunnableFuture实现的Runnable） } catch (RuntimeException x) { thrown = x; throw x; } catch (Error x) { thrown = x; throw x; } catch (Throwable x) { thrown = x; throw new Error(x); } finally { // 注意：这一块异常try-catch-finally的逻辑，内部捕获的异常会走两部分，第一部分是继续throw抛出，第二部分是传入afterExecute。第一部分抛出的异常在外边的try给忽略了。 afterExecute(task, thrown); // 任务执行之后调用afterExecute，传入执行过程中捕获到的异常 } } finally { task = null; w.completedTasks++; // 完成任务数+1 w.unlock(); // 解锁，作为空闲线程等着了 } } completedAbruptly = false; // 如果getTask返回了null，就表示该worker是准备正常退出了 } finally { // 注意：内部循环如果有抛出异常，直接忽略 processWorkerExit(w, completedAbruptly); // 带着completedAbruptly去尝试本worker进行退出与终止线程池 } } // Public constructors and methods // 公共构造函数和方法 /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters and default thread factory and rejected execution handler. * It may be more convenient to use one of the {@link Executors} factory * methods instead of this general purpose constructor. * 见调用 * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * * @param maximumPoolSize the maximum number of threads to allow in the * pool * * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * * @param unit the time unit for the {@code keepAliveTime} argument * * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * * @throws IllegalArgumentException if one of the following holds: * {@code corePoolSize * {@code keepAliveTime * {@code maximumPoolSize * {@code maximumPoolSize workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters and default rejected execution handler. * 同上 * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the {@code keepAliveTime} argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * @param threadFactory the factory to use when the executor * creates a new thread * @throws IllegalArgumentException if one of the following holds: * {@code corePoolSize * {@code keepAliveTime * {@code maximumPoolSize * {@code maximumPoolSize workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); } /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters and default thread factory. * 同上 * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the {@code keepAliveTime} argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * @throws IllegalArgumentException if one of the following holds: * {@code corePoolSize * {@code keepAliveTime * {@code maximumPoolSize * {@code maximumPoolSize workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); } /** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters. * 创建新的ThreadPoolExecutor，通过给定的初始化参数和默认的线程工厂（ThreadFactory）和默认的拒绝执行处理器（RejectedExecutionHandler）。 * 可能更方便的（convenient）是通过调用Executors的工厂方法，而不是此公共构造方法。（然而实际上代码风格检测通常更建议直接调用ThreadPoolExecutor的构造方法） * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * corePoolSize表示线程池保持的线程数，即使这些线程是空闲的，除非设置了allowCoreThreadTimeOut为true * @param maximumPoolSize the maximum number of threads to allow in the * pool * maximumPoolSize表示线程池允许的最大线程数 * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * keepAliveTime表示当线程数超过核心线程数时，多余的（excess）空闲线程在终止前用于等待新任务的最大等待时间 * @param unit the time unit for the {@code keepAliveTime} argument * unit表示keepAliveTime的时间单位 * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * workQueue用于保存还未执行任务的队列。该队列将只保存通过execute方法提交的实现Runnable接口的任务。 * @param threadFactory the factory to use when the executor * creates a new thread * threadFactor用于当executor创建新线程的时候 * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * handler用于当线程池线程边界与工作队列容量饱和时导致执行阻塞，需要执行的相关拒绝策略 * @throws IllegalArgumentException if one of the following holds: * {@code corePoolSize * {@code keepAliveTime * {@code maximumPoolSize // maximum不能 workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize =SHUTDOWN），则移除该command reject(command); // 拒绝该任务（相当于作为新提交的任务来拒绝的，而SHUTDOWN状态还是会处理工作队列中的任务） else if (workerCountOf(recheck) == 0) // 如果线程池还处于RUNNING时，worker线程为0，则需要添加worker线程来处理任务 addWorker(null, false); } else if (!addWorker(command, false)) // 3、如果线程数>corePoolSize，并且入队失败（工作队列满了），那么就新建worker线程处理该任务（创建corePoolSize到maximumPoolSize中间的worker线程） reject(command); // 如果新建worker失败（比如当前rs>=SHUTDOWN），则拒绝该任务 } /** * Initiates an orderly shutdown in which previously submitted * tasks are executed, but no new tasks will be accepted. * Invocation has no additional effect if already shut down. * 启动有序关闭，其中之前已提交的任务将执行，不会再接受新任务。 * 如果已经处于SHUTDOWN，重复调用不会有额外的效果。 * * This method does not wait for previously submitted tasks to * complete execution. Use {@link #awaitTermination awaitTermination} * to do that. * 该方法不会等待之前已提交的任务完成执行。（意思就是该方法会通知线程池去SHUTDOWN，但不会等待所有worker线程都完成退出与线程池终止） * 使用awaitTermination来做这些事儿（限时等待检测任务完成与线程池终止）。 * 常见用法： * threadPoolExecutor.shutdown(); * while(!threadPoolExecutor.awaitTermination(...)) { // 循环 限时等待worker线程完成退出与线程池状态成为TERMINATED}; * * @throws SecurityException {@inheritDoc} * * 注意，该方法正常退出时仅表示已正确设置了线程池状态为SHUTDOWN，但不保证所有worker线程已完成，也不保证线程池状态到达TERMINATED状态 * */ public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 涉及worker集合的操作加mainLock（因为要逐步清除worker线程） try { checkShutdownAccess(); // 检查shutdown权限 advanceRunState(SHUTDOWN); // 更新线程池状态为SHUTDOWN（如果rsThis method does not wait for actively executing tasks to * terminate. Use {@link #awaitTermination awaitTermination} to * do that. * 该方法不会等待正在执行的任务执行完成。（意思就是该方法会通知线程池去STOP，但不会等待所有worker线程完成退出与线程池终止） * 使用awaitTermination来做到这一点。（用于限时等待检测线程池里的任务是否已执行完毕，线程池已关闭） * * There are no guarantees beyond best-effort attempts to stop * processing actively executing tasks. This implementation * cancels tasks via {@link Thread#interrupt}, so any task that * fails to respond to interrupts may never terminate. * 除了尽力尝试停止运行正在执行的任务外，没有任何保证。 * 通过Thread#interrupt实现取消任务，所以任何未能响应中断的的任务可能永远不会终止。 * 常见用法： * threadPoolExecutor.shutdown(); * while(!threadPoolExecutor.awaitTermination(...)) { // 循环 限时等待worker线程完成退出与线程池状态成为TERMINATED}; * * @throws SecurityException {@inheritDoc} * * 注意，该方法正常退出时仅表示已正确设置了线程池状态为SHUTDOWN，但不保证所有worker线程已完成，也不保证线程池状态到达TERMINATED状态 * */ public List shutdownNow() { List tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 涉及worker集合的操作加mainLock（因为要逐步清除worker线程） try { checkShutdownAccess(); // 检查shutdown权限 advanceRunState(STOP); // 更新线程池状态为STOP（如果rsRUNNING） public boolean isShutdown() { return ! isRunning(ctl.get()); } /** * Returns true if this executor is in the process of terminating * after {@link #shutdown} or {@link #shutdownNow} but has not * completely terminated. This method may be useful for * debugging. A return of {@code true} reported a sufficient * period after shutdown may indicate that submitted tasks have * ignored or suppressed interruption, causing this executor not * to properly terminate. * 如果executor在shutdown或者shutdownNow之后正在终止但尚未完全终止，该方法返回true。 * 该方法可能对debug有用。如果在shutdown之后足够（sufficient）长的时间里该方法仍返回true， * 可能表明提交的任务已经忽略或者抑制了中断（不响应中断），导致executor无法正常终止。 * * @return {@code true} if terminating but not yet terminated * 正在终止但未完成终止，返回true */ public boolean isTerminating() { int c = ctl.get(); return ! isRunning(c) && runStateLessThan(c, TERMINATED); } // 检测线程池是否已终止 public boolean isTerminated() { return runStateAtLeast(ctl.get(), TERMINATED); } // 可以在shutdown()与shutdonwNow()调用之后，调用该方法，等待检测线程池是否已关闭 public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 通过加锁来防止其他对worker的操作（包括清理空闲/所有worker） try { for (;;) { if (runStateAtLeast(ctl.get(), TERMINATED)) // 如果线程池状态已到达TERMINATED，说明现在线程池已关闭（没有在运行的worker线程了），返回true return true; if (nanos 当前值（原值），如果需要的话，将启动新线程来执行任意排队任务。 * * @param corePoolSize the new core size * @throws IllegalArgumentException if {@code corePoolSize corePoolSize) interruptIdleWorkers(); // 如果当前线程数>更新后的核心线程数，尝试中断空闲worker线程 else if (delta > 0) { // 如果更新后核心线程数>原值，需要考虑是否是需要是为了增加worker线程而特意设置了较大的核心线程数。 // We don't really know how many new threads are \"needed\". // As a heuristic, prestart enough new workers (up to new // core size) to handle the current number of tasks in // queue, but stop if queue becomes empty while doing so. // 我们不知道需要启动多少新线程。 // 作为一种启发式（heuristic）方法，预先启动足够多的新worker线程（最多达到新的核心线程数）来处理队列中的当前任务 // 但如果在执行此操作过程中队列变空，则停止启动新的worker线程（原已启动的worker线程会继续存活（如果没有设置allowCoreThreadTimeOut）） // int k = Math.min(delta, workQueue.size()); // 新启动的线程数取核心线程数与当前队列任务数中的最小值 while (k-- > 0 && addWorker(null, true)) { // 避免启的新线程太多，有不必要的浪费 if (workQueue.isEmpty()) // 如果任务队列为空了，那么不管当前worker线程数是否达到了核心线程数，都停止创建新的线程 break; } } } /** * Returns the core number of threads. * 返回核心线程数 * * @return the core number of threads * @see #setCorePoolSize */ public int getCorePoolSize() { return corePoolSize; } /** * Starts a core thread, causing it to idly wait for work. This * overrides the default policy of starting core threads only when * new tasks are executed. This method will return {@code false} * if all core threads have already been started. * 启动核心线程，让它空闲着等待任务。 * 该方法覆盖了默认只有在执行新任务的时候才启动核心线程的策略（默认如果没任务就不启动线程） * 该方法会返回false，如果所有的核心线程在此之前都已经启动了（在进入该方法前，worker线程数已达到核心线程数） * （预启动一个核心线程，在任务提交之前准备好线程） * * @return {@code true} if a thread was started */ public boolean prestartCoreThread() { return workerCountOf(ctl.get()) corePoolSize，返回false ++n; return n; } /** * Returns true if this pool allows core threads to time out and * terminate if no tasks arrive within the keepAlive time, being * replaced if needed when new tasks arrive. When true, the same * keep-alive policy applying to non-core threads applies also to * core threads. When false (the default), core threads are never * terminated due to lack of incoming tasks. * 如果该线程池允许核心线程在keepAlive时间内没有任务到达时超时与终止，则返回true， * 并在新任务到达时根据需要进行替换。（不知道这个替换跟addWorker()的替换又有什么关系？？？） * 当返回true时，应用于非核心线程的keep-alive策略也会应用于核心线程。 * 当返回false时（也就是allowCoreThreadTimeOut的默认值），核心线程永远不会由于缺失传入任务而终止。 * * @return {@code true} if core threads are allowed to time out, * else {@code false} * * @since 1.6 */ public boolean allowsCoreThreadTimeOut() { return allowCoreThreadTimeOut; } /** * Sets the policy governing whether core threads may time out and * terminate if no tasks arrive within the keep-alive time, being * replaced if needed when new tasks arrive. When false, core * threads are never terminated due to lack of incoming * tasks. When true, the same keep-alive policy applying to * non-core threads applies also to core threads. To avoid * continual thread replacement, the keep-alive time must be * greater than zero when setting {@code true}. This method * should in general be called before the pool is actively used. * 设置策略，主要用于控制该线程池核心线程在keepAlive时间内没有任务到达时超时与终止， * 并在新任务到达时根据需要进行替换。 * 如果设置为false，核心线程永远不会由于缺失传入任务而终止。 * 如果设置为true，应用于非核心线程的keep-alive策略也会应用于核心线程。 * 为避免不断更换线程，当设置为true时，keep-alive的值必须大于0。 * 通常在主动使用线程池之前调用此方法。 * * @param value {@code true} if should time out, else {@code false} * @throws IllegalArgumentException if value is {@code true} * and the current keep-alive time is not greater than zero * * @since 1.6 */ public void allowCoreThreadTimeOut(boolean value) { if (value && keepAliveTime =corePoolSize>0 * @see #getMaximumPoolSize */ public void setMaximumPoolSize(int maximumPoolSize) { if (maximumPoolSize maximumPoolSize) // 如果当前worker线程数>新值maximumPoolSize，需要将空闲线程终止 interruptIdleWorkers(); } /** * Returns the maximum allowed number of threads. * 返回允许的最大线程数 * * @return the maximum allowed number of threads * @see #setMaximumPoolSize */ public int getMaximumPoolSize() { return maximumPoolSize; } /** * Sets the time limit for which threads may remain idle before * being terminated. If there are more than the core number of * threads currently in the pool, after waiting this amount of * time without processing a task, excess threads will be * terminated. This overrides any value set in the constructor. * 设置线程在终止前可以保持空闲的时间限制。（空闲多少时长后终止） * 如果在线程池中的当前线程数超过核心线程数，并在这段等待时间内没有执行任务，多余的线程将被终止。 * 这会覆盖构造函数中设置的任意值。 * * @param time the time to wait. A time value of zero will cause * excess threads to terminate immediately after executing tasks. * time参数，等待时间。如果time值为0，将导致执行额外的线程（超过核心线程的那部分线程）在执行完任务后会立即终止 * * @param unit the time unit of the {@code time} argument * @throws IllegalArgumentException if {@code time} less than zero or * if {@code time} is zero and {@code allowsCoreThreadTimeOut} * 注意，必须保证time>=0， * 如果设置了allowCoreThreadTimeOut，必须保证time>0（要不然留不住核心线程） * @see #getKeepAliveTime(TimeUnit) */ public void setKeepAliveTime(long time, TimeUnit unit) { if (time getQueue() { return workQueue; } /** * Removes this task from the executor's internal queue if it is * present, thus causing it not to be run if it has not already * started. * 如果该任务存在（present），从executor的内部队列中移除该任务，这会导致尚未启动的任务不会去运行。 * * This method may be useful as one part of a cancellation * scheme. It may fail to remove tasks that have been converted * into other forms before being placed on the internal queue. For * example, a task entered using {@code submit} might be * converted into a form that maintains {@code Future} status. * However, in such cases, method {@link #purge} may be used to * remove those Futures that have been cancelled. * 该方法可作为取消方案的一部分。 * 它可能无法删除那些在放入内部队列之前已转化为其他形式的任务。 * 例如，使用submit方法入队的任务可能转化为了含有Future状态的形式。 * （例如Runnable通过AbstractExecutorService#submit()转成了FutureTask对象（这个过程叫形式转化），如果还用Runnable对象来remove，是删除不了的） * 但是，在这种情况下，purge方法可用于删除这部分已经取消的Future。 * * @param task the task to remove * @return {@code true} if the task was removed */ public boolean remove(Runnable task) { boolean removed = workQueue.remove(task); tryTerminate(); // In case SHUTDOWN and now empty // 对于rs=SHUTDOWN并且任务队列非空的情况下，删除了一个任务队列任务，需要尝试终止线程池。 return removed; } /** * Tries to remove from the work queue all {@link Future} * tasks that have been cancelled. This method can be useful as a * storage reclamation operation, that has no other impact on * functionality. Cancelled tasks are never executed, but may * accumulate in work queues until worker threads can actively * remove them. Invoking this method instead tries to remove them now. * However, this method may fail to remove tasks in * the presence of interference by other threads. * 尝试从工作队列中删除所有已取消的Future任务。 * 该方法可用作存储（storage）回收（reclamation）操作，对功能没有其他影响。 * 取消的任务永远不会执行，但可能会在工作队列中累积，直到worker线程主动删除他们。（worker会调用任务的run方法，在FutureTask中，如果run的Callable的state不为NEW，则直接结束） * 现在调用该方法会尝试删除他们。 * 然而，这种方法可能会在（presence 存在）其他线程干扰（interference）下无法删除任务。 * */ public void purge() { final BlockingQueue q = workQueue; try { Iterator it = q.iterator(); while (it.hasNext()) { Runnable r = it.next(); if (r instanceof Future && ((Future)r).isCancelled()) // 判断任务是否实现了Future接口，并判断该Future任务是否已取消 it.remove(); } } catch (ConcurrentModificationException fallThrough) { // Take slow path if we encounter interference during traversal. // Make copy for traversal and call remove for cancelled entries. // The slow path is more likely to be O(N*N). // 发生并发修改异常 // 如果在遍历过程中遇到干扰，采取slow path。 // 为遍历创建副本，并调用remove来取消entries（就是遍历对象） // slow path的时间复杂度很大的可能为O(N*N) // for (Object r : q.toArray()) if (r instanceof Future && ((Future)r).isCancelled()) q.remove(r); } tryTerminate(); // In case SHUTDOWN and now empty // 对于rs=SHUTDOWN并且任务队列非空的情况下，删除了一个任务队列任务，需要尝试终止线程池。 } /* Statistics */ // 统计数据 /** * Returns the current number of threads in the pool. * 返回当前线程池线程数 * * @return the number of threads */ public int getPoolSize() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 对于worker集合的操作都要加mainLock try { // Remove rare and surprising possibility of // isTerminated() && getPoolSize() > 0 // 一般来说，当执行到isTerminated()方法时，线程池里应该是没有worker线程了 // 但是为了防止罕见与惊讶的可能性发生，对这种情况进行单独判断 return runStateAtLeast(ctl.get(), TIDYING) ? 0 // 如果rs=TIDYING，直接返回0，不再去检查worker集合的数量 : workers.size(); } finally { mainLock.unlock(); } } /** * Returns the approximate number of threads that are actively * executing tasks. * 返回正在执行任务的线程大致（approximate）数量。（不包含空闲的线程） * * @return the number of threads */ public int getActiveCount() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 对worker集合的操作都需要加mainLock try { int n = 0; for (Worker w : workers) if (w.isLocked()) // 判断线程是否正在执行任务的依据是看该worker是否有加锁 ++n; return n; } finally { mainLock.unlock(); } } /** * Returns the largest number of threads that have ever * simultaneously been in the pool. * 返回同时（simultaneously）进入线程池的历史最大线程数。 * * @return the number of threads */ public int getLargestPoolSize() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 对worker集合的操作都需要加mainLock，因为largestPoolSize依赖与workers.size()，所以也加了锁 try { return largestPoolSize; } finally { mainLock.unlock(); } } /** * Returns the approximate total number of tasks that have ever been * scheduled for execution. Because the states of tasks and * threads may change dynamically during computation, the returned * value is only an approximation. * 返回已安排执行的所有任务的预估值。（包含已执行完成、正在执行、入队等待执行的所有任务数） * 由于在计算过程中任务状态与线程状态可能动态变化，因此返回值只是一个近似值。 * * @return the number of tasks */ public long getTaskCount() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 对worker集合的操作都需要加mainLock try { long n = completedTaskCount; for (Worker w : workers) { n += w.completedTasks; // 任务数累加已执行完成任务数 if (w.isLocked()) ++n; // 任务数累加当前worker正在执行任务 } return n + workQueue.size(); // 任务数累加工作队列中尚未执行的任务数 } finally { mainLock.unlock(); } } /** * Returns the approximate total number of tasks that have * completed execution. Because the states of tasks and threads * may change dynamically during computation, the returned value * is only an approximation, but one that does not ever decrease * across successive calls. * 返回已执行完成的所有数的预估值。 * 由于在计算过程中任务状态与线程状态可能动态变化，因此返回值只是一个近似值， * 但是在连续调用本方法时该值永远不会减少。 * * @return the number of tasks */ public long getCompletedTaskCount() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 对worker集合的操作都需要加mainLock try { long n = completedTaskCount; for (Worker w : workers) n += w.completedTasks; // 任务数累加已执行完成任务数 return n; } finally { mainLock.unlock(); } } /** * Returns a string identifying this pool, as well as its state, * including indications of run state and estimated worker and * task counts. * 返回标识此线程池及其状态的字符串，包括运行状态、预估worker数量、任务数量 * * @return a string identifying this pool, as well as its state */ public String toString() { long ncompleted; // 完成任务数 int nworkers, nactive; // worker线程数、活跃worker线程数（活跃=非空闲） final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { ncompleted = completedTaskCount; nactive = 0; nworkers = workers.size(); for (Worker w : workers) { ncompleted += w.completedTasks; if (w.isLocked()) ++nactive; } } finally { mainLock.unlock(); } int c = ctl.get(); String rs = (runStateLessThan(c, SHUTDOWN) ? \"Running\" : (runStateAtLeast(c, TERMINATED) ? \"Terminated\" : \"Shutting down\")); return super.toString() + \"[\" + rs + // 运行状态 \", pool size = \" + nworkers + // 线程池大小=worker线程数 \", active threads = \" + nactive + // 活跃线程数=非空闲线程数 \", queued tasks = \" + workQueue.size() + // 排队等待任务数=工作队列大小 \", completed tasks = \" + ncompleted + // 完成任务数 \"]\"; } /* Extension hooks */ // 扩展的钩子方法 /** * Method invoked prior to executing the given Runnable in the * given thread. This method is invoked by thread {@code t} that * will execute task {@code r}, and may be used to re-initialize * ThreadLocals, or to perform logging. * 在给定的线程中执行给定的Runnable任务时，首先执行该方法。 * 在线程t将要执行任务r的时候调用该方法，可用于重新初始化ThreadLocals，或者记录日志。 * * This implementation does nothing, but may be customized in * subclasses. Note: To properly nest multiple overridings, subclasses * should generally invoke {@code super.beforeExecute} at the end of * this method. * 本类该方法没有具体实现，但在子类中可能会自定义实现 * 注意：为了正确的嵌套覆盖，子类通常应该在该方法的末尾调用super.beforeExecute * * @param t the thread that will run task {@code r} * @param r the task that will be executed */ protected void beforeExecute(Thread t, Runnable r) { } /** * Method invoked upon completion of execution of the given Runnable. * This method is invoked by the thread that executed the task. If * non-null, the Throwable is the uncaught {@code RuntimeException} * or {@code Error} that caused execution to terminate abruptly. * 在执行完给定的Runnable任务后调用该方法。 * 由执行任务的线程调用该方法。 * 如果Throwable非空，表示导致执行突然中断并且未被捕获的RunntimeException或Error * （这个未被捕获，表示未被Runnable内部catch，但被runWorker给catch到了，再通过调用afterExecute进行处理） * * This implementation does nothing, but may be customized in * subclasses. Note: To properly nest multiple overridings, subclasses * should generally invoke {@code super.afterExecute} at the * beginning of this method. * 本类该方法没有具体实现，但在子类中可能会自定义实现 * 注意：为了正确的嵌套覆盖，子类通常应该在该方法前面调用super.afterExecute（跟beforeExecute顺序相反） * * Note: When actions are enclosed in tasks (such as * {@link FutureTask}) either explicitly or via methods such as * {@code submit}, these task objects catch and maintain * computational exceptions, and so they do not cause abrupt * termination, and the internal exceptions are not * passed to this method. If you would like to trap both kinds of * failures in this method, you can further probe for such cases, * as in this sample subclass that prints either the direct cause * or the underlying exception if a task has been aborted: * 注意：当动作被明确的或者通过submit方法包含到任务中（例如FutureTask），该任务对象捕获和维护计算异常， * 所以它不会导致突然终止，并且内部的异常不会传递给此方法。 * （回顾一下FutureTask的run方法，该方法执行时不会抛出异常，而是将异常给set进了outcome里，只有通过get方法拿执行结果outcome时，才能知道运行结果是否有异常） * （这个不会传递意思是，这部分异常不会通过Throwable t入参传递，而是task内部的异常。task内部维护的异常不会抛出，在runWorker中也捕获不到） * 如果想要在该方法中捕获这两种失败，可以进一步探测此种情况， * 例如下面的样例子类里，如果任务已中止（abort），将打印直接原因或者底层异常。 * * {@code * class ExtendedExecutor extends ThreadPoolExecutor { * // ... * protected void afterExecute(Runnable r, Throwable t) { * super.afterExecute(r, t); // 先调用父类afterExecute * if (t == null && r instanceof Future) { // 如果runWorker捕获到的异常为null，并且Runnable r为Future类型（存在异常由Future维护，而没有throw给runWorker） * try { * Object result = ((Future) r).get(); // 调用Future的get时，如果执行过程中发生异常，那么该方法会直接抛出由它维护的相关异常 * } catch (CancellationException ce) { // 捕获Future维护的异常 * t = ce; * } catch (ExecutionException ee) { * t = ee.getCause(); * } catch (InterruptedException ie) { * Thread.currentThread().interrupt(); // ignore/reset // 捕获到中断异常，重新设置中断 * } * } * if (t != null) * System.out.println(t); * } * }} * * @param r the runnable that has completed * @param t the exception that caused termination, or null if * execution completed normally */ protected void afterExecute(Runnable r, Throwable t) { } /** * Method invoked when the Executor has terminated. Default * implementation does nothing. Note: To properly nest multiple * overridings, subclasses should generally invoke * {@code super.terminated} within this method. * 当executor终止时调用该方法。 * 默认本类该方法没有具体实现。 * 注意：为了正确的嵌套(nest 巢 mutiple 多个，嵌套多个)覆盖，子类通常应该在该方法中调用super.terminated。 * */ protected void terminated() { } /* Predefined RejectedExecutionHandlers */ /* 预定义的RejectedExecutionHandlers */ /** * A handler for rejected tasks that runs the rejected task * directly in the calling thread of the {@code execute} method, * unless the executor has been shut down, in which case the task * is discarded. * 处理拒绝任务的handler，将直接在execute方法的调用线程中执行被拒绝的任务。 * 除非executor已经关闭，在这种情况下该任务将被丢弃。 * */ public static class CallerRunsPolicy implements RejectedExecutionHandler { /** * Creates a {@code CallerRunsPolicy}. */ public CallerRunsPolicy() { } /** * Executes task r in the caller's thread, unless the executor * has been shut down, in which case the task is discarded. * 在caller线程中执行任务r，除非executor已经关闭，这种情况下该任务将被抛弃。 * * @param r the runnable task requested to be executed r是需要执行的任务 * @param e the executor attempting to execute this task e是尝试执行该任务的executor（用于判断该executor线程池是否被关闭） */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { r.run(); } } } /** * A handler for rejected tasks that throws a * {@code RejectedExecutionException}. * 处理拒绝任务的handler，抛出RejectedExecutionException * */ public static class AbortPolicy implements RejectedExecutionHandler { /** * Creates an {@code AbortPolicy}. */ public AbortPolicy() { } /** * Always throws RejectedExecutionException. * 总是抛出RejectedExecutionException * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task * @throws RejectedExecutionException always */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\"Task \" + r.toString() + \" rejected from \" + e.toString()); } } /** * A handler for rejected tasks that silently discards the * rejected task. * 处理拒绝任务的handler，静默抛弃拒绝的任务 * */ public static class DiscardPolicy implements RejectedExecutionHandler { /** * Creates a {@code DiscardPolicy}. */ public DiscardPolicy() { } /** * Does nothing, which has the effect of discarding task r. * 啥也不做，就会静默丢弃任务r * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { } } /** * A handler for rejected tasks that discards the oldest unhandled * request and then retries {@code execute}, unless the executor * is shut down, in which case the task is discarded. * 处理拒绝任务的handler，丢弃最早未处理的请求（任务），然后对当前拒绝的任务重试execute， * 除非executor关闭，这种情况下该任务将被抛弃。 * */ public static class DiscardOldestPolicy implements RejectedExecutionHandler { /** * Creates a {@code DiscardOldestPolicy} for the given executor. */ public DiscardOldestPolicy() { } /** * Obtains and ignores the next task that the executor * would otherwise execute, if one is immediately available, * and then retries execution of task r, unless the executor * is shut down, in which case task r is instead discarded. * 获取并忽略executor将要执行的下一个任务， * 如果一个任务立即可用，那么重试任务r的执行， * 除非executor关闭，这种情况下该任务r将被抛弃。 * * @param r the runnable task requested to be executed * @param e the executor attempting to execute this task */ public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { if (!e.isShutdown()) { e.getQueue().poll(); // poll 非阻塞，没有返回null e.execute(r); } } } } "},"Doc/util/concurrent/locks/AbstractOwnableSynchronizer.java.html":{"url":"Doc/util/concurrent/locks/AbstractOwnableSynchronizer.java.html","title":"AbstractOwnableSynchronizer.Java","keywords":"","body":"AbstractOwnableSynchronizer /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent.locks; /** * A synchronizer that may be exclusively owned by a thread. This * class provides a basis for creating locks and related synchronizers * that may entail a notion of ownership. The * {@code AbstractOwnableSynchronizer} class itself does not manage or * use this information. However, subclasses and tools may use * appropriately maintained values to help control and monitor access * and provide diagnostics. * 同步器可能被一个线程独占 * 该类为创建可能需要所有权概念（notion）的锁和相关同步器提供了基础。 * AbstractOwnableSynchronizer类本身不管理或使用这些信息。 * 但是子类和工具可以使用适当（appropriately）维护（maintain）的值来帮助控制、访问控制器、提供诊断。 * * @since 1.6 * @author Doug Lea */ public abstract class AbstractOwnableSynchronizer implements java.io.Serializable { /** Use serial ID even though all fields transient. */ private static final long serialVersionUID = 3737899427754241961L; /** * Empty constructor for use by subclasses. */ protected AbstractOwnableSynchronizer() { } /** * The current owner of exclusive mode synchronization. * 独占锁当前的拥有者 * transient 在序列化过程中，用transient修饰的属性不会被序列化，也就是在序列化之后该属性无法被访问 * 一旦变量被transient修饰，变量将不再是对象持久化的一部分 */ private transient Thread exclusiveOwnerThread; /** * Sets the thread that currently owns exclusive access. * A {@code null} argument indicates that no thread owns access. * This method does not otherwise impose any synchronization or * {@code volatile} field accesses. * @param thread the owner thread * 设置线程为当前独占访问的拥有者。 * 参数为null表示没有线程拥有访问。也就是没有被占用。 * 此方法不会以其他方式强加任何同步或者volatile字段访问？？？ */ protected final void setExclusiveOwnerThread(Thread thread) { exclusiveOwnerThread = thread; } /** * Returns the thread last set by {@code setExclusiveOwnerThread}, * or {@code null} if never set. This method does not otherwise * impose any synchronization or {@code volatile} field accesses. * @return the owner thread * 返回最后一次通过setExclusiveOwnerThread设置的线程，如果从来没有设置，返回null。 * 此方法不会以其他方式强加任何同步或者volatile字段访问？？？ */ protected final Thread getExclusiveOwnerThread() { return exclusiveOwnerThread; } } "},"Doc/util/concurrent/locks/AbstractQueuedSynchronizer.java.html":{"url":"Doc/util/concurrent/locks/AbstractQueuedSynchronizer.java.html","title":"AbstractQueuedSynchronizer.Java","keywords":"","body":"AbstractQueuedSynchronizer /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 // assistance 协助 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent.locks; import java.util.concurrent.TimeUnit; import java.util.ArrayList; import java.util.Collection; import java.util.Date; import sun.misc.Unsafe; // 这里引入了一个Unsafe，是以前没看过的，等看完这个再看 /** * Provides a framework for implementing blocking locks and related * synchronizers (semaphores, events, etc) that rely on * first-in-first-out (FIFO) wait queues. This class is designed to * be a useful basis for most kinds of synchronizers that rely on a * single atomic {@code int} value to represent state. Subclasses * must define the protected methods that change this state, and which * define what that state means in terms of this object being acquired * or released. Given these, the other methods in this class carry * out all queuing and blocking mechanics. Subclasses can maintain * other state fields, but only the atomically updated {@code int} * value manipulated using methods {@link #getState}, {@link * #setState} and {@link #compareAndSetState} is tracked with respect * to synchronization. * 提供一个框架，用于实现依赖FIFO等待队列的阻塞锁和相关（related）同步器（semaphores、events等）。 * 这个类被设计成一个有用的基本类，对于大多数依赖单个原子int值代表状态的同步器。 * 子类必须定义用来改变状态的受保护方法，并定义该状态在获取/释放这个对象时的含义。 * 鉴于这些，此类中的其他方法执行（carry out）所有排队和阻塞机制。 * 子类可以维护（maintain）其他状态字段，但是只有使用getState、setState和compareAndSetState方法来操纵（manipulated）原子性的更新int值，才会在同步方面进行跟踪 * * Subclasses should be defined as non-public internal helper * classes that are used to implement the synchronization properties * of their enclosing class. Class * {@code AbstractQueuedSynchronizer} does not implement any * synchronization interface. Instead it defines methods such as * {@link #acquireInterruptibly} that can be invoked as * appropriate by concrete locks and related synchronizers to * implement their public methods. * 子类应该被定义为非公共的内部帮助类，用于实现其封闭类的同步属性。（就是AQS的子类都应该作为[想要FIFO同步属性的]类的内部类使用，就像ReentrantLock里面的Sync类） * AbstractQueuedSynchronizer类没有实现任何同步接口。 * 相反，它定义了例如acquireInterruptibly等方法，可以被有关（concrete）锁与相关同步器适当调用来实现他们的公共方法。 * * This class supports either or both a default exclusive * mode and a shared mode. When acquired in exclusive mode, * attempted acquires by other threads cannot succeed. Shared mode * acquires by multiple threads may (but need not) succeed. This class * does not &quot;understand&quot; these differences except in the * mechanical sense that when a shared mode acquire succeeds, the next * waiting thread (if one exists) must also determine whether it can * acquire as well. Threads waiting in the different modes share the * same FIFO queue. Usually, implementation subclasses support only * one of these modes, but both can come into play for example in a * {@link ReadWriteLock}. Subclasses that support only exclusive or * only shared modes need not define the methods supporting the unused mode. * 这个类支持独占（exclusive）模式与共享（shared）模式中的一种或者两种。 * 在独占模式中获取（可以理解为加锁）时，其他线程获取不会成功。 * 在共享模式中多个线程获取可能（但是不一定）成功。 * 该类不理解这些不同点，除了在机械意义上说，当共享模式获取成功时，下一个等待线程（如果有一个的话）必须确定它是否也可以获取。 * 在不同模式下等待的线程们共享同一个FIFO队列。（意味着一个AQS可以同时实现两种模式，就开头第一句话）。 * 通常，子类实现时只支持其中一种模式，但是两种都可以起到作用，例如在ReadWriteLock。 * 仅支持独占或者共享模式的子线程不需要实现支持未使用模式的方法（就是两种模式会有两套方法，如果只实现一种模式，只选择一套方法实现就行）（这里也可以解释为什么两套方法都不是abstract方法）。 * * This class defines a nested {@link ConditionObject} class that * can be used as a {@link Condition} implementation by subclasses * supporting exclusive mode for which method {@link * #isHeldExclusively} reports whether synchronization is exclusively * held with respect to the current thread, method {@link #release} * invoked with the current {@link #getState} value fully releases * this object, and {@link #acquire}, given this saved state value, * eventually restores this object to its previous acquired state. No * {@code AbstractQueuedSynchronizer} method otherwise creates such a * condition, so if this constraint cannot be met, do not use it. The * behavior of {@link ConditionObject} depends of course on the * semantics of its synchronizer implementation. * 该类定义了一个嵌套（nest）的ConditionObject对象，可以被支持独占模式的子类用来作为Condition的实现，其中： * isHeldExclusively方法报告是否针对当前线程独占同步， * 使用当前getState值调用release方法完全释放这个对象？？？ * 和acquire，给定保存状态值，最终将这个对象恢复到它之前获取的状态。（看不懂，等下看源码再看看是啥意思） * 没有AbstractQueuedSynchronizer方法否则创建这样的condition，所以如果这些约束不能被满足，不要使用它。 * ConditionObject的行为当然取决于其同步器实现的语义。 * * This class provides inspection, instrumentation, and monitoring * methods for the internal queue, as well as similar methods for * condition objects. These can be exported as desired into classes * using an {@code AbstractQueuedSynchronizer} for their * synchronization mechanics. * 该类提供对内部队列的检查、监测和监控的方法，对condition对象也有同样的方法。 * 可以根据需要导出到类中，使用AQS作为他们的同步机制。 * * Serialization of this class stores only the underlying atomic * integer maintaining state, so deserialized objects have empty * thread queues. Typical subclasses requiring serializability will * define a {@code readObject} method that restores this to a known * initial state upon deserialization. * 该类的序列化只存储底层的用原子interger维护的状态，所以反序列化对象有空的线程队列（或者翻译为线程队列为空）。 * 需要序列化的典型子类将定义readObject方法，在反序列化时将其恢复（restores）到已知（known）的初始化状态。 * * Usage * 用法 * * To use this class as the basis of a synchronizer, redefine the * following methods, as applicable, by inspecting and/or modifying * the synchronization state using {@link #getState}, {@link * #setState} and/or {@link #compareAndSetState}: * 使用该类作为同步器基础，根据适应性（applicable）情况重新定义下面几个方法（5个方法），可以使用getState、setState与compareAndSetState来检查（inspect）和修改同步器状态。 * * 下面这几个方法很关键，是实现类唯一能改的5个方法 * * {@link #tryAcquire} * {@link #tryRelease} * {@link #tryAcquireShared} * {@link #tryReleaseShared} * {@link #isHeldExclusively} * * * Each of these methods by default throws {@link * UnsupportedOperationException}. Implementations of these methods * must be internally thread-safe, and should in general be short and * not block. Defining these methods is the only supported * means of using this class. All other methods are declared * {@code final} because they cannot be independently varied. * 上面的每个方法默认抛出UnsupportedOperationException异常。 * 这些方法的实现必须是内部线程安全的，通常应该是简短并且不会阻塞的。 * 定义这些方法，是使用该类唯一支持的方法（means）（mean是意味着） * 所有的其他方法都声明为final，因为他们不能独立变化（varied） * （就是除了上面这五个方法可以重新定义，其他方法都改不了） * * You may also find the inherited methods from {@link * AbstractOwnableSynchronizer} useful to keep track of the thread * owning an exclusive synchronizer. You are encouraged to use them * -- this enables monitoring and diagnostic tools to assist users in * determining which threads hold locks. * 从AbstractOwnableSynchronizer继承的方法对追踪独占同步器的线程很有用。 * 鼓励使用这些方法 -- 监控和诊断工具能够去帮助使用者确定哪些线程持有锁 * * Even though this class is based on an internal FIFO queue, it * does not automatically enforce FIFO acquisition policies. The core * of exclusive synchronization takes the form: * 即使该类基于内部的FIFO队列，它也不会自动执行FIFO获取策略。 * 独占同步的核心形式为： * * * Acquire: * while (!tryAcquire(arg)) { // 获取失败会循环 * enqueue thread if it is not already queued; // 如果没有排队，则线程排队 * possibly block current thread; // 可能阻塞当前线程 * } * * Release: * if (tryRelease(arg)) // 释放成功 * unblock the first queued thread; // 第一个队列线程被唤醒 * * * (Shared mode is similar but may involve cascading signals.) * 共享模式类似，不过可能会涉及级联信号 * * 非公平锁与公平锁的大致实现 * Because checks in acquire are invoked before * enqueuing, a newly acquiring thread may barge ahead of * others that are blocked and queued. However, you can, if desired, * define {@code tryAcquire} and/or {@code tryAcquireShared} to * disable barging by internally invoking one or more of the inspection * methods, thereby providing a fair FIFO acquisition order. * In particular, most fair synchronizers can define {@code tryAcquire} * to return {@code false} if {@link #hasQueuedPredecessors} (a method * specifically designed to be used by fair synchronizers) returns * {@code true}. Other variations are possible. * 因为在入队之前会调用acquire进行检查，新的发起acquire的线程可能抢（barge ahead of抢先）在其它阻塞和在队列里的线程之前（拿到锁）。 * 但是，如果需要，定义tryAcquire和/或tryAcquireShared以通过内部调用一个或多个检查方式来禁止抢占（插队），从而提供公平（fair）的FIFO获取顺序。 * 特别的，如果hasQueuePredecessors（一个在公平同步器中使用的特定设计的方法）返回true，大多数公平同步器可以定义tryAcquire返回false。（就是等待队列不为空，就不允许插队） * 其他变化（variations）也是可能的。 * * Throughput and scalability are generally highest for the * default barging (also known as greedy, * renouncement, and convoy-avoidance) strategy. * While this is not guaranteed to be fair or starvation-free, earlier * queued threads are allowed to recontend before later queued * threads, and each recontention has an unbiased chance to succeed * against incoming threads. Also, while acquires do not * &quot;spin&quot; in the usual sense, they may perform multiple * invocations of {@code tryAcquire} interspersed with other * computations before blocking. This gives most of the benefits of * spins when exclusive synchronization is only briefly held, without * most of the liabilities when it isn't. If so desired, you can * augment this by preceding calls to acquire methods with * \"fast-path\" checks, possibly prechecking {@link #hasContended} * and/or {@link #hasQueuedThreads} to only do so if the synchronizer * is likely not to be contended. * 在默认抢占策略（又称greedy，renouncement和convoy-avoidance）下，吞吐量（throughput）和可扩展性（scalability）最高。 * 虽然这样不能保证公平或者没有饥饿，但是允许较早的排队进程在较晚的排队线程之前重新竞争（recontend），并且每次重新竞争都有平等的机会成功对抗新来的线程。 *（意思就是排在队首的线程一定在队列里的其他线程之前进行锁竞争，并且队首线程与新来的还未入队的线程竞争锁具有平等的概率） * 虽然acquires在通常意义上不会自旋（自旋就是重复操作直到某个状态退出，类似于while(cond){...}），但他们可能会在阻塞之前执行多次调用tryAcquire并穿插其他计算。 * 在独占同步只短暂持有时，提供的这种自旋的方式具有很大的好处；如果不是，也没有多大的坏处。（如果锁占有时间短暂，可能在自旋过程中就能拿到锁，减少了阻塞再唤醒的消耗） * 如果有需求，你可以通过使用“快速路径”检查来预先调用acquire方法以增强这一点，可能预先检查hasContended 和/或hasQueuedThreads方法，以仅在如果同步器很可能没有竞争时才这样做。 * （预先检查有没有竞争的情况，如果有不竞争的可能性，就通过自旋的方式来尝试获取锁） * * This class provides an efficient and scalable basis for * synchronization in part by specializing its range of use to * synchronizers that can rely on {@code int} state, acquire, and * release parameters, and an internal FIFO wait queue. When this does * not suffice, you can build synchronizers from a lower level using * {@link java.util.concurrent.atomic atomic} classes, your own custom * {@link java.util.Queue} classes, and {@link LockSupport} blocking * support. * 该类对于部分是通过将其使用范围专门用于依赖int状态、获取和释放参数以及内部FIFO等待队列的同步器，从而为同步提供有效（efficient）和可扩展的基础。 * 如果这不能满足（suffice），可以通过使用atomic类、自定义Queue类和LockSupprot阻塞支持从较低级别构建同步器 * * Usage Examples * 使用样例 * * Here is a non-reentrant mutual exclusion lock class that uses * the value zero to represent the unlocked state, and one to * represent the locked state. While a non-reentrant lock * does not strictly require recording of the current owner * thread, this class does so anyway to make usage easier to monitor. * It also supports conditions and exposes * one of the instrumentation methods: * 这里是一个不可重入的互斥锁class，用0代表解锁状态，用1代表加锁状态。 * 虽然不可重入锁不严格要求记录当前用有锁的线程，但这个类无论如何这样做是为了让使用更容易监控。 * 它还支持条件并公开一种检测方法： * * {@code * class Mutex implements Lock, java.io.Serializable { // mutex 是信号量 * * // Our internal helper class * private static class Sync extends AbstractQueuedSynchronizer { * // 继承AQS的，独占锁，得自己实现两个try方法（tryAcquire与tryRelease）与isHeldExclusively方法，因为AQS没有定义这仨实际操作。！！！！！！ * // Reports whether in locked state * protected boolean isHeldExclusively() { // 当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占 * return getState() == 1; * } * * // Acquires the lock if state is zero * public boolean tryAcquire(int acquires) { * assert acquires == 1; // Otherwise unused // assert是java的关键字--断言，如果表达式成立，则继续执行，否则抛出AssertionError，并终止执行。 * if (compareAndSetState(0, 1)) { // 使用CAS来设置加锁 * setExclusiveOwnerThread(Thread.currentThread()); * return true; * } * return false; * } * * // Releases the lock by setting state to zero * protected boolean tryRelease(int releases) { * assert releases == 1; // Otherwise unused * if (getState() == 0) throw new IllegalMonitorStateException(); * setExclusiveOwnerThread(null); * setState(0); // 不使用CAS，直接解锁 * return true; * } * * // Provides a Condition * // 需要用到Conditionobject的，得自己写newCondition方法，AQS不提供这个方法，只提供ConditionObject这个内部类 * Condition newCondition() { return new ConditionObject(); } * * // Deserializes properly // 正确反序列化 * private void readObject(ObjectInputStream s) * throws IOException, ClassNotFoundException { * s.defaultReadObject(); * setState(0); // reset to unlocked state // 重置为不加锁状态 * } * } * * // The sync object does all the hard work. We just forward to it. * private final Sync sync = new Sync(); * * // 通过Sync实现Lock接口的一些功能 * public void lock() { sync.acquire(1); } * public boolean tryLock() { return sync.tryAcquire(1); } * public void unlock() { sync.release(1); } * public Condition newCondition() { return sync.newCondition(); } * public boolean isLocked() { return sync.isHeldExclusively(); } * public boolean hasQueuedThreads() { return sync.hasQueuedThreads(); } * public void lockInterruptibly() throws InterruptedException { * sync.acquireInterruptibly(1); * } * public boolean tryLock(long timeout, TimeUnit unit) * throws InterruptedException { * return sync.tryAcquireNanos(1, unit.toNanos(timeout)); * } * }} * * Here is a latch class that is like a * {@link java.util.concurrent.CountDownLatch CountDownLatch} * except that it only requires a single {@code signal} to * fire. Because a latch is non-exclusive, it uses the {@code shared} * acquire and release methods. * 这里是一个类似于CountDownLatch的闩锁类，只需要单信号量就可以触发。 * 因为latch是个非独占的，它使用共享的acquire与release方法 * * {@code * class BooleanLatch { * * private static class Sync extends AbstractQueuedSynchronizer { * // 用AQS实现共享锁，得自己实现tryAcquireShared和tryReleaseShared方法 * boolean isSignalled() { return getState() != 0; } // 是否有信号，state初始化为0 * * protected int tryAcquireShared(int ignore) { * return isSignalled() ? 1 : -1; * } * * protected boolean tryReleaseShared(int ignore) { * setState(1); * return true; * } * } * * private final Sync sync = new Sync(); * public boolean isSignalled() { return sync.isSignalled(); } * public void signal() { sync.releaseShared(1); } // * public void await() throws InterruptedException { // 如果上来就调用await，那么因为state=0不满足条件，当前线程进入等待队列。如果现在state=1了，那么就不会阻塞直接执行 * sync.acquireSharedInterruptibly(1); * } * }} * * @since 1.5 * @author Doug Lea */ public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer // 用来记录当前独占锁的拥有者（拥有者是个Thread对象） implements java.io.Serializable { private static final long serialVersionUID = 7373984972572414691L; /** * Creates a new {@code AbstractQueuedSynchronizer} instance * with initial synchronization state of zero. * 初始化时，表示状态的state为0 */ protected AbstractQueuedSynchronizer() { } /** * Wait queue node class. * 等待队列节点类 * * The wait queue is a variant of a \"CLH\" (Craig, Landin, and * Hagersten) lock queue. CLH locks are normally used for * spinlocks. We instead use them for blocking synchronizers, but * use the same basic tactic of holding some of the control * information about a thread in the predecessor of its node. A * \"status\" field in each node keeps track of whether a thread * should block. A node is signalled when its predecessor * releases. Each node of the queue otherwise serves as a * specific-notification-style monitor holding a single waiting * thread. The status field does NOT control whether threads are * granted locks etc though. A thread may try to acquire if it is * first in the queue. But being first does not guarantee success; * it only gives the right to contend. So the currently released * contender thread may need to rewait. * 等待队列是CLH锁队列的变种（variant）。CLH锁通常用于自旋锁（spinlock）。 * 我们改为将它用于阻塞同步器，但也用相同的基本策略（tactic），即在node的前驱（predecessor）中保存有关线程的一些控制信息 * 每个节点中的“state”字段保持跟踪线程是否应该被阻塞。 * 节点在其前驱解锁（releases）的时候收到信号（理解为唤醒）。 * 队列中的每个node都充当一个特定通知式监视器，持有一个等待线程。（一个node里面包含了一个waiting线程对象） * 尽管status属性不会控制线程是否被授予锁。（status属性只是用来表名可以去竞争锁，不管会不会加锁成功） * 如果线程是队列里的第一个，它可能尝试去加锁（acquire） * 但是作为第一个不会保证一定能加锁成功；它只是被给予了去竞争的权利。（在unfair非公平锁里，队列的第一个线程要跟尚未入队的竞争线程一起竞争锁） * 所以当前释放的竞争者线程（也就是被唤醒的线程或者队列里的第一个线程）可能需要重新等待。 * * To enqueue into a CLH lock, you atomically splice it in as new * tail. To dequeue, you just set the head field. * CLH锁进队，需要原子性的将它拼接为新的尾部（tail）。 * 出队，只需要设置它的头部（head）字段。 * * +------+ prev +-----+ +-----+ * head | | * * Insertion into a CLH queue requires only a single atomic * operation on \"tail\", so there is a simple atomic point of * demarcation from unqueued to queued. Similarly, dequeuing * involves only updating the \"head\". However, it takes a bit * more work for nodes to determine who their successors are, * in part to deal with possible cancellation due to timeouts * and interrupts. * 插入CLH队列只需要对“tail”进行一次原子性操作，所以从未入队到入队有一个简单的原子分界点。（入队仅经过一个原子性操作） * 类似的，出队涉及只更新“head”。 * 然而，节点需要做更多的工作来确定他们的后继（successors）是谁，部分是为了处理由于超时和中断可能导致的取消。 * * 下面会讲取消的问题 * The \"prev\" links (not used in original CLH locks), are mainly * needed to handle cancellation. If a node is cancelled, its * successor is (normally) relinked to a non-cancelled * predecessor. For explanation of similar mechanics in the case * of spin locks, see the papers by Scott and Scherer at * http://www.cs.rochester.edu/u/scott/synchronization/ * “prev”连接（在原始CLH锁中未使用）主要用于处理取消。 * 如果一个node被取消，它的后继（通常）会重新连接到一个未取消的前驱。（就是一个节点被取消了，那么这个节点应该从CLH链上删除，这时候就需要它的后继去重新找到未取消的前驱） * 有关自旋锁情况下的类似机制解释，请参阅链接的论文 * * We also use \"next\" links to implement blocking mechanics. * The thread id for each node is kept in its own node, so a * predecessor signals the next node to wake up by traversing * next link to determine which thread it is. Determination of * successor must avoid races with newly queued nodes to set * the \"next\" fields of their predecessors. This is solved * when necessary by checking backwards from the atomically * updated \"tail\" when a node's successor appears to be null. * (Or, said differently, the next-links are an optimization * so that we don't usually need a backward scan.) * 我们还使用“next”连接来实现阻塞机制。 * 每个节点的线程ID保存在他们自己的node里，因此前驱信号是通过遍历next连接来确定它是哪个线程来通知唤醒下一个节点。？？？ * 确定后驱节点必须避免与新排队节点竞争以设置其前驱节点的“next”字段。（就是设置其前驱节点的next值时不要与新入队的节点发生冲突） * 当一个节点的后驱出现空时，如果必要，从原子更新的“tail”向后检查来解决。（换句话说，next连接是一种优化（optimization），所以我们通常不需要向后扫描）？？？ * * Cancellation introduces some conservatism to the basic * algorithms. Since we must poll for cancellation of other * nodes, we can miss noticing whether a cancelled node is * ahead or behind us. This is dealt with by always unparking * successors upon cancellation, allowing them to stabilize on * a new predecessor, unless we can identify an uncancelled * predecessor who will carry this responsibility. * 取消（Canellation）为基础算法引入了些保守性。由于我们必须轮询（poll）其他节点的取消，因此我们可能无法注意到取消的node是在我们之前还是之后。 * 通过在取消时总是解除后继来处理的，允许他们稳定在一个新的前驱上，除非我们可以确定一个未取消的前驱将承担这个责任。 * * CLH queues need a dummy header node to get started. But * we don't create them on construction, because it would be wasted * effort if there is never contention. Instead, the node * is constructed and head and tail pointers are set upon first * contention. * CLH队列需要一个虚拟（dummy）头结点来启动。但是我们不会在构建时创建他们，因为如果没有从来没有竞争，这个虚拟头就是浪费。 * 取而代之的是，在第一次竞争的时候，这个虚拟头节点将创建并设置head跟tail指针 * * Threads waiting on Conditions use the same nodes, but * use an additional link. Conditions only need to link nodes * in simple (non-concurrent) linked queues because they are * only accessed when exclusively held. Upon await, a node is * inserted into a condition queue. Upon signal, the node is * transferred to the main queue. A special value of status * field is used to mark which queue a node is on. * 在Condition上等待的线程使用相同的node，不过使用额外的连接（就是说有一个是CLH主链（主链=主队列），还有一些是针对不同的Condition建立的不同的链） * Condition只需要连接在简单的（非并发）链接队列上的node，因为他们仅在独占时才会被访问。 * 根据信号，node被转移到主队列上。（这个信号就是能够满足独占需求的信号，会将对应的Condition链转移到主队列上） * status字段的特殊值用来标记node所在的队列。 * * Thanks go to Dave Dice, Mark Moir, Victor Luchangco, Bill * Scherer and Michael Scott, along with members of JSR-166 * expert group, for helpful ideas, discussions, and critiques * on the design of this class. * 大佬感谢大佬们的时间，不看了 */ static final class Node { /** Marker to indicate a node is waiting in shared mode */ // 表明在共享模式下等待的node static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ // 表明在独占模式下等待的node static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled */ // 等待status值=1 表示线程取消 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ // 等待status值=-1 表示后继的线程需要唤醒 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ // 等待status值=-2 表示线程在等待条件（或者说线程在condition队列上） static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ // waitStatus值=-3 表示下一个acquireShared应该无条件传播 static final int PROPAGATE = -3; /** * Status field, taking on only the values: * SIGNAL: The successor of this node is (or will soon be) * blocked (via park), so the current node must * unpark its successor when it releases or * cancels. To avoid races, acquire methods must * first indicate they need a signal, * then retry the atomic acquire, and then, * on failure, block. * 当前节点的后继节点是被阻塞的，所以当前节点在释放或者取消的时候，必须unpark他的后继节点。 * 为了避免竞争，加锁方法必须首先声明他们需要一个信号，然后重试原子操作的加锁，然后在失败时阻塞。 * CANCELLED: This node is cancelled due to timeout or interrupt. * Nodes never leave this state. In particular, * a thread with cancelled node never again blocks. * 当前节点由于超时或者中断被取消。 * 节点从来不会离开这个状态。特别是，取消节点的线程永远不会再阻塞。 * CONDITION: This node is currently on a condition queue. * It will not be used as a sync queue node * until transferred, at which time the status * will be set to 0. (Use of this value here has * nothing to do with the other uses of the * field, but simplifies mechanics.) * 当前节点在条件队列中。 * 它在传输之前不会用作同步节点，到那个时候status将被设置为0。（在这里使用这个值和这个字段的其他用法无关，但是简化了机制） * PROPAGATE: A releaseShared should be propagated to other * nodes. This is set (for head node only) in * doReleaseShared to ensure propagation * continues, even if other operations have * since intervened. * 共享锁的释放（releaseShared）应当传播到其他节点。 * 这在doReleaseShared中设置（仅适用于头节点）以确保传播继续，即使其他的操作已经介入。 * 0: None of the above * 不处于以上情况的status值就是0 * * The values are arranged numerically to simplify use. * Non-negative values mean that a node doesn't need to * signal. So, most code doesn't need to check for particular * values, just for sign. * 值按数字化排列以简化使用。非负值意味着节点不需要发出信号。 * 所以，大多数代码不需要检查特定值，只需要检查符号。 * * The field is initialized to 0 for normal sync nodes, and * CONDITION for condition nodes. It is modified using CAS * (or when possible, unconditional volatile writes). * 该字段对于普通的同步节点初始化为0，对于condition节点初识化为CONDIITON。使用CAS进行修改（或者可以的话，使用无条件的volatile写入）。 */ volatile int waitStatus; /** * Link to predecessor node that current node/thread relies on * for checking waitStatus. Assigned during enqueuing, and nulled * out (for sake of GC) only upon dequeuing. Also, upon * cancellation of a predecessor, we short-circuit while * finding a non-cancelled one, which will always exist * because the head node is never cancelled: A node becomes * head only as a result of successful acquire. A * cancelled thread never succeeds in acquiring, and a thread only * cancels itself, not any other node. * 连接到当前线程/节点依赖检查waitStatus的前驱节点。 * 在入队期间分配，并仅在出队时取消（为了GC）。 * 同样，在前驱cancel时，当找到一个未取消的node之前进行短路，未取消的node始终存在，因为头节点从来不会cancel：一个节点要成为头结点，只有成功获取到结果。 * 取消的线程在加锁时永远不会成功，并且线程只能取消自己，不能取消其他node。 */ volatile Node prev; /** * Link to the successor node that the current node/thread * unparks upon release. Assigned during enqueuing, adjusted * when bypassing cancelled predecessors, and nulled out (for * sake of GC) when dequeued. The enq operation does not * assign next field of a predecessor until after attachment, * so seeing a null next field does not necessarily mean that * node is at end of queue. However, if a next field appears * to be null, we can scan prev's from the tail to * double-check. The next field of cancelled nodes is set to * point to the node itself instead of null, to make life * easier for isOnSyncQueue. * 连接到当前节点/线程在解锁时需要unpark的后继节点。 * 在入队时分配，在绕过取消的前驱时调整，在出队时取消（置为null）（为了GC）。 * enq操作直到连接后才分配前驱的next字段，因此看到next字段为null时不一定意味着节点是尾结点。 * 然而，如果next字段为null，可以从tail开始扫描上一个字段以进行二次检查。 * 取消节点的next字段指向该节点自己而不是null，以使isOnSyncQueue的工作更轻松。 */ volatile Node next; /** * The thread that enqueued this node. Initialized on * construction and nulled out after use. * 入队node的线程。 * 在构造时初始化，在使用后置为null。 */ volatile Thread thread; /** * Link to next node waiting on condition, or the special * value SHARED. Because condition queues are accessed only * when holding in exclusive mode, we just need a simple * linked queue to hold nodes while they are waiting on * conditions. They are then transferred to the queue to * re-acquire. And because conditions can only be exclusive, * we save a field by using special value to indicate shared * mode. * 连接到下一个等待条件（在条件上等待）的节点，或者特殊值SHARED。 * 因为条件队列（condition queues）只有在独占模式下才会被访问，所以当他们正在等待条件时，我们只需要一个简单的链接队列来保存节点。 * 然后将他们转移到主队列上来重新加锁。因为条件只能是独占的，所以我们通过使用特殊值来表名共享模式来保存字段。 */ Node nextWaiter; /** * Returns true if node is waiting in shared mode. */ final boolean isShared() { return nextWaiter == SHARED; } /** * Returns previous node, or throws NullPointerException if null. * Use when predecessor cannot be null. The null check could * be elided, but is present to help the VM. * 返回前驱节点，如果前驱为空，抛出NullPointerException * 当前驱不能为空时使用。 * 空检查可以省略，但是对VM有帮助。 * * @return the predecessor of this node */ final Node predecessor() throws NullPointerException { Node p = prev; if (p == null) throw new NullPointerException(); else return p; } Node() { // Used to establish initial head or SHARED marker // 独占的可以用来初始化头结点，共享的可以建立SHARED标记 } Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread; } Node(Thread thread, int waitStatus) { // Used by Condition this.waitStatus = waitStatus; this.thread = thread; } } /** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. * 等待队列的头，延迟初始化。 * 除了初始化，只能使用setHead方法来修改 * 提示：如果head存在，保证waitStatus不是CANCELLED */ private transient volatile Node head; /** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. * 等待队列的尾部，懒初始化。 * 只能通过enq方法，在增加新的等待node时修改。 */ private transient volatile Node tail; /** * The synchronization state. * 同步状态（获取锁的状态）（用volatile修饰，内存可见） */ private volatile int state; /** * Returns the current value of synchronization state. * This operation has memory semantics of a {@code volatile} read. * state由volatile修饰，这个操作有内存读的语义 * @return current state value */ protected final int getState() { return state; } /** * Sets the value of synchronization state. * This operation has memory semantics of a {@code volatile} write. * 通过volatile实现的内存语义，如果不安全，可以用下面的compareAndSetState方法。 * （这个方法通常被实现AQS的子类来调用，由子类决定如何更新state值） * * @param newState the new state value */ protected final void setState(int newState) { state = newState; } /** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * This operation has memory semantics of a {@code volatile} read * and write. * 用原子操作来设定state值 * （这个方法通常被实现AQS的子类来调用，由子类决定如何更新state值） * * @param expect the expected value * @param update the new value * @return {@code true} if successful. False return indicates that the actual * value was not equal to the expected value. */ protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } // Queuing utilities // 队列相关有益操作 /** * The number of nanoseconds for which it is faster to spin * rather than to use timed park. A rough estimate suffices * to improve responsiveness with very short timeouts. * 自旋比使用定时park具有更快的纳秒数。粗略估计满足在非常短的超时时间内提高响应。 * （自旋的时间，单位：纳秒） */ static final long spinForTimeoutThreshold = 1000L; /** * Inserts node into queue, initializing if necessary. See picture above. * node入队，必要的话初始化。上面有图。 * @param node the node to insert * @return node's predecessor */ private Node enq(final Node node) { for (;;) { // 这个循环是为了，如果CAS加锁失败，通过循环来重新加锁或者执行其他操作 Node t = tail; if (t == null) { // Must initialize // 队尾为null，说明现在队列里啥也没有，需要初始化队列（主要就是初始化队列Head与Tail，用来指向队列头尾） if (compareAndSetHead(new Node())) // 如果Head为null，则设置为New Node() tail = head; // 新增一个空节点，头和尾都指向同一个节点 } else { node.prev = t; // 当前节点的prev指向尾指针指向的节点 if (compareAndSetTail(t, node)) { // CAS修改tail指向的节点为当前节点 t.next = node; // 原来的最后一个节点next指向这个node return t; } } } } /** * Creates and enqueues node for current thread and given mode. * 为当前线程和给定模式创建和入队node * （用当前线程创建Node，根据指定的模式入队） * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // addWaiter的构造方法 // Try the fast path of enq; backup to full enq on failure // 尝试简化enq过程； Node pred = tail; // 前驱=tail（注意不是head） if (pred != null) { // 有tail，就简化enq(...)方法 node.prev = pred; // node.prev->tail if (compareAndSetTail(pred, node)) { // tail -> node pred.next = node; // 原来最后一个节点的next指向这个node，这个node的next是null return node; } } enq(node); // 上面的不行再走enq方法 return node; } /** * Sets head of queue to be node, thus dequeuing. Called only by * acquire methods. Also nulls out unused fields for sake of GC * and to suppress unnecessary signals and traversals. * 设置队列的head为该节点，从而出队。只能通过加锁方法调用。 * 将不使用的字段设置为null，为了GC与抑制不必要的信号与遍历。 * （相当于在该节点加锁成功时（就是成功获取到了锁，不需要再排队了），把当前节点设置为了原来的虚拟节点作为head） * * @param node the node */ private void setHead(Node node) { head = node; node.thread = null; node.prev = null; } /** * Wakes up node's successor, if one exists. * 如果存在，唤醒node的后继 * * @param node the node */ private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. * 如果状态为负值（可能需要信号量）尝试清楚以期待信号。 * 如果清除状态失败或者状态已经被等待线程修改了，也没问题。 * */ int ws = node.waitStatus; if (ws 0) { // 后继为null或者被取消 s = null; for (Node t = tail; t != null && t != node; t = t.prev) // 找到离当前node最近的未取消的非空（后继）node （当前node的prev是null，所以找到当前node之后就会终止） if (t.waitStatus 0 or * PROPAGATE status was set. * 设置队列头，并且检查它的后继者是否在共享模式下等待。 * 如果propagate > 0，或者设置了PROPAGATE状态，则进行传播。 * * @param node the node * @param propagate the return value from a tryAcquireShared * propagate入参值是tryAcquireShared方法的返回值。 */ private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below setHead(node); // 设置head指向node，并清除thread、prev的值为null（因为当前线程一定是成功获取到锁了，所以直接置为head，表示线程已执行，变成了虚拟head） /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. * 尝试向下一个队列里的node发出信号，如果： * 1. 调用者明确指示广播（Propagation），或者被前一个操作记录（作为h.waitStataus，在setHead之前或者之后）。（注意：waitStatus上的信号检查，因为PROPAGATE状态可能会转化为SIGNAL状态） * 2. 下一个节点在共享模式下等待，或者我们不知道，因为它看起来是null。 * 这个两项检查的保守性可能会导致不必要的唤醒，但是仅当有多个竞争加锁/解锁时，大多数很快就会需要信号。 */ // h == null 的判断是防止空指针异常。 // h.waitStatus 0 -> PROPAGATE。 // 那么为什么 SIGNAL 状态也要唤醒呢？这是因为在 doAcquireShared 中，第一次没有获得足够的资源时，shouldParkAfterFailedAcquire 将 PROPAGATE 状态转换成 SIGNAL，准备阻塞线程， // 但是第二次进入本方法时发现资源刚好够，而此时 h 的状态是 SIGNAL 状态 // (h = head) == null 是再次检查 if (propagate > 0 || h == null || h.waitStatus 0) node.prev = pred = pred.prev; // 不断修改当前节点的前驱 // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. // predNext是要取消拼接的明显节点（就是这个节点要退出队列，不在队列链上）。 // 如果没有，下面的CAS将失败，在这种场景下，在与另一个cancel或者signal竞争中输了，所以不需要采取后续操作。 Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. // 在这里可使用无条件的写而不是用CAS // 在这个原子步骤之后，其他节点可以跳过我们 // 之前，不受其他线程的干扰（waitStatus由volatile提供内存可见性） node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. // 如果待取消的节点是在队尾，直接移除 if (node == tail && compareAndSetTail(node, pred)) { // 设置tail为该节点的前驱节点 compareAndSetNext(pred, predNext, null); // 将该节点前驱节点的next设置为null（断开与该节点的关联，为了GC与其他操作） } else { // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. // 如果待取消的节点不在队尾（在队列中间（不能为队首，因为队首是个虚拟节点）） // 如果后继需要signal，尝试设置前驱节点的下一个连接，这样就会得到一个。 // 否则唤醒它进行广播（propagate） int ws; if (pred != head && // 如果该节点前面是队首，说明它前面没有等待的节点了 ((ws = pred.waitStatus) == Node.SIGNAL || // 前驱节点的ws本来就是SIGNAL (ws 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. * 前驱节点已经取消了。跳过取消节点重试找到未取消的。 */ do { node.prev = pred = pred.prev; } while (pred.waitStatus > 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. * 到了这里waitStatus一定是0或者PROPAGATE（-3）。声明需要一个signal，但park还没有执行。？？？ * 调用者应该重试以确保在park前无法加锁？？？ */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } /** * Convenience method to interrupt current thread. * 中断当前线程的便捷（convenience）方法 */ static void selfInterrupt() { Thread.currentThread().interrupt(); } /** * Convenience method to park and then check if interrupted * park和之后检查是否中断的便捷方法 * * @return {@code true} if interrupted */ private final boolean parkAndCheckInterrupt() { LockSupport.park(this); // park会响应中断，中断发生时会设置interrupted值，不会抛出异常 return Thread.interrupted(); // 返回检查到的线程中断状态，并清除中断状态 } /* * Various flavors of acquire, varying in exclusive/shared and * control modes. Each is mostly the same, but annoyingly * different. Only a little bit of factoring is possible due to * interactions of exception mechanics (including ensuring that we * cancel if tryAcquire throws exception) and other control, at * least not without hurting performance too much. * 不同形式的加锁，在独占/共享和控制模式下各有不同。 * 每一个都大致相同，但总有不同（annoyingly 恼人的）。 * 由于异常机制（包括确保我们在tryAcquire抛出的异常时cancel）和其他控制的相互作用，只能进行一点点分解，至少在不会过多损耗性能的前提下进行。 * */ /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * 对于已经在队列里的线程，在独占非中断模式下加锁。 * 由条件等待方法使用也能加锁？？？ * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting // 如果在等待时中断，返回true */ final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 如果加锁失败，这个for啥时候会退出呢？？？ final Node p = node.predecessor(); if (p == head && tryAcquire(arg)) { // 如果前驱是head，并且尝试获取独占锁成功 setHead(node); // 将当前node转移为head p.next = null; // help GC // 原来head的next指向null，断开head的连接，准备回收原head failed = false; // 加锁失败状态为false（表示获取锁成功） return interrupted; // 获取锁成功了，返回当前线程中断状态 } if (shouldParkAfterFailedAcquire(p, node) && // 判断在获取锁失败后是否需要park parkAndCheckInterrupt()) // 如果需要park，进行park并且检查中断状态（如果线程为中断状态，返回true）（因为park能响应中断，中断时会退出park） interrupted = true; // 能进到这里说明已经设置了park（阻塞），并且在park等待时发生了中断，当前线程中断状态为true。（这里true也不会直接抛出异常，而是继续去尝试获取锁） } } finally { if (failed) cancelAcquire(node); // 啥时候会走到这里呢？？？ } } /** * Acquires in exclusive interruptible mode. * 在独占可中断模式下加锁 * @param arg the acquire argument */ private void doAcquireInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.EXCLUSIVE); // 返回用当前线程封装的node boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head && tryAcquire(arg)) { // tryAcquire()方法需要自己实现，来决定如何实现尝试获取锁的语义，在AQS里没有阻塞/非阻塞的概念 setHead(node); p.next = null; // help GC failed = false; return; } if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) throw new InterruptedException(); // 如果检查到线程中断，抛出异常 } } finally { if (failed) cancelAcquire(node); // 啥时候会走到这里呢？？？ } } /** * Acquires in exclusive timed mode. * 在独占限时模式下加锁 * * @param arg the acquire argument * @param nanosTimeout max wait time // 最大等待时间 * @return {@code true} if acquired // 成功加锁返回true */ private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (nanosTimeout spinForTimeoutThreshold) // 如果等待时间（相当于预估的还需要等待时间）> 自旋的时间阈值，就进入park（如果预估时间小于自旋的阈值，可以通过自旋继续等待）。 // 这里表明，如果给一个较小的等待时间，就可以不断的通过自旋来加锁（当然也会因为自旋加锁失败，需要不断调用加锁的消耗） LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } /** * Acquires in shared uninterruptible mode. * 在共享非中断模式下加锁 * @param arg the acquire argument */ private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); // 需要自己实现的5大方法之一，在共享模式下尝试加锁。负值表示失败，0表示当前成功，但后继的线程们加锁可能会失败，正值表示当前成功，后继的线程们加锁也可能成功 if (r >= 0) { setHeadAndPropagate(node, r); // 将当前节点设置为头结点（表示当前节点已成功获取到锁），如果其他后继节点也能获取到锁（毕竟是个共享锁），也会被从park唤醒 p.next = null; // help GC if (interrupted) selfInterrupt(); // 如果检测到线程中断，调用中断方法（只是写了个中断标记，没有抛出异常） failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) // 检测线程是否被中断 interrupted = true; // 如果判断在加锁失败时需要阻塞（park），并且阻塞后检测到线程被中断，更新当前中断标记为true } } finally { // 不知道什么时候会走到这里，可能是中断的时候？？？ if (failed) cancelAcquire(node); } } /** * Acquires in shared interruptible mode. * 在共享可中断模式下加锁 * @param arg the acquire argument */ private void doAcquireSharedInterruptibly(int arg) throws InterruptedException { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { for (;;) { final Node p = node.predecessor(); if (p == head) { int r = tryAcquireShared(arg); if (r >= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) throw new InterruptedException(); // 与上面不同的就在这里，如果检测到了中断，直接抛出中断异常 } } finally { if (failed) cancelAcquire(node); } } /** * Acquires in shared timed mode. * 在共享限时模式下加锁 * * @param arg the acquire argument * @param nanosTimeout max wait time * @return {@code true} if acquired */ private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException { if (nanosTimeout = 0) { setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return true; } } nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); // 同样的，也会抛出中断异常 } } finally { if (failed) cancelAcquire(node); } } // Main exported methods // 主要对外方法（上面那些都是private的方法） // 下面这5个protected方法需要子类来实现 /** * Attempts to acquire in exclusive mode. This method should query * if the state of the object permits it to be acquired in the * exclusive mode, and if so to acquire it. * 尝试以独占模式加锁。这个方法应当检查对象的状态是否允许在独占模式下加锁，如果允许则加锁 * * This method is always invoked by the thread performing * acquire. If this method reports failure, the acquire method * may queue the thread, if it is not already queued, until it is * signalled by a release from some other thread. This can be used * to implement method {@link Lock#tryLock()}. * 这个方法总是被执行加锁（acquire）的线程调用。 * 如果此方法报告失败，这个acquire方法可能会将线程入队（如果该线程还没有入队），直到它被其他线程发出release（释放）信号。 * 可以通过tryLock()方法实现。 * * The default * implementation throws {@link UnsupportedOperationException}. * * @param arg the acquire argument. This value is always the one * passed to an acquire method, or is the value saved on entry * to a condition wait. The value is otherwise uninterpreted * and can represent anything you like. * 加锁参数。该值始终是传递给acquire方法的值，或者是进入条件等待时保存的值。 * 该值是未经解释的，可以表示你喜欢的任何内容 * @return {@code true} if successful. Upon success, this object has * been acquired. * @throws IllegalMonitorStateException if acquiring would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * 如果加锁会导致同步器进入非法状态则会抛出IllegalMonitorStateException。 * 必须以一致的方式抛出此异常，同步器才能正常工作（也是个runtimeException） * @throws UnsupportedOperationException if exclusive mode is not supported // 如果不支持独占模式，抛出UnsupportedOperationException（这是个runtimeException） */ protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } /** * Attempts to set the state to reflect a release in exclusive * mode. * 尝试设置状态来反映独占模式下的解锁/释放（release） * * This method is always invoked by the thread performing release. * 该方法总是被执行解锁（release）的线程调用 * * The default implementation throws * {@link UnsupportedOperationException}. * * @param arg the release argument. This value is always the one * passed to a release method, or the current state value upon * entry to a condition wait. The value is otherwise * uninterpreted and can represent anything you like. * @return {@code true} if this object is now in a fully released * state, so that any waiting threads may attempt to acquire; * and {@code false} otherwise. * true：表示此对象处于完全释放状态，任何等待线程都可以尝试获取 * @throws IllegalMonitorStateException if releasing would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * @throws UnsupportedOperationException if exclusive mode is not supported */ protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } /** * Attempts to acquire in shared mode. This method should query if * the state of the object permits it to be acquired in the shared * mode, and if so to acquire it. * 尝试在共享模式下加锁。这个方法应当检查对象的状态是否允许在共享模式下加锁，如果允许则加锁 * * This method is always invoked by the thread performing * acquire. If this method reports failure, the acquire method * may queue the thread, if it is not already queued, until it is * signalled by a release from some other thread. * 这个方法总是被想加锁的线程调用。 * 如果这个方法报告失败，这个方法可能会将还没在等待队列里的线程入队，直到其他线程释放锁时来唤醒它。 * * The default implementation throws {@link * UnsupportedOperationException}. * * @param arg the acquire argument. This value is always the one * passed to an acquire method, or is the value saved on entry * to a condition wait. The value is otherwise uninterpreted * and can represent anything you like. * @return a negative value on failure; zero if acquisition in shared * mode succeeded but no subsequent shared-mode acquire can * succeed; and a positive value if acquisition in shared * mode succeeded and subsequent shared-mode acquires might * also succeed, in which case a subsequent waiting thread * must check availability. (Support for three different * return values enables this method to be used in contexts * where acquires only sometimes act exclusively.) Upon * success, this object has been acquired. * 负值表示失败； * 0表示在共享模式下加锁成功但是在随后的共享模式加锁中没有成功；（就是当前线程能够获取到共享锁，没有剩余的共享锁可以被获取） * 正值表示在共享模式下加锁成功但是在随后的共享模式加锁中也可能成功（就是当前线程能够获取到共享锁，还有剩余的共享锁可以被获取），在这种情况下，后续等待线程必须检查可用性。 * （支持三种不同的返回值，能够保证这个方法能够在仅执行独占行为的上下文中使用） * 成功值表示该对象加锁成功。 * * @throws IllegalMonitorStateException if acquiring would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * @throws UnsupportedOperationException if shared mode is not supported */ protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } /** * Attempts to set the state to reflect a release in shared mode. * 尝试设置状态来反映在共享模式下解锁/释放（release） * * This method is always invoked by the thread performing release. * * The default implementation throws * {@link UnsupportedOperationException}. * * @param arg the release argument. This value is always the one * passed to a release method, or the current state value upon * entry to a condition wait. The value is otherwise * uninterpreted and can represent anything you like. * @return {@code true} if this release of shared mode may permit a * waiting acquire (shared or exclusive) to succeed; and * {@code false} otherwise * true：表示共享模式下的release可以允许等待获取（共享/独占）操作成功 * @throws IllegalMonitorStateException if releasing would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * @throws UnsupportedOperationException if shared mode is not supported */ protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException(); } /** * Returns {@code true} if synchronization is held exclusively with * respect to the current (calling) thread. This method is invoked * upon each call to a non-waiting {@link ConditionObject} method. * (Waiting methods instead invoke {@link #release}.) * 如果当前（调用）线程持有独占的同步锁，将返回true。 * 这个方法被每个非等待的ConditionObject方法调用。 * （等待方法替换成调用release） * * The default implementation throws {@link * UnsupportedOperationException}. This method is invoked * internally only within {@link ConditionObject} methods, so need * not be defined if conditions are not used. * 这个方法仅在ConditionObject的方法内部调用，如果不使用Condition就不用定义这个方法。 * * @return {@code true} if synchronization is held exclusively; * {@code false} otherwise * @throws UnsupportedOperationException if conditions are not supported */ protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } // 下面是完全对外的public方法 /** * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once {@link #tryAcquire}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquire} until success. This method can be used * to implement method {@link Lock#lock}. * 在独占模式下获取，忽略中断。通过至少调用一次tryAcquire来实现，在成功时返回。 * 否则线程会排队，可能会反复阻塞与解除阻塞，调用tryAcquire直到成功。 * 这个方法可以用来实现lock方法。 * （拿不到锁就入队排队，等不到就阻塞等待唤醒） * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquire} but is otherwise uninterpreted and * can represent anything you like. */ public final void acquire(int arg) { if (!tryAcquire(arg) && // 尝试获取失败 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) // addWaiter(Node.EXCLUSIVE), arg)将当前线程按独占模式创建node，加入到队列中 // acquireQueued如果当前node的前驱是head，那么尝试获取，如果不是，分析是否阻塞等待与阻塞唤醒后检测中断信号 selfInterrupt(); } /** * Acquires in exclusive mode, aborting if interrupted. * Implemented by first checking interrupt status, then invoking * at least once {@link #tryAcquire}, returning on * success. Otherwise the thread is queued, possibly repeatedly * blocking and unblocking, invoking {@link #tryAcquire} * until success or the thread is interrupted. This method can be * used to implement method {@link Lock#lockInterruptibly}. * 在独占模式下获取，如果中断了就终止。 * 通过首先检查中断状态，然后至少调用一次tryAcquire实现，成功时返回。 * 否则线程入队，可能反复阻塞与取消阻塞，调用tryAcquire直到成功或者线程被中断。 * 这个方法可以用来实现lockInterruptibly方法。 * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquire} but is otherwise uninterpreted and * can represent anything you like. * @throws InterruptedException if the current thread is interrupted */ public final void acquireInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); // 如果获取失败，调用doAcquireInterruptibly方法，跟acquireQueued方法类似，只是会在检测到线程中断后，直接抛出中断异常，而不是继续尝试获取锁 } /** * Attempts to acquire in exclusive mode, aborting if interrupted, * and failing if the given timeout elapses. Implemented by first * checking interrupt status, then invoking at least once {@link * #tryAcquire}, returning on success. Otherwise, the thread is * queued, possibly repeatedly blocking and unblocking, invoking * {@link #tryAcquire} until success or the thread is interrupted * or the timeout elapses. This method can be used to implement * method {@link Lock#tryLock(long, TimeUnit)}. * 在独占模式下获取，如果中断或者超时就终止或者失败。 * 通过首先检查中断状态，然后至少一次调用tryAcquire来实现，成功时返回。 * 否则当前线程入队，可能反复阻塞与取消阻塞，调用tryAcquire直到获取成功，或者被中断，或者超时。 * 这个方法可以用来实现tryLock(long, TimeUnit)方法 * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquire} but is otherwise uninterpreted and * can represent anything you like. * @param nanosTimeout the maximum number of nanoseconds to wait * @return {@code true} if acquired; {@code false} if timed out * @throws InterruptedException if the current thread is interrupted */ public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); } /** * Releases in exclusive mode. Implemented by unblocking one or * more threads if {@link #tryRelease} returns true. * This method can be used to implement method {@link Lock#unlock}. * 在独占模式下释放。如果tryRelease返回true，通过解除阻塞一个或多个线程来实现。 * 这个方法可以用来实现unlock方法 * * @param arg the release argument. This value is conveyed to * {@link #tryRelease} but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from {@link #tryRelease} */ public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null && h.waitStatus != 0) // 如果有头结点，并且ws不是默认值0 unparkSuccessor(h); // 唤醒一个后继节点，这个方法会把ws置为0，表示正在操作？？？ return true; } return false; } /** * Acquires in shared mode, ignoring interrupts. Implemented by * first invoking at least once {@link #tryAcquireShared}, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking {@link * #tryAcquireShared} until success. * 共享模式下获取，忽略中断。 * 通过首先调用至少一次tryAcquireShared方法来实现，成功时返回。 * 否则该线程入队，可能反复阻塞或者解除阻塞，调用tryAcquireShared直到成功。 * * @param arg the acquire argument. This value is conveyed to * {@link #tryAcquireShared} but is otherwise uninterpreted * and can represent anything you like. */ public final void acquireShared(int arg) { if (tryAcquireShared(arg) =0，会调用setHeadAndPropagate方法，先把当前node设置为head，然后尝试释放后继的node；如果tryAcquireShared返回= 0 || doAcquireSharedNanos(arg, nanosTimeout); // 正常逻辑操作，没啥说的 } /** * Releases in shared mode. Implemented by unblocking one or more * threads if {@link #tryReleaseShared} returns true. * 共享模式下释放。 * 如果tryReleaseShared返回true，通过解除阻塞一个或多个线程来实现。 * * @param arg the release argument. This value is conveyed to * {@link #tryReleaseShared} but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from {@link #tryReleaseShared} */ public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } // Queue inspection methods // 队列检查方法 /** * Queries whether any threads are waiting to acquire. Note that * because cancellations due to interrupts and timeouts may occur * at any time, a {@code true} return does not guarantee that any * other thread will ever acquire. * 查询是否有线程正在等待获取。 * 注意：由于可能在任意时间发生中断或者超时，会导致线程取消，所以返回true也不能保证有线程永远在等待获取。 * * In this implementation, this operation returns in * constant time. * * @return {@code true} if there may be other threads waiting to acquire */ public final boolean hasQueuedThreads() { return head != tail; } /** * Queries whether any threads have ever contended to acquire this * synchronizer; that is if an acquire method has ever blocked. * 查询是否有线程竞争过获取这个同步器； * 也就是说，曾经有线程调用acquire方法阻塞过。 * * In this implementation, this operation returns in * constant time. * * @return {@code true} if there has ever been contention */ public final boolean hasContended() { return head != null; } /** * Returns the first (longest-waiting) thread in the queue, or * {@code null} if no threads are currently queued. * 返回队列里的第一个线程（等待时间最长的），如果没有线程在当前队列，返回null * * In this implementation, this operation normally returns in * constant time, but may iterate upon contention if other threads are * concurrently modifying the queue. * * @return the first (longest-waiting) thread in the queue, or * {@code null} if no threads are currently queued */ public final Thread getFirstQueuedThread() { // handle only fast path, else relay return (head == tail) ? null : fullGetFirstQueuedThread(); } /** * Version of getFirstQueuedThread called when fastpath fails * 快速路径失败时调用的版本 */ private Thread fullGetFirstQueuedThread() { /* * The first node is normally head.next. Try to get its * thread field, ensuring consistent reads: If thread * field is nulled out or s.prev is no longer head, then * some other thread(s) concurrently performed setHead in * between some of our reads. We try this twice before * resorting to traversal. * 确保读一致性，如果线程字段被置null，或者s.prev不再是head，然后其他线程并发的在我们读中间setHead。 * 尝试两次 */ Node h, s; Thread st; if (((h = head) != null && (s = h.next) != null && s.prev == head && (st = s.thread) != null) || ((h = head) != null && (s = h.next) != null && s.prev == head && (st = s.thread) != null)) return st; /* * Head's next field might not have been set yet, or may have * been unset after setHead. So we must check to see if tail * is actually first node. If not, we continue on, safely * traversing from tail back to head to find first, * guaranteeing termination. * head的next可能还没有设置，或者可能在setHead之后未设置。所以应该检查tail是否实际上是第一个节点。 * 如果不是，继续安全的从tail向head查找第一个，保证终止。 */ Node t = tail; Thread firstThread = null; while (t != null && t != head) { Thread tt = t.thread; if (tt != null) firstThread = tt; t = t.prev; } return firstThread; } /** * Returns true if the given thread is currently queued. * 如果当前线程在排队，返回true * * This implementation traverses the queue to determine * presence of the given thread. * * @param thread the thread * @return {@code true} if the given thread is on the queue * @throws NullPointerException if the thread is null */ public final boolean isQueued(Thread thread) { if (thread == null) throw new NullPointerException(); for (Node p = tail; p != null; p = p.prev) if (p.thread == thread) return true; return false; } /** * Returns {@code true} if the apparent first queued thread, if one * exists, is waiting in exclusive mode. If this method returns * {@code true}, and the current thread is attempting to acquire in * shared mode (that is, this method is invoked from {@link * #tryAcquireShared}) then it is guaranteed that the current thread * is not the first queued thread. Used only as a heuristic in * ReentrantReadWriteLock. * 如果明显的第一个线程（如果有的话）在独占模式下等待，返回true。 * 如果该方法返回true，并且当前线程试图在共享模式下获取（这意味着，这个方式是通过tryAcquireShared方法调用的），则可以保证当前线程不是第一个排队的线程。 * 仅用于ReentrantReadWriteLcok的启发式方法 * */ final boolean apparentlyFirstQueuedIsExclusive() { Node h, s; return (h = head) != null && (s = h.next) != null && !s.isShared() && s.thread != null; } /** * Queries whether any threads have been waiting to acquire longer * than the current thread. * 查询是否有比当前线程等待时间更久的线程。 * * An invocation of this method is equivalent to (but may be * more efficient than): * 调用此方法等效于（但是可能更高效）： * {@code * getFirstQueuedThread() != Thread.currentThread() && * hasQueuedThreads()} * 当前线程不是队列里的第一个，并且队列里有线程 * * Note that because cancellations due to interrupts and * timeouts may occur at any time, a {@code true} return does not * guarantee that some other thread will acquire before the current * thread. Likewise, it is possible for another thread to win a * race to enqueue after this method has returned {@code false}, * due to the queue being empty. * 这个方法不能保证这个线程前面一定有老线程，或者这个线程一定是等待时间最长的线程 * 原因1、可能在这个方法返回true后，前面的线程由于中断或者超时导致退出了等待 * 原因2、可能在这个方法返回false后，在队列为空时，有新的线程在与该线程入队竞争时获胜，比该线程更早入队 * * This method is designed to be used by a fair synchronizer to * avoid barging. * Such a synchronizer's {@link #tryAcquire} method should return * {@code false}, and its {@link #tryAcquireShared} method should * return a negative value, if this method returns {@code true} * (unless this is a reentrant acquire). For example, the {@code * tryAcquire} method for a fair, reentrant, exclusive mode * synchronizer might look like this: * 该方法是为了公平同步器设计的，避免插队情况。 * 如果这个方法返回true，这种同步器的tryAcquire方法应该返回false，它的tryAcquireShared方法应该返回负值，除非这是一个可重入的获取过程。 * 例如：公平、可重入、独占模式下的同步器tryAcquire方法可能如下所示： * * {@code * protected boolean tryAcquire(int arg) { * if (isHeldExclusively()) { // 先看是不是当前线程独占 * // A reentrant acquire; increment hold count * return true; * } else if (hasQueuedPredecessors()) { // 再看前面有没有排队的（现在线程可能不在队列，也可能在队列里，不影响判断） * return false; * } else { // 都没有就准备竞争 * // try to acquire normally * } * }} * * @return {@code true} if there is a queued thread preceding the * current thread, and {@code false} if the current thread * is at the head of the queue or the queue is empty * @since 1.7 */ public final boolean hasQueuedPredecessors() { // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. // 正确性取决于head在tail之前被初始化，并且如果当前线程是在队列的第一个，那么head.next是准确的 Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; // 方法返回true表示在当前线程之前还有等待的线程，false表示没有 // head != tail排除了两种情况： // 1、head = tail = null（此时队列还未有阶段入过队） // 2、head = tail = node（此时队列里曾经有入过队的，但都已出队） // (s = h.next) == null（可能存在一种情况，设置了head，但是next还没来得及设置为（除了head之外）第一个等待的线程节点，这种情况下，next不准确，因为不知道next是当前线程还是其他线程，为了保险起见，返回true） // s.thread != Thread.currentThread() （这个简单了，判断第一个等待节点是不是该线程的节点，不是的话返回true） return h != t && ((s = h.next) == null || s.thread != Thread.currentThread()); } // Instrumentation and monitoring methods // 仪表盘和监控方法 /** * Returns an estimate of the number of threads waiting to * acquire. The value is only an estimate because the number of * threads may change dynamically while this method traverses * internal data structures. This method is designed for use in * monitoring system state, not for synchronization * control. * 返回预估的等待获取的线程数。 * 这个返回值只是个预估值，因为在方法遍历内部数据结构时，线程是可能动态变化的。 * 该方法是为了监控系统状态设计的，不是为了同步。 * * @return the estimated number of threads waiting to acquire */ public final int getQueueLength() { int n = 0; for (Node p = tail; p != null; p = p.prev) { // 再次理解一下，说是queue，其实没有维护一个队列长度的属性 if (p.thread != null) ++n; } return n; } /** * Returns a collection containing threads that may be waiting to * acquire. Because the actual set of threads may change * dynamically while constructing this result, the returned * collection is only a best-effort estimate. The elements of the * returned collection are in no particular order. This method is * designed to facilitate construction of subclasses that provide * more extensive monitoring facilities. * 返回一个包含正在等待获取的线程集合。 * 因为在构造该集合结果时，实际线程可能在动态改变，所以这个返回的集合只是一个尽力的预估。 * 返回集合里的线程没有特定顺序。 * 该方法是为了促进子类构建而设计，以提高更广泛的监控设备 * * @return the collection of threads */ public final Collection getQueuedThreads() { ArrayList list = new ArrayList(); for (Node p = tail; p != null; p = p.prev) { Thread t = p.thread; if (t != null) list.add(t); } return list; } /** * Returns a collection containing threads that may be waiting to * acquire in exclusive mode. This has the same properties * as {@link #getQueuedThreads} except that it only returns * those threads waiting due to an exclusive acquire. * 返回一个包含可能正在独占模式下等待的线程集合。 * 跟上面的getQueueThreads方法类似，除了只返回独占获取的等待线程 * * @return the collection of threads */ public final Collection getExclusiveQueuedThreads() { ArrayList list = new ArrayList(); for (Node p = tail; p != null; p = p.prev) { if (!p.isShared()) { // 去掉共享模式下的等待线程（就是说一个queue里面可能既有独占，又有共享的等待线程） Thread t = p.thread; if (t != null) list.add(t); } } return list; } /** * Returns a collection containing threads that may be waiting to * acquire in shared mode. This has the same properties * as {@link #getQueuedThreads} except that it only returns * those threads waiting due to a shared acquire. * 返回一个包含在共享模式下等待的线程集合。 * * @return the collection of threads */ public final Collection getSharedQueuedThreads() { ArrayList list = new ArrayList(); for (Node p = tail; p != null; p = p.prev) { if (p.isShared()) { // 只要共享模式下的 Thread t = p.thread; if (t != null) list.add(t); } } return list; } /** * Returns a string identifying this synchronizer, as well as its state. * The state, in brackets, includes the String {@code \"State =\"} * followed by the current value of {@link #getState}, and either * {@code \"nonempty\"} or {@code \"empty\"} depending on whether the * queue is empty. * 返回标识此同步器和state的字符串（state由子类实现，在AQS中没使用） * （bracket 括号） * @return a string identifying this synchronizer, as well as its state */ public String toString() { int s = getState(); String q = hasQueuedThreads() ? \"non\" : \"\"; return super.toString() + \"[State = \" + s + \", \" + q + \"empty queue]\"; } // Internal support methods for Conditions // 内部支持Condition的方法 /** * Returns true if a node, always one that was initially placed on * a condition queue, is now waiting to reacquire on sync queue. * 如果一个节点始终是最初放在条件队列中的节点，现在正在等待重新获取sync队列，则返回true * * @param node the node * @return true if is reacquiring */ final boolean isOnSyncQueue(Node node) { // 如果节点的等待状态是CONDITION，说明在condition队列中（不在AQS主队列）； // 如果prev是null，并且是AQS，也是已获取到锁的head节点，也不在AQS主队列中等待 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue // 意思是只有AQS主队列才有next跟prev关系，如果next不为空，一定在AQS sync主队列里 return true; /* * node.prev can be non-null, but not yet on queue because * the CAS to place it on queue can fail. So we have to * traverse from tail to make sure it actually made it. It * will always be near the tail in calls to this method, and * unless the CAS failed (which is unlikely), it will be * there, so we hardly ever traverse much. * node.prev如果不为null，不能保证一定在队列里，因为通过CAS操作入队时会失败。（可以看addWaiter方法，先设置node.prev=tail，然后去做的CAS，只有CAS成功了才算成功入队） * 所以从tail向前遍历，确保它确实入队了。 * 除非CAS失败（基本不太可能），否则在调用这个方法时它总是靠近尾部，所以我们不会遍历太多。 */ return findNodeFromTail(node); } /** * Returns true if node is on sync queue by searching backwards from tail. * Called only when needed by isOnSyncQueue. * 从sync队列的tail向前遍历，如果找到该节点，就返回true * * @return true if present */ private boolean findNodeFromTail(Node node) { Node t = tail; for (;;) { if (t == node) return true; if (t == null) // 要么tail为null，要么找到了head的prev，也是null，可以看setHead return false; t = t.prev; } } /** * Transfers a node from a condition queue onto sync queue. * Returns true if successful. * 将node从condition队列转移到sync队列。 * 成功转移返回true * * @param node the node * @return true if successfully transferred (else the node was * cancelled before signal) */ final boolean transferForSignal(Node node) { /* * If cannot change waitStatus, the node has been cancelled. * 如果不能更改ws，说明这个node已经被取消了。（在condition队列上的node一定是CONDITION状态，如果node存活，一定可以CAS改变ws） */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). * 拼接到队列，尝试设置前驱的ws值，表名当前线程在（可能）等待。 * 如果前驱被取消或者试图设置前驱的ws失败，则唤醒以重新同步（在这种情况下，waitStatus不匹配可能是暂时且无害的错误） * */ Node p = enq(node); // 加入到sync队列中，并返回前驱节点 int ws = p.waitStatus; if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) // 如果前驱的ws>0（说明前驱节点被cancel了），或者设置前驱的ws为SIGNAL失败，那么直接唤醒当前这个node去竞争资源（竞争不到咋办？？？由具体的实现去做，比如重新入队） LockSupport.unpark(node.thread); return true; } /** * Transfers node, if necessary, to sync queue after a cancelled wait. * Returns true if thread was cancelled before being signalled. * 如果必要的话，在取消等待后，转移node到sync队列。（这个取消等待，不是在condition队列wait时被CANCEL了，而是wait的条件满足，或者等待时间超时，被唤醒了，才调用的这个方法） * 如果线程在收到信号前取消等待了，返回true * * @param node the node * @return true if cancelled before the node was signalled */ final boolean transferAfterCancelledWait(Node node) { if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) { // 如果当前状态为CONDITION，则进行入sync队列操作 enq(node); return true; } // 不为CONDITION状态的话，有两种情况 // 1、CANCEL 说明当前节点被取消了，但不知道是在队列里被取消还是没在队列里被取消 // 2、其他状态 说明当前节点在队列里 // 上面那句话不对，其实不为CONDITION只有一种情况，那就是该node已经进了sync队列，并且ws发生了变化。在condition队列里ws是不会变的。这句话也不对，condition里面状态可以变。 /* * If we lost out to a signal(), then we can't proceed * until it finishes its enq(). Cancelling during an * incomplete transfer is both rare and transient, so just * spin. * 如果我们输给了signal方法，那么在它完成enq()之前不能继续做别的。 * 在未完成转移时取消，是罕见又短暂的，因此只需要自旋。 */ while (!isOnSyncQueue(node)) Thread.yield(); return false; } /** * Invokes release with current state value; returns saved state. * Cancels node and throws exception on failure. * 在当前state值下调用release； * 返回保存的state值 * 在失败时取消节点并抛出异常 * * @param node the condition node for this wait * @return previous sync state */ final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); if (release(savedState)) { // 用当前state值作为release(arg)的入参，如果自定义的tryRelease返回true，从head开始唤醒后继节点 failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; // 如果唤醒失败，就取消当前节点（这是个什么操作？） } } // Instrumentation methods for conditions // condition的检测方法 /** * Queries whether the given ConditionObject * uses this synchronizer as its lock. * 查询给定的ConditionObject是否用该同步器作为它的锁 * * @param condition the condition * @return {@code true} if owned * @throws NullPointerException if the condition is null */ public final boolean owns(ConditionObject condition) { return condition.isOwnedBy(this); } /** * Queries whether any threads are waiting on the given condition * associated with this synchronizer. Note that because timeouts * and interrupts may occur at any time, a {@code true} return * does not guarantee that a future {@code signal} will awaken * any threads. This method is designed primarily for use in * monitoring of the system state. * 查询是否有线程在给定的condition关联的同步器上等待。 * 注意，由于超时和中断可能在任意时刻发生，返回结果true不保证未来signal可以唤醒线程。 * 该方法设计的意图是为了在监控系统中使用。 * * @param condition the condition * @return {@code true} if there are any waiting threads * @throws IllegalMonitorStateException if exclusive synchronization * is not held * @throws IllegalArgumentException if the given condition is * not associated with this synchronizer * @throws NullPointerException if the condition is null */ public final boolean hasWaiters(ConditionObject condition) { if (!owns(condition)) // 如果condition没有关联到本AbstractQueuedSynchronizer（sync) throw new IllegalArgumentException(\"Not owner\"); return condition.hasWaiters(); // 如果有在CONDITION上等待条件的，返回true } /** * Returns an estimate of the number of threads waiting on the * given condition associated with this synchronizer. Note that * because timeouts and interrupts may occur at any time, the * estimate serves only as an upper bound on the actual number of * waiters. This method is designed for use in monitoring of the * system state, not for synchronization control. * 返回预估的在给定的condition关联的同步器上等待的线程数。 * 注意，由于超时与中断可能在任意时刻发生，预估的服务数是实际服务数的上限。 * 该方法只是设计用作监控系统的，不是为了同步控制。 * * @param condition the condition * @return the estimated number of waiting threads * @throws IllegalMonitorStateException if exclusive synchronization * is not held * @throws IllegalArgumentException if the given condition is * not associated with this synchronizer * @throws NullPointerException if the condition is null */ public final int getWaitQueueLength(ConditionObject condition) { if (!owns(condition)) throw new IllegalArgumentException(\"Not owner\"); return condition.getWaitQueueLength(); } /** * Returns a collection containing those threads that may be * waiting on the given condition associated with this * synchronizer. Because the actual set of threads may change * dynamically while constructing this result, the returned * collection is only a best-effort estimate. The elements of the * returned collection are in no particular order. * 返回包含可能在给定condition关联的同步器上等待的线程集合。 * 由于在结构化生成结果过程中，实际上线程是动态变化的，这个返回结果稽核只是一个尽力预估值。 * 返回的稽核元素没有特定的顺序。 * * @param condition the condition * @return the collection of threads * @throws IllegalMonitorStateException if exclusive synchronization * is not held * @throws IllegalArgumentException if the given condition is * not associated with this synchronizer * @throws NullPointerException if the condition is null */ public final Collection getWaitingThreads(ConditionObject condition) { if (!owns(condition)) throw new IllegalArgumentException(\"Not owner\"); return condition.getWaitingThreads(); } /** * Condition implementation for a {@link * AbstractQueuedSynchronizer} serving as the basis of a {@link * Lock} implementation. * 作为AQS服务的条件实现，作为Lock实现的基础。 * * Method documentation for this class describes mechanics, * not behavioral specifications from the point of view of Lock * and Condition users. Exported versions of this class will in * general need to be accompanied by documentation describing * condition semantics that rely on those of the associated * {@code AbstractQueuedSynchronizer}. * 该类的方法说明从使用者的角度描述Lock与Condition的机制，而不是行为规范。 * 该类的导出版本通常需要跟依赖关联的AQS的条件语义文档一起看。 * * This class is Serializable, but all fields are transient, * so deserialized conditions have no waiters. * class是可序列化的，不过所有的字段都是transient（暂时的），所以反序列化的condition没有任何waiter。 * */ public class ConditionObject implements Condition, java.io.Serializable { private static final long serialVersionUID = 1173984872572414699L; // 用来验证版本一致性。根据包名，类名，继承关系，非私有的方法和属性，以及参数，返回值等诸多因子计算得出的，极度复杂生成的一个64位的哈希字段。基本上计算出来的这个值是唯一的。默认是1L。 /** First node of condition queue. */ private transient Node firstWaiter; // firstWaiter是个Node类型，具有prev、next、thread等属性，还有nextWaiter这种属性 /** Last node of condition queue. */ private transient Node lastWaiter; // lastWaiter是个Node类型 /** * Creates a new {@code ConditionObject} instance. */ public ConditionObject() { } // Internal methods // 内部方法 /** * Adds a new waiter to wait queue. * @return its new wait node */ private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clean out. // 如果最后一个节点取消了，清理掉。 if (t != null && t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); // 从头开始进行完整遍历，留下ws=CONDITION的节点 t = lastWaiter; // unlink会更新lastWaiter，重新指向lastWaiter } Node node = new Node(Thread.currentThread(), Node.CONDITION); // 封装当前线程为Node，默认ws为CONDITION if (t == null) // 没有lastWaiter，说明当前condition队列为空，让firstWaiter指向该节点 firstWaiter = node; else t.nextWaiter = node; // 否则让当前lastWaiter的next指向该节点 lastWaiter = node; // 设置当前节点为lastWaiter return node; } /** * Removes and transfers nodes until hit non-cancelled one or * null. Split out from signal in part to encourage compilers * to inline the case of no waiters. * 转移和移除节点，直到命中未取消的节点或者遍历完没有非null节点。 * 从signal中分离出来，一部分是为了鼓励编译器内联没有waiters的情况。 * * @param first (non-null) the first node on condition queue */ private void doSignal(Node first) { // 目标就是将firstWaiter节点转移到sync队列里，然后移除该节点。first为非空的firstWaiter。（如果是null，会导致transferForSignal(first)报错） do { if ( (firstWaiter = first.nextWaiter) == null) // 1、让firstWaiter指向firstWaiter的下一个节点 lastWaiter = null; // 2、如果下一个节点为空，说明condition队列里没有等待节点了，lastWaiter也置为空 first.nextWaiter = null; // 3、断开即将移入sync队列的节点next引用 } while (!transferForSignal(first) && // 4、如果该节点状态非CONDITION，表示该节点已CANCEL，返回false，表示无法入队，否则将该节点enq入队，如果入队失败，会unpark该节点直接竞争锁 (first = firstWaiter) != null); // 5、让first指向firstWaiter，如果现在第一个节点不为null，并且上一个节点已经被取消了，那么尝试释放下一个节点。 } /** * Removes and transfers all nodes. * 转移和移除所有节点 * * @param first (non-null) the first node on condition queue */ private void doSignalAll(Node first) { lastWaiter = firstWaiter = null; // 反正都要移除了，啥也不管直接都置为null do { Node next = first.nextWaiter; // 遍历非null的节点，有一个算一个，都给扔到transferForSignal(first)方法中去转移到sync队列里，然后移除。 first.nextWaiter = null; transferForSignal(first); first = next; } while (first != null); } /** * Unlinks cancelled waiter nodes from condition queue. * Called only while holding lock. This is called when * cancellation occurred during condition wait, and upon * insertion of a new waiter when lastWaiter is seen to have * been cancelled. This method is needed to avoid garbage * retention in the absence of signals. So even though it may * require a full traversal, it comes into play only when * timeouts or cancellations occur in the absence of * signals. It traverses all nodes rather than stopping at a * particular target to unlink all pointers to garbage nodes * without requiring many re-traversals during cancellation * storms. * 从条件队列中取消连接的cancel waiter节点。 * 只有在持有锁的时候才会被调用。 * 当在条件等待时发生取消，在插入新的waiter时发现最后的waiter已经被取消时，会调用到该方法。（发现最后一个被取消时会调用，遍历则是从头开始向后遍历） * 需要该方法在没有信号（absence 缺席）的情况下避免垃圾保留。 * 因此，即使它可能需要全部遍历，它也仅在没有信号的情况下发生超时或者取消时才起作用。 * 它遍历所有节点而不是在特定节点处停止，以取消所有指向垃圾节点的指针，而不需要在取消风暴中多次重新遍历。 * */ private void unlinkCancelledWaiters() { Node t = firstWaiter; // 从第一个节点开始向后遍历 Node trail = null; // trail保留最后一个未取消的节点引用（每当发现一个后续未取消节点，这个trail就变为指向该节点） while (t != null) { Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) { // 如果当前节点的ws不是CONDITION，说明当前节点不再等待了（就是取消了），需要取消连接 t.nextWaiter = null; // 断开该节点与下一个节点的关联， if (trail == null) // 如果现在剩余节点link为空，说明现在还没有节点留下来 firstWaiter = next; // 把第一个留下来的节点作为firstWaiter else trail.nextWaiter = next; // 否则就把当前节点（准备清理的节点）的下一个节点加入到剩余节点link中（通过trail保留截止到目前最后一个节点的引用，使用next来构建link） if (next == null) // 如果没有后续waiter了 lastWaiter = trail; // lastWaiter指向剩余节点link的最后一个节点 } else trail = t; // 当前节点不用取消，link没变化，直接让trail指向当前未取消的节点，继续向后遍历 t = next; // 准备下一个节点的遍历 } } // public methods // 公共方法 /** * Moves the longest-waiting thread, if one exists, from the * wait queue for this condition to the wait queue for the * owning lock. * 如果有等待线程的话，将等待时间最长的线程从等待condition的队列转移到等待lock的队列 * * @throws IllegalMonitorStateException if {@link #isHeldExclusively} * returns {@code false} */ public final void signal() { if (!isHeldExclusively()) // 首先要当前线程得持有锁（自己实现的方法返回true） throw new IllegalMonitorStateException(); Node first = firstWaiter; // 排在第一个的线程节点，就是等待时间最长的（因为先来先入队先等待） if (first != null) // 如果上来就是null，就不转移了 doSignal(first); } /** * Moves all threads from the wait queue for this condition to * the wait queue for the owning lock. * 把所有的线程Node从等待condition的队列转移到等待lock的队列。 * * @throws IllegalMonitorStateException if {@link #isHeldExclusively} * returns {@code false} */ public final void signalAll() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first); } /** * Implements uninterruptible condition wait. * 实现非中断的condition等待 * * * Save lock state returned by {@link #getState}. * Invoke {@link #release} with saved state as argument, * throwing IllegalMonitorStateException if it fails. * Block until signalled. * Reacquire by invoking specialized version of * {@link #acquire} with saved state as argument. * */ public final void awaitUninterruptibly() { Node node = addConditionWaiter(); // 将当前线程封装成Node添加到等待condition队列中 int savedState = fullyRelease(node); // 这里为什么要去释放呢？释放不成功还会直接cancel 这里结合场景说一下，如果当前线程想要在condition上做await操作，那么它一定是已经获取到锁了，这是第一。第二，已获取到锁的线程需要await，那么它一定要释放锁，把资源交出去，直到它被唤醒进行竞争。 boolean interrupted = false; while (!isOnSyncQueue(node)) { // 判断当前node是否已在sync队列里（就是等待lock的队列），如果没有的话，就自己阻塞了 LockSupport.park(this); if (Thread.interrupted()) // 即使有中断，也只是记录状态，不响应 interrupted = true; } if (acquireQueued(node, savedState) || interrupted) // 能到这里，说明已经在sync队列里了，尝试获取锁，获取失败也阻塞。如果在加入sync队列时发生了中断，或者在sync获取锁的时候发生中断，都会重新中断。 selfInterrupt(); } /* * For interruptible waits, we need to track whether to throw * InterruptedException, if interrupted while blocked on * condition, versus reinterrupt current thread, if * interrupted while blocked waiting to re-acquire. * 对于可中断的waits，需要跟踪是否抛出InterruptedException， * 如果在condition阻塞过程中发生中断， * 相对的重新中断当前线程 * 如果在等待重新获取的阻塞时发生中断 */ /** Mode meaning to reinterrupt on exit from wait */ // 在退出时重新中断 private static final int REINTERRUPT = 1; /** Mode meaning to throw InterruptedException on exit from wait */ // 在退出时抛出中断异常 private static final int THROW_IE = -1; /** * Checks for interrupt, returning THROW_IE if interrupted * before signalled, REINTERRUPT if after signalled, or * 0 if not interrupted. * 检查中断 * 如果在获取到signal之前发生中断，返回THROW_IE * 如果在获取到signal之后发生中断，返回REINTERRUPT * 没有中断发生，返回0 */ private int checkInterruptWhileWaiting(Node node) { return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : // transferAfterCancelledWait如果能成功将ws从CONDITION更新成0，会尝试将node加入到sync队列，返回true表示被signal之前被cancel 0; } /** * Throws InterruptedException, reinterrupts current thread, or * does nothing, depending on mode. * 根据模式，抛出中断异常，或者重新中断当前线程，或者啥也不做 * */ private void reportInterruptAfterWait(int interruptMode) throws InterruptedException { if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); } /** * Implements interruptible condition wait. * 实现可中断condition等待 * * * If current thread is interrupted, throw InterruptedException. * Save lock state returned by {@link #getState}. * Invoke {@link #release} with saved state as argument, * throwing IllegalMonitorStateException if it fails. * Block until signalled or interrupted. * Reacquire by invoking specialized version of * {@link #acquire} with saved state as argument. * If interrupted while blocked in step 4, throw InterruptedException. * 1、如果当前线程被中断，抛出异常。 * 2、保存由getState返回的锁的state值。 * 3、调用release方法，将保存的state值作为参数，如果release失败，抛出IllegalMonitorStateException异常。（说明该线程的操作非法，类似于Ojbect上的wait与notify） * 4、阻塞，直到被唤醒或者被中断 * 5、通过使用保存的state值，调用特殊版本的acquire方法，来重新获取。 * 6、如果在第4步阻塞时被中断，抛出中断异常。 * * */ public final void await() throws InterruptedException { if (Thread.interrupted()) // 0、上来先看中断状态，如果已经中断了，直接抛出异常。 throw new InterruptedException(); Node node = addConditionWaiter(); // 1、将当前线程加入到Condition队列中。与不可中断的await一样 int savedState = fullyRelease(node); // 2、当前线程放弃对锁的竞争，释放资源唤醒后继进行锁获取 int interruptMode = 0; // while (!isOnSyncQueue(node)) { // 3、判断当前线程node是否在sync队列里 LockSupport.park(this); // 4、如果不在sync队列，说明没有满足的Condition，进行park if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) // 5、检查在wait时发生的中断，如果没有中断，返回0，当返回值!=0时，跳出循环等待 break; } if (acquireQueued(node, savedState) && interruptMode != THROW_IE) // 6、调用不可中断的acquireQueued方法竞争，竞争成功返回中断状态。如果竞争时发生中断，并且中断模式为THROW_IE（在获取到信号之前就被中断了） interruptMode = REINTERRUPT; // 7、中断模式改为REINTERRUPT（在获取信号之后被中断） if (node.nextWaiter != null) // clean up if cancelled // 8、如果当前节点的nextWaiter不为null，从CONDITION队列的firstWaiter开始清理一遍非CONDITION状态的节点 unlinkCancelledWaiters(); if (interruptMode != 0) // 9、如果中断模式不是0（意味着发生过中断），按照中断模式，调用reportInterruptAfterWait方法抛出异常或者恢复中断状态（就是重新将中断标识位置为中断） reportInterruptAfterWait(interruptMode); } /** * Implements timed condition wait. * 实现超时condition等待 * * If current thread is interrupted, throw InterruptedException. * Save lock state returned by {@link #getState}. * Invoke {@link #release} with saved state as argument, * throwing IllegalMonitorStateException if it fails. * Block until signalled, interrupted, or timed out. * Reacquire by invoking specialized version of * {@link #acquire} with saved state as argument. * If interrupted while blocked in step 4, throw InterruptedException. * 1、如果当前线程被中断，抛出InterruptedException。 * 2、保存getState方法返回的state值。 * 3、调用release方法，使用保存的state值作为参数。如果调用失败，抛出IllegalMonitorStateException。 * 4、阻塞，直到被唤醒，或者被中断，或者超时。 * 5、通过带着保存的state值调用特殊版本的acquire方法，来重新获取。 * 6、如果在步骤4阻塞时被中断，抛出中断异常。 * * */ public final long awaitNanos(long nanosTimeout) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) { if (nanosTimeout = spinForTimeoutThreshold) // 如果剩余的超时时间比自旋的等待时间阈值高，那么直接park LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) // 检查是否发生过中断，如果有，跳出循环 break; nanosTimeout = deadline - System.nanoTime(); } if (acquireQueued(node, savedState) && interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime(); // 返回剩余的等待纳秒数 } /** * Implements absolute timed condition wait. * 实现绝对定时condition等待。 * * If current thread is interrupted, throw InterruptedException. * Save lock state returned by {@link #getState}. * Invoke {@link #release} with saved state as argument, * throwing IllegalMonitorStateException if it fails. * Block until signalled, interrupted, or timed out. * Reacquire by invoking specialized version of * {@link #acquire} with saved state as argument. * If interrupted while blocked in step 4, throw InterruptedException. * If timed out while blocked in step 4, return false, else true. * 1、如果当前线程被中断，抛出InterruptedException。 * 2、保存getState方法返回的state值。 * 3、调用release方法，使用保存的state值作为参数。如果调用失败，抛出IllegalMonitorStateException。 * 4、阻塞，直到被唤醒，或者被中断，或者超时。 * 5、通过带着保存的state值调用特殊版本的acquire方法，来重新获取。 * 6、如果在步骤4阻塞时被中断，抛出中断异常。 * 7、如果在步骤4超时了，返回false，否则返回true。 * */ public final boolean awaitUntil(Date deadline) throws InterruptedException { long abstime = deadline.getTime(); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) { if (System.currentTimeMillis() > abstime) { timedout = transferAfterCancelledWait(node); // transferAfterCancelledWait如果在信号之前取消了wait，返回true（超时了返回true） break; } LockSupport.parkUntil(this, abstime); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } if (acquireQueued(node, savedState) && interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; // 超时了返回false，否则返回true } /** * Implements timed condition wait. * 实现超时condition等待 * * If current thread is interrupted, throw InterruptedException. * Save lock state returned by {@link #getState}. * Invoke {@link #release} with saved state as argument, * throwing IllegalMonitorStateException if it fails. * Block until signalled, interrupted, or timed out. * Reacquire by invoking specialized version of * {@link #acquire} with saved state as argument. * If interrupted while blocked in step 4, throw InterruptedException. * If timed out while blocked in step 4, return false, else true. * 1、如果当前线程被中断，抛出InterruptedException。 * 2、保存getState方法返回的state值。 * 3、调用release方法，使用保存的state值作为参数。如果调用失败，抛出IllegalMonitorStateException。 * 4、阻塞，直到被唤醒，或者被中断，或者超时。 * 5、通过带着保存的state值调用特殊版本的acquire方法，来重新获取。 * 6、如果在步骤4阻塞时被中断，抛出中断异常。 * 7、如果在步骤4超时了，返回false，否则返回true。 * */ public final boolean await(long time, TimeUnit unit) throws InterruptedException { long nanosTimeout = unit.toNanos(time); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) { if (nanosTimeout = spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); } if (acquireQueued(node, savedState) && interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; } // support for instrumentation /** * Returns true if this condition was created by the given * synchronization object. * 如果该condition是通过给定的同步器创建的，返回true * * @return {@code true} if owned */ final boolean isOwnedBy(AbstractQueuedSynchronizer sync) { return sync == AbstractQueuedSynchronizer.this; } /** * Queries whether any threads are waiting on this condition. * Implements {@link AbstractQueuedSynchronizer#hasWaiters(ConditionObject)}. * 查询是否在该condition上有线程在等待。 * * @return {@code true} if there are any waiting threads * @throws IllegalMonitorStateException if {@link #isHeldExclusively} * returns {@code false} */ protected final boolean hasWaiters() { if (!isHeldExclusively()) // 如果当前线程没有独占锁，抛出异常，这个方法是需要独占锁自己实现的三个方法之一。 throw new IllegalMonitorStateException(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) { // 从第一个等待节点开始找，如果有waitStatus是CONDITION的，表示在等待条件，返回true if (w.waitStatus == Node.CONDITION) // （在CONDITION队列上的，ws只有CONDITION跟CANCEL状态么？） return true; } return false; } /** * Returns an estimate of the number of threads waiting on * this condition. * Implements {@link AbstractQueuedSynchronizer#getWaitQueueLength(ConditionObject)}. * 返回预估的在该condition上等待的线程数 * AbstractQueuedSynchronizer的getWaitQueueLength(ConditionObject)方法会调用 * * @return the estimated number of waiting threads * @throws IllegalMonitorStateException if {@link #isHeldExclusively} * returns {@code false} */ protected final int getWaitQueueLength() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int n = 0; for (Node w = firstWaiter; w != null; w = w.nextWaiter) { if (w.waitStatus == Node.CONDITION) ++n; } return n; } /** * Returns a collection containing those threads that may be * waiting on this Condition. * Implements {@link AbstractQueuedSynchronizer#getWaitingThreads(ConditionObject)}. * 返回包含可能在该Condition上等待的线程集合。 * * @return the collection of threads * @throws IllegalMonitorStateException if {@link #isHeldExclusively} * returns {@code false} */ protected final Collection getWaitingThreads() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); ArrayList list = new ArrayList(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) { if (w.waitStatus == Node.CONDITION) { Thread t = w.thread; if (t != null) list.add(t); } } return list; } } /** * Setup to support compareAndSet. We need to natively implement * this here: For the sake of permitting future enhancements, we * cannot explicitly subclass AtomicInteger, which would be * efficient and useful otherwise. So, as the lesser of evils, we * natively implement using hotspot intrinsics API. And while we * are at it, we do the same for other CASable fields (which could * otherwise be done with atomic field updaters). * 设置以支持CAS。 * 需要在这里进行本地实现： * 为了允许未来增强，我们不能显式集成AtomicInteger类，否则就是有效和有用的。（如果不是为了增强，就可以用AtomicXXX操作了） * 所以，作为较小的弊端，本地实现使用hotspot内在函数API。 * 当我们这样做时，对其他可以使用CAS字段也这样做（否则可以使用原子字段更新程序来完成） */ private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long stateOffset; private static final long headOffset; private static final long tailOffset; private static final long waitStatusOffset; private static final long nextOffset; static { try { stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"state\")); headOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"head\")); tailOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(\"tail\")); waitStatusOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(\"waitStatus\")); nextOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(\"next\")); } catch (Exception ex) { throw new Error(ex); } } /** * CAS head field. Used only by enq. */ private final boolean compareAndSetHead(Node update) { return unsafe.compareAndSwapObject(this, headOffset, null, update); } /** * CAS tail field. Used only by enq. */ private final boolean compareAndSetTail(Node expect, Node update) { return unsafe.compareAndSwapObject(this, tailOffset, expect, update); } /** * CAS waitStatus field of a node. */ private static final boolean compareAndSetWaitStatus(Node node, int expect, int update) { return unsafe.compareAndSwapInt(node, waitStatusOffset, expect, update); } /** * CAS next field of a node. */ private static final boolean compareAndSetNext(Node node, Node expect, Node update) { return unsafe.compareAndSwapObject(node, nextOffset, expect, update); } } "},"Doc/util/concurrent/locks/Condition.java.html":{"url":"Doc/util/concurrent/locks/Condition.java.html","title":"Condition.Java","keywords":"","body":"Condition /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent.locks; import java.util.concurrent.TimeUnit; import java.util.Date; /** * {@code Condition} factors out the {@code Object} monitor * methods ({@link Object#wait() wait}, {@link Object#notify notify} * and {@link Object#notifyAll notifyAll}) into distinct objects to * give the effect of having multiple wait-sets per object, by * combining them with the use of arbitrary {@link Lock} implementations. * Where a {@code Lock} replaces the use of {@code synchronized} methods * and statements, a {@code Condition} replaces the use of the Object * monitor methods. * Condition将Object监视器方法（wait、notify、notifyAll）分解到不同的对象，通过将他们与使用任意的Lock实现进行组合，以产生每个对象具有多个等待集的效果。 *在使用Lock替换synchronized使用的地方，用Condition替换Object监视器使用（Lock与Condition配对，synchronized与ObjectMonitor配对（就是Object.wait/notify那一套）） * * Conditions (also known as condition queues or * condition variables) provide a means for one thread to * suspend execution (to &quot;wait&quot;) until notified by another * thread that some state condition may now be true. Because access * to this shared state information occurs in different threads, it * must be protected, so a lock of some form is associated with the * condition. The key property that waiting for a condition provides * is that it atomically releases the associated lock and * suspends the current thread, just like {@code Object.wait}. * Conditions（也叫条件队列或者条件变量）提供了一种一个线程暂停执行（等待）直到一些状态条件可能为true时被另一个线程唤醒的能力。 * 因为访问共享变量信息发生在不同的线程，它必须受保护，所以需要某种形式的锁与条件相关联。 * 等待条件提供的关键属性是原子地释放关联的锁并且暂停当前线程，就像Object.wait一样。 * * A {@code Condition} instance is intrinsically bound to a lock. * To obtain a {@code Condition} instance for a particular {@link Lock} * instance use its {@link Lock#newCondition newCondition()} method. * Condition实例本质上（intrinsically）绑定到了一个锁。 * 获取（obtain）特定Lock实例的Condition实例使用Lock的newCondition()方法。 * * As an example, suppose we have a bounded buffer which supports * {@code put} and {@code take} methods. If a * {@code take} is attempted on an empty buffer, then the thread will block * until an item becomes available; if a {@code put} is attempted on a * full buffer, then the thread will block until a space becomes available. * We would like to keep waiting {@code put} threads and {@code take} * threads in separate wait-sets so that we can use the optimization of * only notifying a single thread at a time when items or spaces become * available in the buffer. This can be achieved using two * {@link Condition} instances. * 举例来说，假设我们有一个有界的buffer，支持put和take方法。 * 如果有线程对空buffer尝试take，当前线程会阻塞直到有东西变得可用（就是buffer里有东西） * 如果有线程对满buffer尝试put，当前线程会阻塞直到有空地方可用 * 我们希望将等待的多个put线程与多个take线程保持在独立的等待集，这样我们就可以优化（optimization）成当buffer里有东西或者有空间可用时，每次只唤醒一个线程。 * 可以通过使用两个Condition实例来实现 * * * class BoundedBuffer { * final Lock lock = new ReentrantLock(); // 等下再返回看ReentrantLock实现 * final Condition notFull = lock.newCondition(); // 同一个lock创建两个Condition实例 * final Condition notEmpty = lock.newCondition(); * * final Object[] items = new Object[100]; * int putptr, takeptr, count; * * public void put(Object x) throws InterruptedException { * lock.lock(); * try { * // 注意这里的while循环，特别有用，因为线程被唤醒后，可能仍然没有满足的条件（比如条件被别的线程抢了），这时候就得重新进入挂起-唤醒的循环 * //（这其实就是虚假唤醒的语义，下面会解释） * while (count == items.length) * notFull.await(); // 挂起，并释放锁 * items[putptr] = x; * if (++putptr == items.length) putptr = 0; * ++count; * notEmpty.signal(); // buffer里有东西了，唤醒一个挂起的take * } finally { * lock.unlock(); // 记得释放锁 * } * } * * public Object take() throws InterruptedException { * lock.lock(); * try { * while (count == 0) * notEmpty.await(); * Object x = items[takeptr]; * if (++takeptr == items.length) takeptr = 0; * --count; * notFull.signal(); * return x; * } finally { * lock.unlock(); * } * } * } * * * (The {@link java.util.concurrent.ArrayBlockingQueue} class provides * this functionality, so there is no reason to implement this * sample usage class.) * ArrayBlockingQueue类提供了这些方法，所有没有必要去实现这个相同用处的类 * * A {@code Condition} implementation can provide behavior and semantics * that is * different from that of the {@code Object} monitor methods, such as * guaranteed ordering for notifications, or not requiring a lock to be held * when performing notifications. * If an implementation provides such specialized semantics then the * implementation must document those semantics. * Condition的实现可以提供与Object监视器不同的行为与语义，例如保证通知顺序，或者执行通知时不要求持有锁。 * 如果实现提供这些专门的语义，那么实现必须记录下来。 * * Note that {@code Condition} instances are just normal objects and can * themselves be used as the target in a {@code synchronized} statement, * and can have their own monitor {@link Object#wait wait} and * {@link Object#notify notification} methods invoked. * Acquiring the monitor lock of a {@code Condition} instance, or using its * monitor methods, has no specified relationship with acquiring the * {@link Lock} associated with that {@code Condition} or the use of its * {@linkplain #await waiting} and {@linkplain #signal signalling} methods. * It is recommended that to avoid confusion you never use {@code Condition} * instances in this way, except perhaps within their own implementation. * 注意，Condition的实例就是普通的object，并且他自身可以用于synchronized statement，并且也拥有自己的监视器wait和notify方法调用。 * 获取Condition实例的监视器锁，或者使用它的监视器方法，跟获取该实例关联的Lock，或者使用await、signal方法没有任何特定的关系。 * 为了避免混淆，建议不要以这种方式使用Condition的实例，除非在他们自己的实现中 * （跟Lock的建议一样） * * Except where noted, passing a {@code null} value for any parameter * will result in a {@link NullPointerException} being thrown. * 除非另有说明，传参时传个null会抛出NullPointerException异常。 * * Implementation Considerations * 注意事项 * When waiting upon a {@code Condition}, a &quot;spurious * wakeup&quot; is permitted to occur, in * general, as a concession to the underlying platform semantics. * This has little practical impact on most application programs as a * {@code Condition} should always be waited upon in a loop, testing * the state predicate that is being waited for. An implementation is * free to remove the possibility of spurious wakeups but it is * recommended that applications programmers always assume that they can * occur and so always wait in a loop. * 当等待Condition时（就是调用await后等待唤醒时），允许虚假唤醒（spurious wakeup）发生，通常，作为对底层平台语义的让步（concession）。 * 这对大多数应用几乎没有实际影响，因为应用始终在循环中等待Condition，在循环中检测等待的状态谓词。 * 实现可以自由的消除虚假唤醒的可能性，不过建议应用程序员始终假设他们可能发生，并且始终在循环中等待（与检测）。 * * The three forms of condition waiting * (interruptible, non-interruptible, and timed) may differ in their ease of * implementation on some platforms and in their performance characteristics. * In particular, it may be difficult to provide these features and maintain * specific semantics such as ordering guarantees. * Further, the ability to interrupt the actual suspension of the thread may * not always be feasible to implement on all platforms. * 条件等待的三种形式（可中断、不可中断、定时）在某些平台上实现的难易程度和性能特征方面可能有所不同。 * 特别是，可能很难提供这些功能并维护特定的语义，例如排序保证。 * 此外，在所有平台上实现中断线程实际挂起的能力并不总是可行。 * * Consequently, an implementation is not required to define exactly the * same guarantees or semantics for all three forms of waiting, nor is it * required to support interruption of the actual suspension of the thread. * 因此，不需要一个实现针对这三种形式定义完全（exactly 确切）相同的保证或者语义，也不需要支持中断线程实际挂起的。 * * An implementation is required to * clearly document the semantics and guarantees provided by each of the * waiting methods, and when an implementation does support interruption of * thread suspension then it must obey the interruption semantics as defined * in this interface. * 要求实现明确记录下每个等待方法提供的语义和保证，并且当实现支持中断线程挂起，那么它必须遵循这个接口中定义的中断语义 * * As interruption generally implies cancellation, and checks for * interruption are often infrequent, an implementation can favor responding * to an interrupt over normal method return. This is true even if it can be * shown that the interrupt occurred after another action that may have * unblocked the thread. An implementation should document this behavior. * 中断通常意味着（implies）取消，并且中断检查通常很少发生，因此实现类可以偏向于响应中断而不是正常的方法返回。 * 即使可以证明 中断发生在 另一个动作已经解除了本线程阻塞之后，也是如此。实现类中应该记录下该行为 * * @since 1.5 * @author Doug Lea */ public interface Condition { /** * Causes the current thread to wait until it is signalled or * {@linkplain Thread#interrupt interrupted}. * 使当前线程等待，直到收到信号或者被中断 * * The lock associated with this {@code Condition} is atomically * released and the current thread becomes disabled for thread scheduling * purposes and lies dormant until one of four things happens: * 原子操作释放Condition关联的锁，当前线程转变为不可用的线程调度目标，并且挂起，直到以下四种情况之一发生： * * * Some other thread invokes the {@link #signal} method for this * {@code Condition} and the current thread happens to be chosen as the * thread to be awakened; or * Some other thread invokes the {@link #signalAll} method for this * {@code Condition}; or * Some other thread {@linkplain Thread#interrupt interrupts} the * current thread, and interruption of thread suspension is supported; or * A &quot;spurious wakeup&quot; occurs. * * 1.其他一些线程调用了这个Condition的signal方法，并且当前线程被选中为唤醒线程 * 2.其他一些线程调用了这个Condition的signalAll方法 * 3.其他一些线程中断当前线程，并且当前线程支持中断线程挂起 * 4.发生虚假唤醒 * * In all cases, before this method can return the current thread must * re-acquire the lock associated with this condition. When the * thread returns it is guaranteed to hold this lock. * 在所有情况下，在此方法可以返回到当前线程（继续执行）之前，当前线程必须重新获取到这个condition关联的锁。 * 当线程返回时，它保证持有这个锁 * * If the current thread: * * has its interrupted status set on entry to this method; or * is {@linkplain Thread#interrupt interrupted} while waiting * and interruption of thread suspension is supported, * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. It is not specified, in the first * case, whether or not the test for interruption occurs before the lock * is released. * 如果当前线程： * 1. 在进入该方法时设置了中断状态 * 2. 或者在等待时被中断，并且当前线程支持中断挂起 * 那么会抛出InterruptedException异常并且清理当前线程的中断状态。 * 对于第一种情况，没有规定要检测在中断发生前锁是否被释放。 * * Implementation Considerations * 注意事项 * The current thread is assumed to hold the lock associated with this * {@code Condition} when this method is called. * It is up to the implementation to determine if this is * the case and if not, how to respond. Typically, an exception will be * thrown (such as {@link IllegalMonitorStateException}) and the * implementation must document that fact. * 在调用此方法时，假定当前线程拥有该Condition关联的锁。 * 由实现去决定如果不满足上述假设时该如何响应。 * 通常会抛出IllegalMonitorStateException异常，并且实现必须记录下该事实（写明处理规则） * * An implementation can favor responding to an interrupt over normal * method return in response to a signal. In that case the implementation * must ensure that the signal is redirected to another waiting thread, if * there is one. * 实现响应信号时可以倾向于响应中断而不是正常方法返回。 * 实现必须确保信号量被重定向到另一个等待线程，如果还有等待线程的话。（就是如果当前线程唤醒失败，需要把唤醒信号量传递给其他等待线程） * * @throws InterruptedException if the current thread is interrupted * (and interruption of thread suspension is supported) */ void await() throws InterruptedException; /** * Causes the current thread to wait until it is signalled. * (这些都与await()方法一样） * The lock associated with this condition is atomically * released and the current thread becomes disabled for thread scheduling * purposes and lies dormant until one of three things happens: * * Some other thread invokes the {@link #signal} method for this * {@code Condition} and the current thread happens to be chosen as the * thread to be awakened; or * Some other thread invokes the {@link #signalAll} method for this * {@code Condition}; or * A &quot;spurious wakeup&quot; occurs. * * 这里少了一种打断wait的方法，那就是少了中断 * * In all cases, before this method can return the current thread must * re-acquire the lock associated with this condition. When the * thread returns it is guaranteed to hold this lock. * * If the current thread's interrupted status is set when it enters * this method, or it is {@linkplain Thread#interrupt interrupted} * while waiting, it will continue to wait until signalled. When it finally * returns from this method its interrupted status will still * be set. * 注意这里是不一样的： * 如果当前线程在进入方法之前被设置了中断，或者在等待时被中断，它将仍然处于等待状态直到收到唤醒信号。 * 当它最终返回的时候，它的中断状态仍旧被设置。（不是清除中断状态） * 所以，它不会抛出异常 * * Implementation Considerations * * The current thread is assumed to hold the lock associated with this * {@code Condition} when this method is called. * It is up to the implementation to determine if this is * the case and if not, how to respond. Typically, an exception will be * thrown (such as {@link IllegalMonitorStateException}) and the * implementation must document that fact. */ void awaitUninterruptibly(); /** * Causes the current thread to wait until it is signalled or interrupted, * or the specified waiting time elapses. * 当前线程等待直到收到唤醒信号或者被中断，或者是指定的等待时间超时。 * * The lock associated with this condition is atomically * released and the current thread becomes disabled for thread scheduling * purposes and lies dormant until one of five things happens: * * Some other thread invokes the {@link #signal} method for this * {@code Condition} and the current thread happens to be chosen as the * thread to be awakened; or * Some other thread invokes the {@link #signalAll} method for this * {@code Condition}; or * Some other thread {@linkplain Thread#interrupt interrupts} the * current thread, and interruption of thread suspension is supported; or * The specified waiting time elapses; or * A &quot;spurious wakeup&quot; occurs. * * 这里有五种方法可以打断线程的挂起： * 1. signal并且当前线程被选中 * 2. signalAll * 3. interrupted * 4. 等待超时（相较await()，多了个这个） * 5. 虚假唤醒 * * In all cases, before this method can return the current thread must * re-acquire the lock associated with this condition. When the * thread returns it is guaranteed to hold this lock. * * If the current thread: * * has its interrupted status set on entry to this method; or * is {@linkplain Thread#interrupt interrupted} while waiting * and interruption of thread suspension is supported, * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. It is not specified, in the first * case, whether or not the test for interruption occurs before the lock * is released. * * The method returns an estimate of the number of nanoseconds * remaining to wait given the supplied {@code nanosTimeout} * value upon return, or a value less than or equal to zero if it * timed out. This value can be used to determine whether and how * long to re-wait in cases where the wait returns but an awaited * condition still does not hold. Typical uses of this method take * the following form: * 这个方法返回给定超时纳秒数的剩余纳秒数预估值（就是如果在给定的超时纳秒数之前收到了唤醒信号，就返回剩余的等待时间），如果超时了，返回一个小于等于0的值。 * 传入的超时纳秒数M，线程等待了N秒，返回值为M-N * 这个返回值（剩余等待时间）可以用来确定当等待返回了但是等待条件仍未满足时，是否重新等待与重新等待的时间。 * 此方法的典型用法如下： * * {@code * boolean aMethod(long timeout, TimeUnit unit) { * long nanos = unit.toNanos(timeout); * lock.lock(); * try { * while (!conditionBeingWaitedFor()) { // 判断是否重新等待 * if (nanos * * Design note: This method requires a nanosecond argument so * as to avoid truncation errors in reporting remaining times. * Such precision loss would make it difficult for programmers to * ensure that total waiting times are not systematically shorter * than specified when re-waits occur. * 这个方法要求传入的参数为纳秒值，以避免报告剩余时间时出现截断错误。 * 这种精度损失会导致程序员难以保证在重新等待发生时，总等待时间（系统性的）不短于指定时间。 * 理解上总等待时间要>=指定时间（对应超时时，返回值为Implementation Considerations * * The current thread is assumed to hold the lock associated with this * {@code Condition} when this method is called. * It is up to the implementation to determine if this is * the case and if not, how to respond. Typically, an exception will be * thrown (such as {@link IllegalMonitorStateException}) and the * implementation must document that fact. * * An implementation can favor responding to an interrupt over normal * method return in response to a signal, or over indicating the elapse * of the specified waiting time. In either case the implementation * must ensure that the signal is redirected to another waiting thread, if * there is one. * （记得发生中断后要把唤醒信号重定向到另一个等待线程） * * @param nanosTimeout the maximum time to wait, in nanoseconds * @return an estimate of the {@code nanosTimeout} value minus * the time spent waiting upon return from this method. * A positive value may be used as the argument to a * subsequent call to this method to finish waiting out * the desired time. A value less than or equal to zero * indicates that no time remains. * indicates 表示，remains 剩余 * @throws InterruptedException if the current thread is interrupted * (and interruption of thread suspension is supported) */ long awaitNanos(long nanosTimeout) throws InterruptedException; /** * Causes the current thread to wait until it is signalled or interrupted, * or the specified waiting time elapses. This method is behaviorally * equivalent to: * {@code awaitNanos(unit.toNanos(time)) > 0} * 这个方法等效于awaitNanos(unit.toNanos(time)) > 0，就是如果在等待时间内被唤醒，返回true，等待超时返回false * 这里有个问题，0算等待超时么？可以看具体实现，比如AQS里面的ConditionObject * * @param time the maximum time to wait * @param unit the time unit of the {@code time} argument * @return {@code false} if the waiting time detectably elapsed * before return from the method, else {@code true} // 如果在返回之前可检测到等待时间超时，返回true，否则返回false * @throws InterruptedException if the current thread is interrupted * (and interruption of thread suspension is supported) */ boolean await(long time, TimeUnit unit) throws InterruptedException; /** * Causes the current thread to wait until it is signalled or interrupted, * or the specified deadline elapses. * 当前线程等待直到收到信号、被中断，或者超过指定截止日期。 * * The lock associated with this condition is atomically * released and the current thread becomes disabled for thread scheduling * purposes and lies dormant until one of five things happens: * * Some other thread invokes the {@link #signal} method for this * {@code Condition} and the current thread happens to be chosen as the * thread to be awakened; or * Some other thread invokes the {@link #signalAll} method for this * {@code Condition}; or * Some other thread {@linkplain Thread#interrupt interrupts} the * current thread, and interruption of thread suspension is supported; or * The specified deadline elapses; or * A &quot;spurious wakeup&quot; occurs. * * 有五种方式可以打断线程的挂起： * 1. signal并且当先线程被选中 * 2. signalAll * 3. interrupted * 4. 超过指定的截止日期 * 5. 虚假唤醒 * * In all cases, before this method can return the current thread must * re-acquire the lock associated with this condition. When the * thread returns it is guaranteed to hold this lock. * （源码里多了个空行，不严谨了-.-） * * If the current thread: * * has its interrupted status set on entry to this method; or * is {@linkplain Thread#interrupt interrupted} while waiting * and interruption of thread suspension is supported, * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. It is not specified, in the first * case, whether or not the test for interruption occurs before the lock * is released. * * * The return value indicates whether the deadline has elapsed, * which can be used as follows: * 返回值表示当前方法是否已经超过了截止日期 * * {@code * boolean aMethod(Date deadline) { * boolean stillWaiting = true; * lock.lock(); * try { * while (!conditionBeingWaitedFor()) { * if (!stillWaiting) * return false; * stillWaiting = theCondition.awaitUntil(deadline); // 继续等待到原来的截止日期（awaitNanos是等待到剩余时间） * } * // ... * } finally { * lock.unlock(); * } * }} * * Implementation Considerations * * The current thread is assumed to hold the lock associated with this * {@code Condition} when this method is called. * It is up to the implementation to determine if this is * the case and if not, how to respond. Typically, an exception will be * thrown (such as {@link IllegalMonitorStateException}) and the * implementation must document that fact. * * An implementation can favor responding to an interrupt over normal * method return in response to a signal, or over indicating the passing * of the specified deadline. In either case the implementation * must ensure that the signal is redirected to another waiting thread, if * there is one. * * @param deadline the absolute time to wait until * @return {@code false} if the deadline has elapsed upon return, else // （upon 在...之上） * {@code true} * @throws InterruptedException if the current thread is interrupted * (and interruption of thread suspension is supported) */ boolean awaitUntil(Date deadline) throws InterruptedException; /** * Wakes up one waiting thread. * 唤醒一个等待线程 * * If any threads are waiting on this condition then one * is selected for waking up. That thread must then re-acquire the * lock before returning from {@code await}. * 如果在这个condition下有许多线程在等待，那么会选择一个唤醒。 * 选中的线程必须在await返回之前重新获取锁。 * * Implementation Considerations * * An implementation may (and typically does) require that the * current thread hold the lock associated with this {@code * Condition} when this method is called. Implementations must * document this precondition and any actions taken if the lock is * not held. Typically, an exception such as {@link * IllegalMonitorStateException} will be thrown. * 实现可能（基本是必须）要求调用该方法的线程必须持有该Condition的关联锁，实现必须记录下先决条件和如果没有持有锁下的任何操作。 * 如果没有持有锁就调用，通常会抛出IllegalMonitorStateException（这是个RuntimeException）。 */ void signal(); /** * Wakes up all waiting threads. * 唤醒所有等待线程 * * If any threads are waiting on this condition then they are * all woken up. Each thread must re-acquire the lock before it can * return from {@code await}. * 唤醒所有在这个condition上等待的线程，并且每一个线程在从wait返回前必须重新获取到锁 *（如果是共享锁，所有线程都可以从await转为正式运行，如果是排它锁，就会出现唤醒了一堆，但只有一个会运行，造成部分开销） * * Implementation Considerations * * An implementation may (and typically does) require that the * current thread hold the lock associated with this {@code * Condition} when this method is called. Implementations must * document this precondition and any actions taken if the lock is * not held. Typically, an exception such as {@link * IllegalMonitorStateException} will be thrown. */ void signalAll(); } "},"Doc/util/concurrent/locks/Lock.java.html":{"url":"Doc/util/concurrent/locks/Lock.java.html","title":"Lock.Java","keywords":"","body":"Lock /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent.locks; import java.util.concurrent.TimeUnit; /** * {@code Lock} implementations provide more extensive locking * operations than can be obtained using {@code synchronized} methods * and statements. They allow more flexible structuring, may have * quite different properties, and may support multiple associated * {@link Condition} objects. * 相比使用synchronized的方法和语句获得的锁操作，Lock的实现提供了更广泛的锁操作。 * 它允许更灵活的结构，可能具有完全不同的属性，并且可能支持多个关联Condition对象 * 简单说一下，synchronized methods 指的是 public synchronized getV()这个样子的 * synchronized statements指的是 public getV() { synchronized(this) { ... }} 这个样子的 * * A lock is a tool for controlling access to a shared resource by * multiple threads. Commonly, a lock provides exclusive access to a * shared resource: only one thread at a time can acquire the lock and * all access to the shared resource requires that the lock be * acquired first. However, some locks may allow concurrent access to * a shared resource, such as the read lock of a {@link ReadWriteLock}. * Lock是一个工具，用来在多线程场景下对共享资源访问（访问包含读写）的限制。 * 通常来说，lock提供对共享资源的独占访问：在同一时间只能有一个线程可以获得锁，并且所有对共享资源的访问都必须先获取到锁 * 然而，一些lock（的实现）可能支持并发访问共享资源，例如读锁（ReadWriteLock） * * 下面开始说明synchronized的特性与不足： * The use of {@code synchronized} methods or statements provides * access to the implicit monitor lock associated with every object, but * forces all lock acquisition and release to occur in a block-structured way: * when multiple locks are acquired they must be released in the opposite * order, and all locks must be released in the same lexical scope in which * they were acquired. * 使用synchronized方法或者语句提供对关联对象的隐式监视器锁访问，但是强制所有锁的获取与释放都按块结构（block-structured）方式进行： * 当获取多个锁时，必须按相反的顺序进行释放，并且必须在与获取锁同一个词法范围内释放锁。 * * While the scoping mechanism for {@code synchronized} methods * and statements makes it much easier to program with monitor locks, * and helps avoid many common programming errors involving locks, * there are occasions where you need to work with locks in a more * flexible way. For example, some algorithms for traversing * concurrently accessed data structures require the use of * &quot;hand-over-hand&quot; or &quot;chain locking&quot;: you * acquire the lock of node A, then node B, then release A and acquire * C, then release B and acquire D and so on. Implementations of the * {@code Lock} interface enable the use of such techniques by * allowing a lock to be acquired and released in different scopes, * and allowing multiple locks to be acquired and released in any * order. * 尽管synchronized方法与语句的作用域机制使得使用监视器锁变成变得容易， * 并且可以帮助避免许多涉及到锁的常见编程错误，但在某些情况（occasion）下，需要更灵活的锁方式。 * 例如一些遍历（traverse）并发访问数据结构的算法需要使用交换锁（hand-over-hand）或者链锁（chain locking），向下面这样： * 按这样的顺序操作锁：加锁节点A-->加锁节点B-->解锁节点A-->加锁节点C-->解锁节点B-->加锁节点D这样 * Lock接口的实现，确保可以使用如下技术：允许在不同范围内获取和释放锁，并允许以任意顺序获取和释放多个锁 * * With this increased flexibility comes additional * responsibility. The absence of block-structured locking removes the * automatic release of locks that occurs with {@code synchronized} * methods and statements. In most cases, the following idiom * should be used: * 随着灵活性的提高，责任（responsibility）也随之（comes带来）增加。 * 块结构锁的缺失消除了synchronized方法与语句中发生的锁自动释放（Lock接口的实现不会自动释放锁） * 在大多数情况下，应使用以下习惯用法 * * {@code * Lock l = ...; * l.lock(); * try { * // access the resource protected by this lock * } finally { * l.unlock(); // 手工释放 * }} * * When locking and unlocking occur in different scopes, care must be * taken to ensure that all code that is executed while the lock is * held is protected by try-finally or try-catch to ensure that the * lock is released when necessary. * 当在不同的作用域获得锁与释放锁时，必须注意确保所有在持有锁期间执行的方法必须被try-finally或者try-catch保护（包裹），确保在必要时刻可以释放锁 * * {@code Lock} implementations provide additional functionality * over the use of {@code synchronized} methods and statements by * providing a non-blocking attempt to acquire a lock ({@link * #tryLock()}), an attempt to acquire the lock that can be * interrupted ({@link #lockInterruptibly}, and an attempt to acquire * the lock that can timeout ({@link #tryLock(long, TimeUnit)}). * Lock的实现，相较于synchronized方法与语句提供了额外的方法，例如： * tryLock()，非阻塞前提下尝试获取锁 * lockInterruptibly，尝试获取可以中断的锁 * tryLock(long, TimeUnit)，有最大等待时间的尝试获取锁 * * A {@code Lock} class can also provide behavior and semantics * that is quite different from that of the implicit monitor lock, * such as guaranteed ordering, non-reentrant usage, or deadlock * detection. If an implementation provides such specialized semantics * then the implementation must document those semantics. * Lock类还可以提供与隐式监视器锁完全不同的行为与语义，例如保证排序，不可重入使用，或者死锁检测。 * 如果实现类提供这些专门的语义，那么实现类必须在文档中记录这些语义。（看起来是对代码说明的限制） * * Note that {@code Lock} instances are just normal objects and can * themselves be used as the target in a {@code synchronized} statement. * Acquiring the * monitor lock of a {@code Lock} instance has no specified relationship * with invoking any of the {@link #lock} methods of that instance. * It is recommended that to avoid confusion you never use {@code Lock} * instances in this way, except within their own implementation. * 请注意，Lock的实例只是个普通的对象，并且他们自身也可以用来做synchronized statement的目标对象（synchronized(lock1){...}这个样子）。 * 获取Lock实例的监视器锁与调用lock实例的任何锁方法没有特定的关系。 * 为避免混淆，建议不要以这种方式使用Lock实例，除非在他们自己的实现里。 * * Except where noted, passing a {@code null} value for any * parameter will result in a {@link NullPointerException} being * thrown. * 除非另有说明，传递null值给任何参数都会导致抛出NullPointException异常 * * Memory Synchronization * 内存同步 * * All {@code Lock} implementations must enforce the same * memory synchronization semantics as provided by the built-in monitor * lock, as described in * * The Java Language Specification (17.4 Memory Model): * 强制所有Lock的实现类都必须与内置监视器锁提供的具有相同的内存锁语义，如这个链接里的所述 * * * A successful {@code lock} operation has the same memory * synchronization effects as a successful Lock action. * A successful {@code unlock} operation has the same * memory synchronization effects as a successful Unlock action. * * （不知道这句话实际含义） * 成功的Lock动作与成功的lock操作具有相同的内存同步效果 * 成功的Unlock动作与成功的unlock操作具有相同的内存同步效果 * * Unsuccessful locking and unlocking operations, and reentrant * locking/unlocking operations, do not require any memory * synchronization effects. * 不成功的加锁/解锁操作，和可重入的加锁/解锁操作，不要求任何内存同步效果 * * Implementation Considerations * 实现的注意事项 * * The three forms of lock acquisition (interruptible, * non-interruptible, and timed) may differ in their performance * characteristics, ordering guarantees, or other implementation * qualities. Further, the ability to interrupt the ongoing * acquisition of a lock may not be available in a given {@code Lock} * class. Consequently, an implementation is not required to define * exactly the same guarantees or semantics for all three forms of * lock acquisition, nor is it required to support interruption of an * ongoing lock acquisition. An implementation is required to clearly * document the semantics and guarantees provided by each of the * locking methods. It must also obey the interruption semantics as * defined in this interface, to the extent that interruption of lock * acquisition is supported: which is either totally, or only on * method entry. * 锁获取（acquisition）的三种形式（可中断，不可中断，和有时限的）可能有着不同的行为特征，顺序保证，与其他的实现质量。 * 此外，中断正在获取锁的操作的能力，在给定的Lock实现中可能不支持。 * 因此，并不要求实现类为三种形式的锁获取（lock acquisition）定义完全相同的保证或者语义，也不要求支持中断正在获取锁的操作。 * 要求实现类清楚的记录提供的每个locking方法对应的语义和保证。 * 同时，实现类也需要遵循在Lock这个接口类中定义的中断语义，以支持锁获取的中断：要么完全支持，要么只在方法入口 * * As interruption generally implies cancellation, and checks for * interruption are often infrequent, an implementation can favor responding * to an interrupt over normal method return. This is true even if it can be * shown that the interrupt occurred after another action may have unblocked * the thread. An implementation should document this behavior. * 中断通常意味着（implies）取消，并且中断检查通常很少发生，因此实现类可以偏向于响应中断而不是正常的方法返回。 * 即使可以证明 中断发生在 另一个动作已经解除了本线程阻塞之后，也是如此。实现类中应该记录下该行为 * * @see ReentrantLock * @see Condition * @see ReadWriteLock * * @since 1.5 * @author Doug Lea */ public interface Lock { /** * Acquires the lock. * * If the lock is not available then the current thread becomes * disabled for thread scheduling purposes and lies dormant until the * lock has been acquired. * 如果不能获取到锁，那么当前线程将被禁止用于线程调度目的并处于（lie）休眠（dormant蛰伏）状态，直到能够获取到锁 * * Implementation Considerations * 实现注意事项 * * A {@code Lock} implementation may be able to detect erroneous use * of the lock, such as an invocation that would cause deadlock, and * may throw an (unchecked) exception in such circumstances. The * circumstances and the exception type must be documented by that * {@code Lock} implementation. * Lock的实现可能需要能够检测到锁的错误使用，比如导致死锁的调用，和在这些情况（circumstances）下可能抛出（未检查）异常。 * 在Lock的实现中必须记录下这些情况和异常类型。 */ void lock(); /** * Acquires the lock unless the current thread is * {@linkplain Thread#interrupt interrupted}. * 除非当前线程被中断（interrupted），否则获取锁 * * Acquires the lock if it is available and returns immediately. * 如果可用，则获取锁并立即返回。 * * If the lock is not available then the current thread becomes * disabled for thread scheduling purposes and lies dormant until * one of two things happens: * 如果锁不可用，那么当前线程将被禁止用户线程调度目的并处于休眠状态，直到以下两种情况之一发生：（这两种情况就是1.要么获取到了锁，2.要么在获取锁的时候被中断了，而正好支持中断这个获取锁操作） * * * The lock is acquired by the current thread; or * Some other thread {@linkplain Thread#interrupt interrupts} the * current thread, and interruption of lock acquisition is supported. * * 1.锁被当前线程获取； * 2.或者其他的一些线程中断了当前线程，并且支持在获取锁的过程中被中断。 * * 下面解释如果获取锁过程中被中断会发生什么 * If the current thread: * * has its interrupted status set on entry to this method; or * is {@linkplain Thread#interrupt interrupted} while acquiring the * lock, and interruption of lock acquisition is supported, * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * 如果当前线程： * 1. 在进入这个方法时设置了中断状态 * 2. 或者在获取锁时被中断，并且支持获取锁的过程被中断。 * 那么将抛出InterruptedException，并且清除当前线程中断状态 * * Implementation Considerations * 实现该方法的注意事项 * * The ability to interrupt a lock acquisition in some * implementations may not be possible, and if possible may be an * expensive operation. The programmer should be aware that this * may be the case. An implementation should document when this is * the case. * 中断锁的获取的能力在一些实现中是不可能的，如果可能，也会是个昂贵的操作（比较费时等）。 * 程序员应当意识到这是可能的情况。 * 实现应当记录下这些情况。 * * An implementation can favor responding to an interrupt over * normal method return. * 实现可以倾向于响应中断而不是正常的方法返回。 * * A {@code Lock} implementation may be able to detect * erroneous use of the lock, such as an invocation that would * cause deadlock, and may throw an (unchecked) exception in such * circumstances. The circumstances and the exception type must * be documented by that {@code Lock} implementation. * （跟上面一样，记得检测可能会发生的死锁等错误使用锁的情况，并进行记录） * * @throws InterruptedException if the current thread is * interrupted while acquiring the lock (and interruption * of lock acquisition is supported) * 抛出InterruptedException，如果当前线程在获取锁的时候被中断 */ void lockInterruptibly() throws InterruptedException; /** * Acquires the lock only if it is free at the time of invocation. * 只有在调用时，当前锁空闲才会获取到锁（跟上面两种方式不一样的是，如果在调用时锁被占用了，那么当前线程不会进入休眠，而是立即返回） * * Acquires the lock if it is available and returns immediately * with the value {@code true}. * If the lock is not available then this method will return * immediately with the value {@code false}. * 如果可用那么会获取锁（加锁）并立即返回true * 如果锁不可用，该方法会立即返回false（没有休眠） * * A typical usage idiom for this method would be: （typical usage idiom典型使用习惯） * {@code * Lock lock = ...; * if (lock.tryLock()) { * try { * // manipulate protected state * } finally { * lock.unlock(); // tryLock()成功也会加锁，记得显式释放锁 * } * } else { * // perform alternative actions // 执行替代操作 * }} * * This usage ensures that the lock is unlocked if it was acquired, and * doesn't try to unlock if the lock was not acquired. * 这种用法确保在获取到锁后正确释放锁，并且不会在获取锁失败后尝试释放锁。 * * @return {@code true} if the lock was acquired and * {@code false} otherwise * 这个不会抛出异常 */ boolean tryLock(); /** * Acquires the lock if it is free within the given waiting time and the * current thread has not been {@linkplain Thread#interrupt interrupted}. * 在给定的等待时间里，如果锁空闲并且当前线程没有被中断，则会获取锁（加锁）。 * * If the lock is available this method returns immediately * with the value {@code true}. * If the lock is not available then * the current thread becomes disabled for thread scheduling * purposes and lies dormant until one of three things happens: * * The lock is acquired by the current thread; or * Some other thread {@linkplain Thread#interrupt interrupts} the * current thread, and interruption of lock acquisition is supported; or * The specified waiting time elapses * * 如果能够获取锁，该方法立即返回true * 如果锁不可用，那么当前线程将禁止作为线程调用目标并进入休眠，直到以下三种情况之一发生： * 1. 当前线程获取到该锁 * 2. 其他一些线程中断当前线程，并且支持中断获取锁操作 * 3. 到达了等待时间（等待超时） * * 下面会针对上面说的三种情况进行说明 * If the lock is acquired then the value {@code true} is returned. * 如果成功获取到锁，会返回true * * If the current thread: * * has its interrupted status set on entry to this method; or * is {@linkplain Thread#interrupt interrupted} while acquiring * the lock, and interruption of lock acquisition is supported, * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * 如果当前线程： * 1. 在进入这个方法时设置了中断状态 * 2. 或者在获取锁时被中断，并且支持中断获取锁的操作 * 那么就会抛出InterruptedException异常，并且当前线程清理中断状态 * * If the specified waiting time elapses then the value {@code false} * is returned. * If the time is * less than or equal to zero, the method will not wait at all. * 如果等待时间过去了，那么会返回false * 注意：如果等待时间参数Implementation Considerations * 注意事项 * The ability to interrupt a lock acquisition in some implementations * may not be possible, and if possible may * be an expensive operation. * The programmer should be aware that this may be the case. An * implementation should document when this is the case. * 与lockInterruptibly()的注意事项一样： * 中断锁的获取的能力在一些实现中是不可能的，如果可能，也会是个昂贵的操作（比较费时等）。 * 程序员应当意识到这是可能的情况。 * 实现应当记录下这些情况。 * * An implementation can favor responding to an interrupt over normal * method return, or reporting a timeout. * 更倾向于抛出异常而不是正常的方法返回，或者报告超时 * * A {@code Lock} implementation may be able to detect * erroneous use of the lock, such as an invocation that would cause * deadlock, and may throw an (unchecked) exception in such circumstances. * The circumstances and the exception type must be documented by that * {@code Lock} implementation. * 同样需要检测死锁等错误使用的情况，并且记录下来 * * @param time the maximum time to wait for the lock // 最大等待时间 * @param unit the time unit of the {@code time} argument // 等待时间的时间单位 * @return {@code true} if the lock was acquired and {@code false} * if the waiting time elapsed before the lock was acquired * * @throws InterruptedException if the current thread is interrupted * while acquiring the lock (and interruption of lock * acquisition is supported) * 这个方法如果响应中断也会抛出异常 */ boolean tryLock(long time, TimeUnit unit) throws InterruptedException; /** * Releases the lock. * 释放锁（解锁） * * Implementation Considerations * 注意事项 * A {@code Lock} implementation will usually impose * restrictions on which thread can release a lock (typically only the * holder of the lock can release it) and may throw * an (unchecked) exception if the restriction is violated. * Any restrictions and the exception * type must be documented by that {@code Lock} implementation. * 通常会对可以释放锁的线程加以限制（restrictions）（通常只有锁的持有者（持有该锁的线程）才可以释放它），如果违反限制可能会抛出（未检查）的异常 * 必须记录下任何限制与异常情况 */ void unlock(); /** * Returns a new {@link Condition} instance that is bound to this * {@code Lock} instance. * 返回绑定到此Lock实例的新Condition实例 * 这个在AQS中有使用到，到那里在进行详细观察 * * Before waiting on the condition the lock must be held by the * current thread. * A call to {@link Condition#await()} will atomically release the lock * before waiting and re-acquire the lock before the wait returns. * 在等待条件之前，必须由当前线程来持有锁。 * 调用wait()将在等待之前自动释放锁，并且在等待返回之前重新获取锁 * （这个很关键，当前线程可以调用wait()来主动释放锁并休眠，直到等待结束（比如等待的条件满足了）当前线程会重新获取到锁来继续执行。 * * Implementation Considerations * 注意事项 * The exact operation of the {@link Condition} instance depends on * the {@code Lock} implementation and must be documented by that * implementation. * Condition实例的具体操作取决于Lock实现，并且必须由实现记录下来。 * * @return A new {@link Condition} instance for this {@code Lock} instance * @throws UnsupportedOperationException if this {@code Lock} * implementation does not support conditions * 如果Lock实现不支持conditions，会返回UnsupporttedOperationException异常 */ Condition newCondition(); } "},"Doc/util/concurrent/locks/ReentrantLock.java.html":{"url":"Doc/util/concurrent/locks/ReentrantLock.java.html","title":"ReentrantLock.Java","keywords":"","body":"ReentrantLock /* * ORACLE PROPRIETARY/CONFIDENTIAL. Use is subject to license terms. * * * * * * * * * * * * * * * * * * * * */ /* * * * * * * Written by Doug Lea with assistance from members of JCP JSR-166 * Expert Group and released to the public domain, as explained at * http://creativecommons.org/publicdomain/zero/1.0/ */ package java.util.concurrent.locks; import java.util.concurrent.TimeUnit; import java.util.Collection; /** * A reentrant mutual exclusion {@link Lock} with the same basic * behavior and semantics as the implicit monitor lock accessed using * {@code synchronized} methods and statements, but with extended * capabilities. * 可重入的互斥锁与使用synchronized方法或语句访问的隐式监视器锁具有相同的行为和语义，不过提供了扩展功能 * * A {@code ReentrantLock} is owned by the thread last * successfully locking, but not yet unlocking it. A thread invoking * {@code lock} will return, successfully acquiring the lock, when * the lock is not owned by another thread. The method will return * immediately if the current thread already owns the lock. This can * be checked using methods {@link #isHeldByCurrentThread}, and {@link * #getHoldCount}. * ReentrantLock属于上次成功加锁并且还没解锁的线程。当lock不属于其他线程时，调用Lock方法的线程会返回并成功加锁。 * 如果该线程已拥有该锁，那么Lock方法会立即返回。可以调用isHeldByCurrentThread与getHoldCount方法来检查锁的相关信息。 * * The constructor for this class accepts an optional * fairness parameter. When set {@code true}, under * contention, locks favor granting access to the longest-waiting * thread. Otherwise this lock does not guarantee any particular * access order. Programs using fair locks accessed by many threads * may display lower overall throughput (i.e., are slower; often much * slower) than those using the default setting, but have smaller * variances in times to obtain locks and guarantee lack of * starvation. Note however, that fairness of locks does not guarantee * fairness of thread scheduling. Thus, one of many threads using a * fair lock may obtain it multiple times in succession while other * active threads are not progressing and not currently holding the * lock. * Also note that the untimed {@link #tryLock()} method does not * honor the fairness setting. It will succeed if the lock * is available even if other threads are waiting. * ReetrantLock的构造方法可以接收一个公平参数，如果设置该参数为true，在有竞争的情况下，lock偏向于授予等待时间最长的线程。否则这个锁不能保证任何的特定的访问顺序。 * 通过多线程访问使用公平锁的程序，相较于使用默认（即非公平锁）设置，会显现出较低的吞吐量（即更慢，通常慢很多），但是在获取锁与保证不出现饥饿的时间上具有较小的差异。 * 然而需要注意的是，锁的公平性并不保证线程调度的公平性。因此，使用公平锁的许多线程中的某一个会连续多次的获得锁（不断重入？），其他active线程并没有进行和持有该锁 * * 另外需要注意的是，无时间的tryLock()方法没有公平性的设置，即使有其他线程在等待，当锁可用时也会返回true * * It is recommended practice to always immediately * follow a call to {@code lock} with a {@code try} block, most * typically in a before/after construction such as: * 推荐的做法是“总是”在使用lock后马上调用try方法块，最常见的做法是在构造函数之前/之后 * * {@code * class X { * private final ReentrantLock lock = new ReentrantLock(); * // ... * * public void m() { * lock.lock(); // block until condition holds * try { * // ... method body * } finally { * lock.unlock() // 因为不能自己释放锁，所以要确保try final手动释放锁 * } * } * }} * * In addition to implementing the {@link Lock} interface, this * class defines a number of {@code public} and {@code protected} * methods for inspecting the state of the lock. Some of these * methods are only useful for instrumentation and monitoring. * 除了实现Lock接口，该class还定义了一些public和protected方法来检查锁的状态，其中的一些方法只对仪表盘与监控有用 * * Serialization of this class behaves in the same way as built-in * locks: a deserialized lock is in the unlocked state, regardless of * its state when serialized. * 此类的序列化与内置锁的行为方式一致；反序列化的锁处于解锁状态，无论其序列化时的状态如何。？？？ * * This lock supports a maximum of 2147483647 recursive locks by * the same thread. Attempts to exceed this limit result in * {@link Error} throws from locking methods. * 该锁最大支持同一个线程建立2147483647个递归锁，尝试超过此限制会导致抛出Error异常（通过递归的方式重入2^31 - 1次) * * @since 1.5 * @author Doug Lea */ public class ReentrantLock implements Lock, java.io.Serializable { private static final long serialVersionUID = 7373984872572414699L; /** Synchronizer providing all implementation mechanics */ // 提供所有实现机制的同步器 private final Sync sync; // 用Sync来实现锁，它包含子类公平/非公平锁类的实现，与AQS的默认实现 /** * Base of synchronization control for this lock. Subclassed * into fair and nonfair versions below. Uses AQS state to * represent the number of holds on the lock. * ReentrantLock的同步控制基础（根基）。可实现公平锁与非公平锁版本。使用AQS的state值来表示锁的持有次数。 */ abstract static class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -5179523762034025860L; /** * Performs {@link Lock#lock}. The main reason for subclassing * is to allow fast path for nonfair version. * lock方法。子类化（abstract）的主要原因是为了快速支持非公平版本。 */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. * 执行非公平的tryLock。 * tryAcquire是在子类中实现，但是nofaireTryAcquire与tryAcquire都需要对tryLock方法进行非公平尝试。 */ final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 当前AQS没有被占用 if (compareAndSetState(0, acquires)) { // 设置state状态，这一步很关键，如果多线程同时调用该tryAcquire方法，只有一个线程能CAS成功，成为锁的拥有者，其他线程只能失败 setExclusiveOwnerThread(current); // 调用AQS继承的AbstarctOwnableSynchronizer类的方法，设置独占锁的当前拥有者 return true; } } else if (current == getExclusiveOwnerThread()) { // state!=0的情况下，如果独占锁当前的拥有者是本线程，表示可重入 int nextc = c + acquires; // 计算AQS state的新值 if (nextc Acquires the lock if it is not held by another thread and returns * immediately, setting the lock hold count to one. * 如果没有被其他线程持有，则获取锁并立即返回，设置锁的持有数量为1. * * If the current thread already holds the lock then the hold * count is incremented by one and the method returns immediately. * 如果当前线程已经持有该锁，那么锁的持有数量加1，并且方法立即返回 * * If the lock is held by another thread then the * current thread becomes disabled for thread scheduling * purposes and lies dormant until the lock has been acquired, * at which time the lock hold count is set to one. * 如果该锁已被其他线程持有，那么当前线程被禁止用于线程调度并且挂起（休眠），直到锁能够获取，到那时设置锁的持有数为1 * */ public void lock() { sync.lock(); } /** * Acquires the lock unless the current thread is * {@linkplain Thread#interrupt interrupted}. * 获取锁，除非当前线程被中断。 * * Acquires the lock if it is not held by another thread and returns * immediately, setting the lock hold count to one. * 如果锁没有被其他线程持有，加锁并且立即返回，设置锁持有数为1。 * * If the current thread already holds this lock then the hold count * is incremented by one and the method returns immediately. * 如果当前线程已经持有该锁，那么将持有数加1，并且立即返回。 * * If the lock is held by another thread then the * current thread becomes disabled for thread scheduling * purposes and lies dormant until one of two things happens: * 如果该锁已被其他线程获取，那么当前线程对于线程调度不可用并且挂起（休眠）直到以下两个事件发生任意一个： * * * * The lock is acquired by the current thread; or * 线程成功获取到锁； * * Some other thread {@linkplain Thread#interrupt interrupts} the * current thread. * 其他线程中断了当前线程。 * * * * If the lock is acquired by the current thread then the lock hold * count is set to one. * 如果锁被当前线程成功获取，那么锁的持有数设置为1。 * * If the current thread: * 如果当前线程： * * * has its interrupted status set on entry to this method; or * 在进入该方法前被设置了中断状态； * * is {@linkplain Thread#interrupt interrupted} while acquiring * the lock, * 在获取锁的过程中被中断， * * * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * 那么抛出中断异常，并且清除当前线程的中断状态（线程的中断status由“中断”变为“无中断”） * * In this implementation, as this method is an explicit * interruption point, preference is given to responding to the * interrupt over normal or reentrant acquisition of the lock. * 在此实现中，这个方法是个明显的中断点，所以优先（preference）响应中断而不是正常或者可重入的获取锁 * * @throws InterruptedException if the current thread is interrupted */ public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); // 调用的AQS方法，如果进来时已经被中断，直接抛出异常，否则就调用AQS的doAcquireInterruptibly方法去排队竞争锁，如果排队过程中有中断，也抛出异常并退出等待 } /** * Acquires the lock only if it is not held by another thread at the time * of invocation. * 获取锁，只有在调用时没有被其他线程持有该锁。 * * Acquires the lock if it is not held by another thread and * returns immediately with the value {@code true}, setting the * lock hold count to one. Even when this lock has been set to use a * fair ordering policy, a call to {@code tryLock()} will * immediately acquire the lock if it is available, whether or not * other threads are currently waiting for the lock. * This &quot;barging&quot; behavior can be useful in certain * circumstances, even though it breaks fairness. If you want to honor * the fairness setting for this lock, then use * {@link #tryLock(long, TimeUnit) tryLock(0, TimeUnit.SECONDS) } * which is almost equivalent (it also detects interruption). * 如果没有被其他线程持有则获取锁，并立即返回true，设置锁持有数为1。 * 即使设置使用公平策略加锁，在锁可用的情况下，调用tryLock将立即获取锁，不管是否有其他线程正在sync队列上等待锁。 * 抢占在某些（certain）情况（circumstances）下是有用的，即使破坏了公平性。 * 如果想保持公平性，那么使用tryLock(long, TimeUnit)、tryLock(0, TimeUnit.SECONDS)，这俩几乎是等效的。 * * If the current thread already holds this lock then the hold * count is incremented by one and the method returns {@code true}. * 如果当前线程已经持有锁了，那么持有数加1，并且返回true。 * * If the lock is held by another thread then this method will return * immediately with the value {@code false}. * 如果锁已经被其他线程持有，那么该方法将立即返回false。 * * @return {@code true} if the lock was free and was acquired by the * current thread, or the lock was already held by the current * thread; and {@code false} otherwise */ public boolean tryLock() { return sync.nonfairTryAcquire(1); // 不管公平不公平，直接调用Sync的nonfairTryAcquire方法，试图抢占锁，加锁失败返回false。 } /** * Acquires the lock if it is not held by another thread within the given * waiting time and the current thread has not been * {@linkplain Thread#interrupt interrupted}. * 获取锁，如果在等待时间内没有被其他线程持有（在等待时间内有时间点锁有空闲），并且当前线程没有被中断。 * * Acquires the lock if it is not held by another thread and returns * immediately with the value {@code true}, setting the lock hold count * to one. If this lock has been set to use a fair ordering policy then * an available lock will not be acquired if any other threads * are waiting for the lock. This is in contrast to the {@link #tryLock()} * method. If you want a timed {@code tryLock} that does permit barging on * a fair lock then combine the timed and un-timed forms together: * 获取锁，如果在等待时间内没有被其他线程持有，将立即返回true，设置锁的持有数为1。 * 如果设置使用公平策略加锁，有线程在排队等锁的话，那么即使锁可用也不会成功获取锁。 * 这与tryLock()方法相反（contrast 比对）。 * 如果在公平锁下，既想用限时的tryLock()，又想允许抢占，那么联合使用限时与不限时的形式： * * {@code * if (lock.tryLock() || * lock.tryLock(timeout, unit)) { // 先试试抢占，如果抢不到就在等待时间内尝试 * ... * }} * * If the current thread * already holds this lock then the hold count is incremented by one and * the method returns {@code true}. * 如果当前线程已经持有锁，那么持有数加1，并且方法返回true。 * * If the lock is held by another thread then the * current thread becomes disabled for thread scheduling * purposes and lies dormant until one of three things happens: * 如果该锁已被其他线程持有，那么当前线程对线程调度不可用并且挂起（休眠），直到以下三种情况任意一种发生： * * * * The lock is acquired by the current thread; or * * Some other thread {@linkplain Thread#interrupt interrupts} * the current thread; or * * The specified waiting time elapses * 1、当前线程获取到锁； * 2、当前线程被其他线程中断； * 3、指定的等待时间超时； * * * * If the lock is acquired then the value {@code true} is returned and * the lock hold count is set to one. * * If the current thread: * * * * has its interrupted status set on entry to this method; or * * is {@linkplain Thread#interrupt interrupted} while * acquiring the lock, * * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * 如果当前线程： * 1、在进入该方法之前已被中断； * 2、在等待获取锁时被中断； * 那么将抛出InterruptedException，并且当前线程的interrupted status清空。 * * If the specified waiting time elapses then the value {@code false} * is returned. If the time is less than or equal to zero, the method * will not wait at all. * 如果指定等待时间超时，那么将返回false。 * 如果指定的等待时间In this implementation, as this method is an explicit * interruption point, preference is given to responding to the * interrupt over normal or reentrant acquisition of the lock, and * over reporting the elapse of the waiting time. * 优先响应中断，而不是正常或者重入的获取锁，也不是响应已超时时间。 * * @param timeout the time to wait for the lock * @param unit the time unit of the timeout argument * @return {@code true} if the lock was free and was acquired by the * current thread, or the lock was already held by the current * thread; and {@code false} if the waiting time elapsed before * the lock could be acquired * @throws InterruptedException if the current thread is interrupted * @throws NullPointerException if the time unit is null */ public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(timeout)); // AQS的tryAcquireNanos，先尝试本类(sync)实现的tryAcquire，如果失败，则调用AQS的doAcquireNanos，将该线程入队，等待获取锁。 } /** * Attempts to release this lock. * 释放锁 * * If the current thread is the holder of this lock then the hold * count is decremented. If the hold count is now zero then the lock * is released. If the current thread is not the holder of this * lock then {@link IllegalMonitorStateException} is thrown. * 如果当前线程持有该锁，那么持有数递减。 * 如果锁的持有数成了0，那么当前锁被释放。 * 如果当前线程不是该锁的持有者，那么抛出IllegalMonitorStateException（大概是非法修改监视器状态异常） * * @throws IllegalMonitorStateException if the current thread does not * hold this lock */ public void unlock() { sync.release(1); // 调用AQS实现的release方法，先调用本类（sync）实现的tryRelease，如果可以，从等待队列的head处unpark一个后继。 } /** * Returns a {@link Condition} instance for use with this * {@link Lock} instance. * 返回一个与该Lock实例一起使用的Condition实例。 * * The returned {@link Condition} instance supports the same * usages as do the {@link Object} monitor methods ({@link * Object#wait() wait}, {@link Object#notify notify}, and {@link * Object#notifyAll notifyAll}) when used with the built-in * monitor lock. * 当与内置的监视器锁一起使用时，返回的Condition实例支持与Object监视器相同的使用方法，例如wait、notify和notifyAll。 * * * * If this lock is not held when any of the {@link Condition} * {@linkplain Condition#await() waiting} or {@linkplain * Condition#signal signalling} methods are called, then an {@link * IllegalMonitorStateException} is thrown. * 如果在调用Condition的waiting、signalling等方法时，关联的该锁没有被当前线程持有，那么将抛出IllegalMonitorStateException。 * * When the condition {@linkplain Condition#await() waiting} * methods are called the lock is released and, before they * return, the lock is reacquired and the lock hold count restored * to what it was when the method was called. * 当调用Condition的waiting方法时，持有的锁将释放。 * 在该方法返回时，将重新持有锁，并且将锁的持有数恢复到调用该方法时的状态。 * （锁的释放与重新获取） * * If a thread is {@linkplain Thread#interrupt interrupted} * while waiting then the wait will terminate, an {@link * InterruptedException} will be thrown, and the thread's * interrupted status will be cleared. * 如果线程在等待过程中被中断，那么wait将终止，抛出中断异常，并且线程的interrupted state被清理。 * * Waiting threads are signalled in FIFO order. * 等待线程按FIFO顺序被唤醒（signalled 接收信号） * * The ordering of lock reacquisition for threads returning * from waiting methods is the same as for threads initially * acquiring the lock, which is in the default case not specified, * but for fair locks favors those threads that have been * waiting the longest. * 从等待方法返回的线程重新获取锁的顺序与最初获取锁的线程（方式）相同，在默认情况下没有指定，但是对于公平锁，那些队列中等待时间最长的线程要比该线程优先。 * * * * @return the Condition object */ public Condition newCondition() { return sync.newCondition(); // 本类重写的Lock接口方法，其实是调用的内部类Sync里写的方法。 } /** * Queries the number of holds on this lock by the current thread. * 查询当前线程持有该锁的持有数。 * * A thread has a hold on a lock for each lock action that is not * matched by an unlock action. * 线程为每一个与解锁操作不匹配的加锁操作持有一个锁（含义可能是，如果加锁了但没解锁，那么锁的数量会加1） * * The hold count information is typically only used for testing and * debugging purposes. For example, if a certain section of code should * not be entered with the lock already held then we can assert that * fact: * 持有数信息通常只用于测试和debug的目的。 * 例如，如果在已经持有锁的情况下，某段代码不应该被输入，那么我们可以断言（assert）这个事实： * * {@code * class X { * ReentrantLock lock = new ReentrantLock(); * // ... * public void m() { * assert lock.getHoldCount() == 0; // assert 断言，在AQS里也有，表示如果满足就继续执行，不满足就抛出异常 * lock.lock(); * try { * // ... method body * } finally { * lock.unlock(); * } * } * }} * 上面那段代码的意思就是，assert 如果当前线程没有持有锁，那么就加锁，否则就直接跳过加锁。 * * @return the number of holds on this lock by the current thread, * or zero if this lock is not held by the current thread * 如果当前线程没有持有该锁，返回0 */ public int getHoldCount() { return sync.getHoldCount(); // 调用Sync的，先判断当前线程是否持有锁，如果持有，返回AQS的state值 } /** * Queries if this lock is held by the current thread. * 查询当前线程是否持有该锁。 * * Analogous to the {@link Thread#holdsLock(Object)} method for * built-in monitor locks, this method is typically used for * debugging and testing. For example, a method that should only be * called while a lock is held can assert that this is the case: * 类似于内置监视器锁的holdsLock(Object)方法，通常只用于测试和debug的目的。 * 例如，方法应该只在当前线程持有锁的情况下执行，可以这样使用assert： * * {@code * class X { * ReentrantLock lock = new ReentrantLock(); * // ... * * public void m() { * assert lock.isHeldByCurrentThread(); * // ... method body * } * }} * * It can also be used to ensure that a reentrant lock is used * in a non-reentrant manner, for example: * 也可以用于确保可重入锁以不可重入的方式使用。 * （把可重入锁当做不可重入锁使用） * * {@code * class X { * ReentrantLock lock = new ReentrantLock(); * // ... * * public void m() { * assert !lock.isHeldByCurrentThread(); // 当前线程是否持有锁，如果持有，抛出异常 * lock.lock(); * try { * // ... method body * } finally { * lock.unlock(); * } * } * }} * * @return {@code true} if current thread holds this lock and * {@code false} otherwise */ public boolean isHeldByCurrentThread() { return sync.isHeldExclusively(); // Sync#isHeldExclusively -> AbstractOwnerSynchronizer#getExclusiveOwnerThread 与当前线程比较 } /** * Queries if this lock is held by any thread. This method is * designed for use in monitoring of the system state, * not for synchronization control. * 查询该锁是否被线程持有（不限于当前线程）。 * 该方法为了监控系统状态设计的，不是为了同步控制。 * * @return {@code true} if any thread holds this lock and * {@code false} otherwise */ public boolean isLocked() { return sync.isLocked(); // Sync#isLocked，通过判断AQS的state值是否等于=0 } /** * Returns {@code true} if this lock has fairness set true. * 使用公平策略的话，返回true。 * * @return {@code true} if this lock has fairness set true */ public final boolean isFair() { return sync instanceof FairSync; } /** * Returns the thread that currently owns this lock, or * {@code null} if not owned. When this method is called by a * thread that is not the owner, the return value reflects a * best-effort approximation of current lock status. For example, * the owner may be momentarily {@code null} even if there are * threads trying to acquire the lock but have not yet done so. * This method is designed to facilitate construction of * subclasses that provide more extensive lock monitoring * facilities. * 返回当前拥有该锁的线程，如果没有拥有者，返回null。 * 当该方法被非拥有者调用时，返回的值尽力反映当前锁的状态。（是个近似值 approximation） * 例如，持有者可能某个时刻是null：有线程正在获取锁，但还没有完成。 * 该方法是为了促进（facilitate）子类构建而设计，以提高更广泛的监控设备 * * @return the owner, or {@code null} if not owned */ protected Thread getOwner() { return sync.getOwner(); } /** * Queries whether any threads are waiting to acquire this lock. Note that * because cancellations may occur at any time, a {@code true} * return does not guarantee that any other thread will ever * acquire this lock. This method is designed primarily for use in * monitoring of the system state. * 查询是否有线程在等待获取锁。 * 注意，因为取消（取消可能是中断或者超时）可能在任意时刻发生，返回true不保证任何其他线程将获得锁。（返回true不保证后续一定有线程会成功加锁，因为即使有排队，但排队线程可能会取消） * 该方法主要是为了监视系统状态设计的。 * * @return {@code true} if there may be other threads waiting to * acquire the lock */ public final boolean hasQueuedThreads() { return sync.hasQueuedThreads(); // AQS的hasQueuedThreads方法，判断head != tail } /** * Queries whether the given thread is waiting to acquire this * lock. Note that because cancellations may occur at any time, a * {@code true} return does not guarantee that this thread * will ever acquire this lock. This method is designed primarily for use * in monitoring of the system state. * 查询给定的线程是否在该锁的等待队列上。 * 注意，因为取消可能在任意时刻发生，返回true不保证该线程将获得锁。（跟上面方法的原因一样） * 该方法主要是为了监视系统状态设计的。 * * @param thread the thread * @return {@code true} if the given thread is queued waiting for this lock * @throws NullPointerException if the thread is null */ public final boolean hasQueuedThread(Thread thread) { return sync.isQueued(thread); // AQS的isQueued方法，从tail向前遍历，如果找到该线程，返回true，否则false。（为什么从tail开始遍历，可以看一下AQS的addWaiter或者enq过程） } /** * Returns an estimate of the number of threads waiting to * acquire this lock. The value is only an estimate because the number of * threads may change dynamically while this method traverses * internal data structures. This method is designed for use in * monitoring of the system state, not for synchronization * control. * 返回一个预估的等待获取该锁的线程数。 * 值只是个预估值，因为在遍历内部数据结构时，线程可能会动态改变。 * 该方法是为了监视系统状态设计的，不是为了同步。 * * @return the estimated number of threads waiting for this lock */ public final int getQueueLength() { return sync.getQueueLength(); // 调用AQS#getQueueLength方法，从tail遍历，累加所有的节点数 } /** * Returns a collection containing threads that may be waiting to * acquire this lock. Because the actual set of threads may change * dynamically while constructing this result, the returned * collection is only a best-effort estimate. The elements of the * returned collection are in no particular order. This method is * designed to facilitate construction of subclasses that provide * more extensive monitoring facilities. * 返回包含可能在获取该锁等待的线程集合。 * 由于实际上的线程集合可能在构建结果的过程中动态改变，这个集合的结果只是个尽力预估值。 * 返回的集合中的元素没有特定顺序。 * 该方法是为了促进子类构建而设计，以提高更广泛的监控设备。 * * @return the collection of threads */ protected Collection getQueuedThreads() { return sync.getQueuedThreads(); // 调用AQS#getQueuedThreads } /** * Queries whether any threads are waiting on the given condition * associated with this lock. Note that because timeouts and * interrupts may occur at any time, a {@code true} return does * not guarantee that a future {@code signal} will awaken any * threads. This method is designed primarily for use in * monitoring of the system state. * 查询是否有线程在给定的与该锁关联的condition上等待。 * 注意，由于超时和中断可能在任意时刻发生，返回true不保证未来signal将唤醒任意线程。（有可能现在在condition queue上有线程在等待，但是过了一段时间这些线程取消了，再过一段时间调用signal也不会有任何线程响应了） * 该方法主要是为了用于监视系统状态设计的。 * * @param condition the condition * @return {@code true} if there are any waiting threads * @throws IllegalMonitorStateException if this lock is not held * @throws IllegalArgumentException if the given condition is * not associated with this lock * @throws NullPointerException if the condition is null */ public boolean hasWaiters(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) // 判断给定的condition是否为AQS内部实现的ConditionObject throw new IllegalArgumentException(\"not owner\"); return sync.hasWaiters((AbstractQueuedSynchronizer.ConditionObject)condition); // 调用AQS#hasWaiters(ConditionObject condition)->AQS#hasWaiters，要求必须持有该锁。从firstWaiter开始遍历，如果有ws=CONDITION的，返回true } /** * Returns an estimate of the number of threads waiting on the * given condition associated with this lock. Note that because * timeouts and interrupts may occur at any time, the estimate * serves only as an upper bound on the actual number of waiters. * This method is designed for use in monitoring of the system * state, not for synchronization control. * 返回预估的在给定与该锁关联的condition上等待的线程数。 * 注意，由于超时和中断可能在任意时刻发生，预估的waiter数量>=实际的waiter数量。 * 该方法主要是为了用于监视系统状态设计的。 * * @param condition the condition * @return the estimated number of waiting threads * @throws IllegalMonitorStateException if this lock is not held * @throws IllegalArgumentException if the given condition is * not associated with this lock * @throws NullPointerException if the condition is null */ public int getWaitQueueLength(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(\"not owner\"); return sync.getWaitQueueLength((AbstractQueuedSynchronizer.ConditionObject)condition); // 调用AQS#getWaitQueueLength，要求必须持有该锁。 } /** * Returns a collection containing those threads that may be * waiting on the given condition associated with this lock. * Because the actual set of threads may change dynamically while * constructing this result, the returned collection is only a * best-effort estimate. The elements of the returned collection * are in no particular order. This method is designed to * facilitate construction of subclasses that provide more * extensive condition monitoring facilities. * 返回在给定的与该锁关联的condition上等待的线程集合。 * 由于在构造结果的过程中实际的线程集会动态变化，所以返回的集合只是一个尽力预估值。 * 返回的集合中元素没有特定的顺序。 * 该方法是为了促进子类构建而设计，以提高更广泛的监控设备。 * * @param condition the condition * @return the collection of threads * @throws IllegalMonitorStateException if this lock is not held * @throws IllegalArgumentException if the given condition is * not associated with this lock * @throws NullPointerException if the condition is null */ protected Collection getWaitingThreads(Condition condition) { if (condition == null) throw new NullPointerException(); if (!(condition instanceof AbstractQueuedSynchronizer.ConditionObject)) throw new IllegalArgumentException(\"not owner\"); return sync.getWaitingThreads((AbstractQueuedSynchronizer.ConditionObject)condition); } /** * Returns a string identifying this lock, as well as its lock state. * The state, in brackets, includes either the String {@code \"Unlocked\"} * or the String {@code \"Locked by\"} followed by the * {@linkplain Thread#getName name} of the owning thread. * * @return a string identifying this lock, as well as its lock state */ public String toString() { Thread o = sync.getOwner(); return super.toString() + ((o == null) ? \"[Unlocked]\" : \"[Locked by thread \" + o.getName() + \"]\"); } } "},"Doc/日志.html":{"url":"Doc/日志.html","title":"日志","keywords":"","body":"gitbook serve gitbook install 学习进度 --202108 * Comparable * Comparator * BiConsumer * BiFunction * Objects 封装了一些对于Object的比较、hashcode、返回对象等，增加对null的处理，提高null的安全与容忍度 * Iterator -- 20210820 1、开始看ConcurrentMap，发现注释上的一句话 except that the action is performed atomically. 有这句话的就表示该方法为原子操作 2、ConcurrentMap的merge与compute的区别是，merge依赖给定的value与原value进行计算，compute只基于原value计算 3、今天整理完开ConcurrentHashMap了 BiConsumer的accept是干啥的 BiFunction的apply是干啥的 -- 20210819 1、AbstractMap里面用到了StringBuilder来构建toString() 它不是线程安全的 This class provides an API compatible with StringBuffer, but with no guarantee of synchronization. 2、看完了AbstractMap，开始下一个了 3、JDK1.7之后的Objects类是个好东西 -- 20210818 1、用新的IDEA发现竟然有阅读模式，555，找了好久结果自己支持。然后就看到了{@inheritDoc}注释不一样的展示 2、加班继续看AbstractMap，前几天出门了，就放下了好久 3、@implSpec注释也不一样了，变成了Implementation Requirements 关于{@inheritDoc}注释 像AbstractMap的这个方法： /** * {@inheritDoc} * * @implSpec * This implementation returns size() == 0. */ public boolean isEmpty() { return size() == 0; } 实现的接口是Map： /** * Returns true if this map contains no key-value mappings. * * @return true if this map contains no key-value mappings */ boolean isEmpty(); 在生成Doc时，通过该注释可以将实现的接口方法的注释给同步过来，就成下面这个样子： /* * Returns true if this map contains no key-value mappings. * Implementation Requirements: * This implementation returns size() == 0. */ public boolean isEmpty() { return size() == 0; } 可以看到，方法的主体注释文本为两个主体注释的拼接，参数，返回值都可以覆盖掉接口的注释。 对于异常的注释的继承比较特殊： 若子类没有声明父类的异常，则父类的异常注释不会被继承。 子类只会继承它和父类共同声明的异常。 当然，异常的注释，子类可以覆盖掉父类的注释。 推荐的异常注释是子类列出所有的异常，如果父类也声明了该异常，则用 @throws IOException {@inheritDoc} 继承该异常的注释。 所有的注释继承都有拼接功能，如 * @return {@inheritDoc} a+b. * @throws IOException {@inheritDoc} when file is missed. 返回值注释会继承父类的返回值注释，在加上新的注释。 异常注释会继承父类的异常注释，在加上新的注释。 -- 20210811 1、对于AbstractMap来说，大多数对key的操作都会被子类给override 2、看AbstractMap，entrySet()真是个好东西 -- 20210810 1、看完了Map，明天开始AbstractMap，争取这周看完ConcurrentMap 2、下周看完ConcurrentHashMap的公共部分，就开始回顾 -- 20210809 对短暂满足上瘾了 下面的有时间需要单独整理出来，作为笔记 1、JDK1.8的新东西，函数式接口 一、概念 函数式接口在Java中是指：有且仅有一个抽象方法的接口。 函数式接口，即适用于函数式编程场景的接口。 而Java中的函数式编程体现就是Lambda，所以函数式接口就是可以适用于Lambda使用的接口。 只有确保接口中有且仅有一个抽象方法，Java中的Lambda才能顺利地进行推导。 二、格式 只要确保接口中有且仅有一个抽象方法即可： 说明：函数式接口要求只有一个抽象方法。但是还可以有默认方法、静态方法，只要只有一个抽象方法就可以 修饰符 interface 接口名称 { public abstract 返回值类型 方法名称(可选参数信息); } 比如这个测试接口 @FunctionalInterface public interface TestInterfacePrint { // 如果接口里有多于1个的抽象方法，那么@FunctionalInterface会报错，继承自Object的方法不算抽象方法 // Multiple non-overriding abstract methods found in interface TestInterfacePrint // void printSingle(String a); // void printDouble(String a, String b); // 唯一的抽象方法 Integer calc(Integer a, Integer b); // 继承自Object的两个方法（写不写@Override对结果没影响） boolean equals(Object obj); @Override String toString(); // 不能通过default重写toString()方法，因为Object里面有实现了： // Default method 'toString' overrides a member of 'java.lang.Object' // default String toString() { // return \"TestInterfacePrint\"; // }; // 不能通过static重写toString()方法，因为Object里面该方法是个对象方法（非类方法），必须得实例化才能调用 // Static method 'toString()' in 'TestInterfacePrint' cannot override instance method 'toString()' in 'java.lang.Object' // static String toString() { // return \"TestInterfacePrint\"; // }; // 默认方法 default String get(String a) { return \"a\" + a; } // 静态方法 static String hi(String a) { return \"hi:\" + a; } } // 如果没有写@FunctionalInterface， public interface TestInterfacePrint2 { void pr(); } 可以这样调用 public class TestPrint2 { public static void main(String[] args) { // 1、如果接口中有多于一个抽象方法，按函数式接口调用会编译失败 // testInterfacePrint.printSingle(\"hello\"); // print1(\"hello\", (a)-> System.out.println(a)); // 2、保留一个抽象方法calc，能够成功调用 print2(1, 2, (a, b) -> a + b); // 2.1 也可以直接创建接口类的**匿名实例**，通过lambda表达式来实现唯一的抽象方法 // （注意匿名实例类似于先：实现类A implements 接口类，再new 实现类A()，不是直接new 接口类()） TestInterfacePrint testInterfacePrint = (a, b) -> a + b; System.out.println(testInterfacePrint.calc(10, 20)); // 2.2 如果不用lambda表达式创建**匿名实例**，匿名实例化就成下面这个样子（这也能看出来是个匿名实现） TestInterfacePrint testInterfacePrint12 = new TestInterfacePrint() { @Override public Integer calc(Integer a, Integer b) { return a + b; } }; // 3、接口类中可以重写继承自Object的方法，不算抽象方法，但也没法通过接口类来改写 print3(\"hello\", (a, b) -> a + b); // 4、通过接口类**匿名实例**来调用默认方法 TestInterfacePrint testInterfacePrint13 = (a, b) -> a + b; String res = testInterfacePrint13.get(\"A\"); System.out.println(res); // 5、通过接口类调用接口的静态方法 String res2 = TestInterfacePrint.hi(\"a\"); System.out.println(res2); // 5.1 下面这个调用会报错：因为接口的static静态方法不能被implements实现它的类继承，但可以被extends继承类继承 // Static method may be invoked on containing interface class only // TestInterfacePrint testInterfacePrint14 = (a, b) -> a + b; // String res2 = testInterfacePrint14.hi(\"a\"); // 6、可以直接传入sout来输出 TestInterfacePrint2 testInterfacePrint2 = () -> System.out.println(\"hello2\"); testInterfacePrint2.pr(); } // public static void print1(String s, TestInterfacePrint testInterfacePrint) { // testInterfacePrint.printSingle(s); // } public static void print2(Integer a, Integer b, TestInterfacePrint testInterfacePrint) { Integer res = testInterfacePrint.calc(a, b); System.out.println(res); } public static void print3(String a, TestInterfacePrint testInterfacePrint) { String res = testInterfacePrint.toString(); System.out.println(res); } } -- 20210806 1、这个Map.Entry里面的Compare水很深，不知道今天能不能看懂 2、java的interface里有default关键字，可以在接口里写实现代码了 比如interface Comparator里的 default Comparator thenComparing(Comparator other) { Objects.requireNonNull(other); return (Comparator & Serializable) (c1, c2) -> { int res = compare(c1, c2); return (res != 0) ? res : other.compare(c1, c2); }; } -- 20210805 1、单纯的搜索，是不是用ES -- 20210728 1、线程池ThreadPoolExecutor终于看完了 2、弄了个gitbook，可以搜索了 3、准备看ConcurrentHashMap，又要从Map开始一层层看 -- 20210721 1、线程池终于看到最后了，明天收尾了 2、hashset、concurrentHashMap咋搞 -- 20210717 1、workQueue用来存还没分配给worker的任务 2、Worker是用AQS实现的，用state控制是否可以被中断，好像没有涉及到aqs主要sync队列的部分 -- 20210713 昨天把AbstractExecutorService看完了 今天继续线程池了，结果才看了500行，还有1700+ -- 20210711 第36天 玩了两天，看完了FutureTask，准备接着看了 AbstractExecutorService依赖串太长了 ExecutorCompletionService（看完了）->completionService -> blockingQueue -> queue -> collection -> Iterable 明天把AbstractExecutorService收尾，可以看线程池了 -- 20210708 第33天 没想到，原来的短信接口发版了，没办法，只能加班把自己的短信上线了。 差仨方法就看完FutureTask了，明天看完，再加上Abstract那个，就开线程池了 估计明天能看完AbstracExecutorService就完成任务了 -- 20210706 第31天 脑袋疼，记忆力下降严重 本来以为今天能重看完线程池，下午的考试加上其他的事情，还是争取先看完依赖的接口类吧 -- 20210705 今天是读JUC源码的第30天吧，算第30天，没仔细记下来啥时候开始的，大概是6月7号吧。 本来只是为了看一下线程池的实现，结果发现线程池关联了很多的其他JUC接口/类，所以，就把涉及到的重点都看一下 今天算是个里程碑吧，看完了ReentrantLock的总体源码，加上前几天通读了一遍的AQS（读完了，但实际上还有些实现点不太吃准），基本上可重入锁这一块差不多了。 前几天看完AQS，觉得所有没超过3000行的源码都是可读的，555。 明天要把线程池的搞完，到本周结束看完AtomicReference、ReadWriteLock、ConcurrentHashMap、CopyOnWriteArrayList、CountDownLatch、DelayQueue java.util.concurrent总目录： AbstractExecutorService.java ArrayBlockingQueue.java BlockingDeque.java BlockingQueue.java BrokenBarrierException.java Callable.java CancellationException.java CompletableFuture.java CompletionException.java CompletionService.java CompletionStage.java ConcurrentHashMap.java ConcurrentLinkedDeque.java ConcurrentLinkedQueue.java ConcurrentMap.java ConcurrentNavigableMap.java ConcurrentSkipListMap.java ConcurrentSkipListSet.java CopyOnWriteArrayList.java CopyOnWriteArraySet.java CountDownLatch.java CountedCompleter.java CyclicBarrier.java Delayed.java DelayQueue.java Exchanger.java ExecutionException.java Executor.java ExecutorCompletionService.java Executors.java ExecutorService.java ForkJoinPool.java ForkJoinTask.java ForkJoinWorkerThread.java Future.java FutureTask.java LinkedBlockingDeque.java LinkedBlockingQueue.java LinkedTransferQueue.java package-info.java Phaser.java PriorityBlockingQueue.java RecursiveAction.java RecursiveTask.java RejectedExecutionException.java RejectedExecutionHandler.java RunnableFuture.java RunnableScheduledFuture.java ScheduledExecutorService.java ScheduledFuture.java ScheduledThreadPoolExecutor.java Semaphore.java SynchronousQueue.java ThreadFactory.java ThreadLocalRandom.java ThreadPoolExecutor.java TimeoutException.java TimeUnit.java TransferQueue.java locks目录下： . .. AbstractOwnableSynchronizer.java AbstractQueuedLongSynchronizer.java AbstractQueuedSynchronizer.java Condition.java Lock.java LockSupport.java package-info.java ReadWriteLock.java ReentrantLock.java ReentrantReadWriteLock.java StampedLock.java atomic目录下： AtomicBoolean.java AtomicInteger.java AtomicIntegerArray.java AtomicIntegerFieldUpdater.java AtomicLong.java AtomicLongArray.java AtomicLongFieldUpdater.java AtomicMarkableReference.java AtomicReference.java AtomicReferenceArray.java AtomicReferenceFieldUpdater.java AtomicStampedReference.java DoubleAccumulator.java DoubleAdder.java LongAccumulator.java LongAdder.java package-info.java Striped64.java "}}